<!DOCTYPE html>
<meta charset="utf-8">
<meta charset="utf-8">
<style type="text/css">
  
	.node {
    cursor: pointer;
  }

  .overlay{
      background-color:#EEE;
  }
   
  .node circle {
    fill: #fff;
    stroke: steelblue;
    stroke-width: 1.5px;
  }
   
  .node text {
    font-size:10px; 
    font-family:sans-serif;
  }
   
  .link {
    fill: none;
    stroke: #ccc;
    stroke-width: 1.5px;
  }

  .templink {
    fill: none;
    stroke: red;
    stroke-width: 3px;
  }

  .ghostCircle.show{
      display:block;
  }

  .ghostCircle, .activeDrag .ghostCircle{
       display: none;
  }
  div.tooltip {
    position: absolute;
    text-align: left;
    width: 200px;
    padding: 2px;
    font: 12px sans-serif;
    background: lightsteelblue;
    border: 0px;
    border-radius: 8px;
    pointer-events: none;
	overflow-y:scroll
 }

</style>
<script src="http://code.jquery.com/jquery-1.10.2.min.js"></script>
<script src="http://d3js.org/d3.v3.min.js"></script>

<body>
    <div id="tree-container"></div>
<script>

// Uncomplete data uploaded in this html. The complete data,with options json or csv will be updated next with the load and save option

var lala=
`name	parent	Label	Class	Level	Definition
0		Statistics	Root	1	Branch of mathematics concerned with collection, classification, analysis, and interpretation of numerical facts, for drawing inferences on the basis of their quantifiable likelihood (probability). Statistics can interpret aggregates of data too large to be intelligible by ordinary observation because such data (unlike individual quantities) tend to behave in regular, predictable manner. It is subdivided into descriptive statistics and inferential statistics.
0.0	0	Summarizing	Statistics	2	Descriptive Statistics describe basic features of the data gathered from an experimental study in various ways. They provide simple summaries about the sample via graphs and numbers, mainly measures of center and variation. Tables (frequency distributions, stem-and-leaf plots, ...) that summarize the data
0.0.0	0.0	Descriptive statistics	Summarizing	3	A descriptive statistic (in the count noun sense) is a summary statistic that quantitatively describes or summarizes features of a collection of information, while descriptive statistics in the mass noun sense is the process of using and analyzing those statistics. Descriptive statistics is distinguished from inferential statistics (or inductive statistics), in that descriptive statistics aims to summarize a sample, rather than use the data to learn about the population that the sample of data is thought to represent. This generally means that descriptive statistics, unlike inferential statistics, is not developed on the basis of probability theory, and are frequently nonparametric statistics.Even when a data analysis draws its main conclusions using inferential statistics, descriptive statistics are generally also presented. For example, in papers reporting on human subjects, typically a table is included giving the overall sample size, sample sizes in important subgroups (e.g., for each treatment or exposure group), and demographic or clinical characteristics such as the average age, the proportion of subjects of each sex, the proportion of subjects with related comorbidities, etc.
0.0.0.0	0.0.0	Summary statistics	Descriptive statistics	4	"Summary statistics are used to summarize a set of observations, in order to communicate the largest amount of information as simply as possible. Statisticians commonly try to describe the observations in; a measure of location, or central tendency, such as the arithmetic mean; a measure of statistical dispersion like the standard deviation; a measure of the shape of the distribution like skewness or kurtosis; if more than one variable is measured, a measure of statistical dependence such as a correlation coefficient"
0.0.0.0.0	0.0.0.0	Location	Summary statistics	5	"A fundamental task in many statistical analyses is to estimate a location parameter for the distribution; i.e., to find a typical or central value that best describes the data."
0.0.0.0.0.0	0.0.0.0.0	Central tendency	Location	6	"In statistics, a central tendency (or measure of central tendency) is a central or typical value for a probability distribution. It may also be called a center or location of the distribution. Colloquially, measures of central tendency are often called averages. The term central tendency dates from the late 1920s. The most common measures of central tendency are the arithmetic mean, the median and the mode. A central tendency can be calculated for either a finite set of values or for a theoretical distribution, such as the normal distribution. Occasionally authors use central tendency to denote """"the tendency of quantitative data to cluster around some central value."""" The central tendency of a distribution is typically contrasted with its dispersion or variability; dispersion and central tendency are the often characterized properties of distributions. Analysts may judge whether data has a strong or a weak central tendency based on its dispersion."
0.0.0.0.0.0.0	0.0.0.0.0.0	Median	Central tendency	7	The median is the value separating the higher half of a data sample, a population, or a probability distribution, from the lower half. For a data set, it may be thought of as the  middle  value.
0.0.0.0.0.0.1	0.0.0.0.0.0	Geometric median	Central tendency	7	The geometric median of a discrete set of sample points in a Euclidean space is the point minimizing the sum of distances to the sample points. This generalizes the median, which has the property of minimizing the sum of distances for one-dimensional data, and provides a central tendency in higher dimensions. It is also known as the 1-median, spatial median, Euclidean minisum point, or Torricelli point.
0.0.0.0.0.0.2	0.0.0.0.0.0	Mode	Central tendency	7	The mode of a set of data values is the value that appears most often. It is the value x at which its probability mass function takes its maximum value. In other words, it is the value that is most likely to be sampled. A mode of a continuous probability distribution is often considered to be any value x at which its probability density function has a locally maximum value, so any peak is a mode.Like the statistical mean and median, the mode is a way of expressing, in a (usually) single number, important information about a random variable or a population. The numerical value of the mode is the same as that of the mean and median in a normal distribution, and it may be very different in highly skewed distributions.
0.0.0.0.0.0.3	0.0.0.0.0.0	Mean	Central tendency	7	"For a data set, the arithmetic mean, also called the mathematical expectation or average, is the central value of a discrete set of numbers: specifically, the sum of the values divided by the number of values. The arithmetic mean of a set of numbers x1, x2, ..., xn is typically denoted by {\displaystyle {\bar {x}}} {\bar {x}}, pronounced """"x bar"""". If the data set were based on a series of observations obtained by sampling from a statistical population, the arithmetic mean is the sample mean (denoted {\displaystyle {\bar {x}}} {\bar {x}}) to distinguish it from the mean of the underlying distribution, the population mean (denoted {\displaystyle \mu } \mu  or {\displaystyle \mu _{x}} \mu _{x})"
0.0.0.0.0.0.3.0	0.0.0.0.0.0.3	Arithmetic mean	Mean	8	The arithmetic mean (or mean or average) is the most commonly used and readily understood measure of central tendency. In statistics, the term average refers to any of the measures of central tendency.
0.0.0.0.0.0.3.1	0.0.0.0.0.0.3	Geometric mean	Mean	8	In mathematics, the geometric mean is a type of mean or average, which indicates the central tendency or typical value of a set of numbers by using the product of their values (as opposed to the arithmetic mean which uses their sum).
0.0.0.0.0.0.3.2	0.0.0.0.0.0.3	Harmonic mean	Mean	8	In mathematics, the harmonic mean (sometimes called the subcontrary mean) is one of several kinds of average, and in particular one of the Pythagorean means. Typically, it is appropriate for situations when the average of rates is desired.
0.0.0.0.0.0.3.3	0.0.0.0.0.0.3	Weighted arithmetic mean	Mean	8	The weighted arithmetic mean is similar to an ordinary arithmetic mean (the most common type of average), except that instead of each of the data points contributing equally to the final average, some data points contribute more than others.
0.0.0.0.0.0.3.4	0.0.0.0.0.0.3	Truncated mean	Mean	8	A truncated mean or trimmed mean is a statistical measure of central tendency, much like the mean and median.It involves the calculation of the mean after discarding given parts of a probability distribution or sample at the high and low end, and typically discarding an equal amount of both.
0.0.0.0.0.0.3.5	0.0.0.0.0.0.3	Winsorized mean	Mean	8	A winsorized mean is a winsorized statistical measure of central tendency, much like the mean and median, and even more similar to the truncated mean.
0.0.0.0.0.0.3.6	0.0.0.0.0.0.3	Quadratic mean	Mean	8	In statistics and its applications, the root mean square (abbreviated RMS or rms) is defined as the square root of mean square (the arithmetic mean of the squares of a set of numbers)
0.0.0.0.0.0.3.7	0.0.0.0.0.0.3	Interquartile mean	Mean	8	The interquartile mean (IQM) (or midmean) is a statistical measure of central tendency based on the truncated mean of the interquartile range.
0.0.0.0.0.0.4	0.0.0.0.0.0	Maximum deviation	Central tendency	7	In statistics, the absolute deviation of an element of a data set is the absolute difference between that element and a given point. Typically the deviation is reckoned from the central value, being construed as some type of average, most often the median or sometimes the mean of the data set.
0.0.0.0.0.0.5	0.0.0.0.0.0	Midrange	Central tendency	7	In statistics, the mid-range or mid-extreme of a set of statistical data values is the arithmetic mean of the maximum and minimum values in a data set
0.0.0.0.0.0.6	0.0.0.0.0.0	Central Moment	Central tendency	7	"In probability theory and statistics, a central moment is a moment of a probability distribution of a random variable about the random variable's mean; that is, it is the expected value of a specified integer power of the deviation of the random variable from the mean. The various moments form one set of values by which the properties of a probability distribution can be usefully characterized. Central moments are used in preference to ordinary moments, computed in terms of deviations from the mean instead of from zero, because the higher-order central moments relate only to the spread and shape of the distribution, rather than also to its location."
0.0.0.0.1	0.0.0.0	Spread	Summary statistics	5	Measures of spread describe how similar or varied the set of observed values are for a particular variable (data item). Measures of spread include the range, quartiles and the interquartile range, variance and standard deviation.
0.0.0.0.1.0	0.0.0.0.1	Statistical dispersion	Spread	6	Example of samples from two populations with the same mean but different dispersion. The blue population is much more dispersed than the red population. In statistics, dispersion (also called variability, scatter, or spread) is the extent to which a distribution is stretched or squeezed. Common examples of measures of statistical dispersion are the variance, standard deviation, and interquartile range. Dispersion is contrasted with location or central tendency, and together they are the most used properties of distributions.
0.0.0.0.1.0.0	0.0.0.0.1.0	Estimates of scale	Statistical dispersion	7	In statistics, a robust measure of scale is a robust statistic that quantifies the statistical dispersion in a set of numerical data. The most common such statistics are the interquartile range (IQR) and the median absolute deviation (MAD). These are contrasted with conventional measures of scale, such as sample variance or sample standard deviation, which are non-robust, meaning greatly influenced by outliers. These robust statistics are particularly used as estimators of a scale parameter, and have the advantages of both robustness and superior efficiency on contaminated data, at the cost of inferior efficiency on clean data from distributions such as the normal distribution. To illustrate robustness, the standard deviation can be made arbitrarily large by increasing exactly one observation (it has a breakdown point of 0, as it can be contaminated by a single point), a defect that is not shared by robust statistics.
0.0.0.0.1.0.0.0	0.0.0.0.1.0.0	Variance	Estimates of scale	8	In probability theory and statistics, variance is the expectation of the squared deviation of a random variable from its mean. Informally, it measures how far a set of (random) numbers are spread out from their average value.
0.0.0.0.1.0.0.1	0.0.0.0.1.0.0	Standard Deviation	Estimates of scale	8	In statistics, the standard deviation SD, also represented by the Greek letter sigma σ or the Latin letter s is a measure that is used to quantify the amount of variation or dispersion of a set of data values.A low standard deviation indicates that the data points tend to be close to the mean also called the expected value of the set, while a high standard deviation indicates that the data points are spread out over a wider range of values.
0.0.0.0.1.0.0.2	0.0.0.0.1.0.0	Interquartile Range	Estimates of scale	8	"In descriptive statistics, the interquartile range IQR, also called the midspread or middle 50%, or technically H-spread, is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = Q3 −  Q1. In other words, the IQR is the first quartile subtracted from the third quartile; these quartiles can be clearly seen on a box plot on the data."
0.0.0.0.1.0.0.3	0.0.0.0.1.0.0	Range	Estimates of scale	8	In descriptive statistics, this concept of range has a more complex meaning. The range is the size of the smallest interval which contains all the data and provides an indication of statistical dispersion.
0.0.0.0.1.0.0.4	0.0.0.0.1.0.0	Absolute deviation	Estimates of scale	8	The average absolute deviation (or mean absolute deviation) of a data set is the average of the absolute deviations from a central point. It is a summary statistic of statistical dispersion or variability. In this general form, the central point can be the mean, median, mode, or the result of another measure of central tendency. Furthermore, as described in the article about averages, the deviation averaging operation may refer to the mean or the median. Thus the total number of combinations amounts to at least four types of average absolute deviation.
0.0.0.0.1.0.0.4.0	0.0.0.0.1.0.0.4	Mean absolute difference	Absolute deviation	9	The mean absolute difference or the MAD  is defined as the average or mean, formally the expected value, of the absolute difference of two random variables X and Y independently and identically distributed with the same (unknown) distribution henceforth called Q.
0.0.0.0.1.0.0.4.1	0.0.0.0.1.0.0.4	Median absolute deviation	Absolute deviation	9	In statistics, the median absolute deviation (MAD) is a robust measure of the variability of a univariate sample of quantitative data. It can also refer to the population parameter that is estimated by the MAD calculated from a sample.
0.0.0.0.1.0.0.5	0.0.0.0.1.0.0	Distance correlation	Estimates of scale	8	In statistics and in probability theory, distance correlation is a measure of statistical dependence between two random variables or two random vectors of arbitrary, not necessarily equal, dimension. It is zero if and only if the random variables are statistically independent, unlike Pearson's correlation, which can be zero for dependent random variables.
0.0.0.0.1.0.1	0.0.0.0.1.0	Dimensionless	Statistical dispersion	7	In dimensional analysis, a dimensionless quantity is a quantity to which no physical dimension is assigned. It is also known as a bare number or pure number or a quantity of dimension one[1] and the corresponding unit of measurement in the SI is one (or 1) unit[2][3] and it is not explicitly shown. Dimensionless quantities are widely used in many fields, such as mathematics, physics, chemistry, engineering, and economics. Examples of quantities, to which dimensions are regularly assigned, are length, time, and speed, which are measured in dimensional units, such as metre, second and metre per second. This is considered to aid intuitive understanding. However, especially in mathematical physics, it is often more convenient to drop the assignment of explicit dimensions and express the quantities without dimensions, e.g., addressing the speed of light simply by the dimensionless number 1.
0.0.0.0.1.0.1.0	0.0.0.0.1.0.1	Coefficient of variation	Dimensionless	8	In probability theory and statistics, the coefficient of variation (CV), also known as relative standard deviation (RSD), is a standardized measure of dispersion of a probability distribution or frequency distribution.
0.0.0.0.1.0.1.1	0.0.0.0.1.0.1	Quartile coefficient of dispersion	Dimensionless	8	In statistics, the quartile coefficient of dispersion is a descriptive statistic which measures dispersion and which is used to make comparisons within and between data sets.
0.0.0.0.1.0.1.2	0.0.0.0.1.0.1	Relative mean difference	Dimensionless	8	When the probability distribution has a finite and nonzero arithmetic mean, the relative mean absolute difference, sometimes denoted by Δ or RMD
0.0.0.0.1.0.1.3	0.0.0.0.1.0.1	Gini coefficient	Dimensionless	8	In economics, the Gini coefficient (sometimes expressed as a Gini ratio or a normalized Gini index) is a measure of statistical dispersion intended to represent the income or wealth distribution of a nation's residents, and is the most commonly used measure of inequality
0.0.0.0.1.0.1.4	0.0.0.0.1.0.1	Entropy	Dimensionless	8	The measure of information entropy associated with each possible data value is the negative logarithm of the probability mass function for the value. Thus, when the data source has a lower-probability value (i.e., when a low-probability event occurs), the event carries more  information  ( surprisal ) than when the source data has a higher-probability value.
0.0.0.0.1.0.2	0.0.0.0.1.0	Qualitative variation	Statistical dispersion	7	An index of qualitative variation (IQV) is a measure of statistical dispersion in nominal distributions. There are a variety of these, but they have been relatively little-studied in the statistics literature. The simplest is the variation ratio, while more complex indices include the information entropy. 
0.0.0.0.1.0.2.0	0.0.0.0.1.0.2	categorical variables	Qualitative variation	8	In statistics, a categorical variable is a variable that can take on one of a limited, and usually fixed, number of possible values, assigning each individual or other unit of observation to a particular group or nominal category on the basis of some qualitative property
0.0.0.0.1.1	0.0.0.0.1	Order statistics	Spread	6	In statistics, the kth order statistic of a statistical sample is equal to its kth-smallest value. Together with rank statistics, order statistics are among the most fundamental tools in non-parametric statistics and inference. Important special cases of the order statistics are the minimum and maximum value of a sample, and (with some qualifications discussed below) the sample median and other sample quantiles. When using probability theory to analyze order statistics of random samples from a continuous distribution, the cumulative distribution function is used to reduce the analysis to the case of order statistics of the uniform distribution.
0.0.0.0.1.1.0	0.0.0.0.1.1	Five-number summary	Order statistics	7	The five-number summary is a set of descriptive statistics that provide information about a dataset. It consists of the five most important sample percentiles.
0.0.0.0.1.1.0.0	0.0.0.0.1.1.0	Sample minimum	Five-number summary	8	In statistics, the sample maximum and sample minimum, also called the largest observation and smallest observation, are the values of the greatest and least elements of a sample.
0.0.0.0.1.1.0.1	0.0.0.0.1.1.0	Lower quartile	Five-number summary	8	In descriptive statistics, the quartiles of a ranked set of data values are the three points that divide the data set into four equal groups, each group comprising a quarter of the data. A quartile is a type of quantile.
0.0.0.0.1.1.0.2	0.0.0.0.1.1.0	Upper quartile	Five-number summary	8	In descriptive statistics, the quartiles of a ranked set of data values are the three points that divide the data set into four equal groups, each group comprising a quarter of the data. A quartile is a type of quantile. The first quartile (Q1) is defined as the middle number between the smallest number and the median of the data set. The second quartile (Q2) is the median of the data. The third quartile (Q3) is the middle value between the median and the highest value of the data set.
0.0.0.0.1.1.0.3	0.0.0.0.1.1.0	Sample maximum	Five-number summary	8	In statistics, the sample maximum and sample minimum, also called the largest observation and smallest observation, are the values of the greatest and least elements of a sample.
0.0.0.0.1.1.1	0.0.0.0.1.1	Box plot	Order statistics	7	Box and whisker plots are uniform in their use of the box: the bottom and top of the box are always the first and third quartiles, and the band inside the box is always the second quartile (the median).
0.0.0.0.1.2	0.0.0.0.1	Percentiles	Spread	6	A percentile (or a centile) is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value (or score) below which 20% of the observations may be found.
0.0.0.0.2	0.0.0.0	Shape	Summary statistics	5	Common measures of the shape of a distribution are skewness or kurtosis, while alternatives can be based on L-moments. A different measure is the distance skewness, for which a value of zero implies central symmetry.
0.0.0.0.2.0	0.0.0.0.2	Skewness	Shape	6	In probability theory and statistics, skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. The skewness value can be positive or negative, or undefined.
0.0.0.0.2.1	0.0.0.0.2	Kurtosis	Shape	6	In probability theory and statistics, kurtosis is a measure of the tailedness of the probability distribution of a real-valued random variable. In a similar way to the concept of skewness, kurtosis is a descriptor of the shape of a probability distribution and, just as for skewness, there are different ways of quantifying it for a theoretical distribution and corresponding ways of estimating it from a sample from a population. Depending on the particular measure of kurtosis that is used, there are various interpretations of kurtosis, and of how particular measures should be interpreted.
0.0.0.0.2.2	0.0.0.0.2	L-moments	Shape	6	In statistics, L-moments are a sequence of statistics used to summarize the shape of a probability distribution. They are linear combinations of order statistics (L-statistics) analogous to conventional moments, and can be used to calculate quantities analogous to standard deviation, skewness and kurtosis, termed the L-scale, L-skewness and L-kurtosis respectively (the L-mean is identical to the conventional mean). Standardised L-moments are called L-moment ratios and are analogous to standardized moments.
0.0.0.0.2.3	0.0.0.0.2	Distance skewness	Shape	6	A value of skewness equal to zero does not imply that the probability distribution is symmetric. Thus there is a need for another measure of asymmetry that has this property: such a measure was introduced in 2000. It is called distance skewness and denoted by dSkew. If X is a random variable taking values in the d-dimensional Euclidean space, X has finite expectation, X' is an independent identically distributed copy of X
0.0.0.0.2.4	0.0.0.0.2	Symmetry	Shape	6	In statistics, a symmetric probability distribution is a probability distribution—an assignment of probabilities to possible occurrences—which is unchanged when its probability density function or probability mass function is reflected around a vertical line at some value of the random variable represented by the distribution. This vertical line is the line of symmetry of the distribution. Thus the probability of being any given distance on one side of the value about which symmetry occurs is the same as the probability of being the same distance on the other side of that value.
0.0.0.0.3	0.0.0.0	Dependence	Summary statistics	5	The common measure of dependence between paired random variables is the Pearson product-moment correlation coefficient, while a common alternative summary statistic is Spearman's rank correlation coefficient. A value of zero for the distance correlation implies independence. 
0.0.0.0.3.0	0.0.0.0.3	Pearson product-moment correlation coefficient	Dependence	6	In statistics, the Pearson correlation coefficient (PCC, pronounced /ˈpɪərsən/), also referred to as the Pearson's r, Pearson product-moment correlation coefficient (PPMCC) or bivariate correlation
0.0.0.0.3.1	0.0.0.0.3	Spearman's rank correlation coefficient	Dependence	6	In statistics, Spearman's rank correlation coefficient or Spearman's rho, named after Charles Spearman and often denoted by the Greek letter {\displaystyle \rho } \rho (rho) or as {\displaystyle r_{s}} r_{s}, is a nonparametric measure of rank correlation (statistical dependence between the ranking of two variables). It assesses how well the relationship between two variables can be described using a monotonic function.
0.0.0.0.3.2	0.0.0.0.3	Kendall rank correlation	Dependence	6	In statistics, the Kendall rank correlation coefficient, commonly referred to as Kendall's tau coefficient (after the Greek letter τ), is a statistic used to measure the ordinal association between two measured quantities. A tau test is a non-parametric hypothesis test for statistical dependence based on the tau coefficient.
0.0.0.1	0.0.0	Index of dispersion	Descriptive statistics	4	In probability theory and statistics, the index of dispersion,  dispersion index, coefficient of dispersion, relative variance, or variance-to-mean ratio (VMR), like the coefficient of variation, is a normalized measure of the dispersion of a probability distribution: it is a measure used to quantify whether a set of observed occurrences are clustered or dispersed compared to a standard statistical model.
0.0.0.2	0.0.0	Summary tables	Descriptive statistics	4	The summary table is a visualization that summarizes statistical information about data in table form. The information is based on one data table in TIBCO Spotfire. ... As you change the set of filtered rows, the Summary Table automatically updates the values displayed to reflect the current selection.
0.0.0.2.0	0.0.0.2	Grouped data	Summary tables	5	Grouped data are data formed by aggregating individual observations of a variable into groups, so that a frequency distribution of these groups serves as a convenient means of summarizing or analyzing the data.
0.0.0.2.1	0.0.0.2	Frequency distribution	Summary tables	5	The summary table is a visualization that summarizes statistical information about data in table form. The information is based on one data table in TIBCO Spotfire. As you change the set of filtered rows, the Summary Table automatically updates the values displayed to reflect the current selection.
0.0.0.2.1.0	0.0.0.2.1	Qualitative Data	Frequency distribution	6	A data sample is called qualitative, also known as categorical, if its values belong to a collection of known defined non-overlapping classes. Common examples include student letter grade (A, B, C, D or F), commercial bond rating (AAA, AAB, ...) and consumer clothing shoe sizes (1, 2, 3, ...). 
0.0.0.2.1.0.0	0.0.0.2.1.0	Frequency Distribution of Qualitative Data	Qualitative Data	7	The frequency distribution of a data variable is a summary of the data occurrence in a collection of non-overlapping categories.
0.0.0.2.1.0.1	0.0.0.2.1.0	Relative Frequency Distribution of Qualitative Data	Qualitative Data	7	The relative frequency distribution of a data variable is a summary of the frequency proportion in a collection of non-overlapping categories. The relationship of frequency and relative frequency is, (Relative Frequency=Frequency/Sample Size)
0.0.0.2.1.0.2	0.0.0.2.1.0	Bar Graph	Qualitative Data	7	A bar graph of a qualitative data sample consists of vertical parallel bars that shows the frequency distribution graphically.
0.0.0.2.1.0.3	0.0.0.2.1.0	Pie Chart	Qualitative Data	7	A pie chart of a qualitative data sample consists of pizza wedges that shows the frequency distribution graphically.
0.0.0.2.1.0.4	0.0.0.2.1.0	Category Statistics	Qualitative Data	7	In the built-in data set painters, the painters are classified according to the schools they belong. Each school can be characterized by its various statistics, such as mean composition, drawing, coloring and expression scores. Suppose we would like to know which school has the highest mean composition score. We would have to first find out the mean composition score of each school. The following shows how to find the mean composition score of an arbitrarily chosen school.  
0.0.0.2.1.1	0.0.0.2.1	Quantitative Data	Frequency distribution	6	Quantitative data, also known as continuous data, consists of numeric data that support arithmetic operations. This is in contrast with qualitative data, whose values belong to pre-defined classes with no arithmetic operation allowed. 
0.0.0.2.1.1.0	0.0.0.2.1.1	Distribution of Quantitative Data	Quantitative Data	7	The frequency distribution of a data variable is a summary of the data occurrence in a collection of non-overlapping categories.
0.0.0.2.1.1.1	0.0.0.2.1.1	Histogram	Quantitative Data	7	A histogram consists of parallel vertical bars that graphically shows the frequency distribution of a quantitative variable. The area of each bar is equal to the frequency of items found in each class.
0.0.0.2.1.1.2	0.0.0.2.1.1	Relative Frequency Distribution of Quantitative Data	Quantitative Data	7	The relative frequency distribution of a data variable is a summary of the frequency proportion in a collection of non-overlapping categories. The relationship of frequency and relative frequency is,Relative Frequency =Frequency/Sample Size
0.0.0.2.1.1.3	0.0.0.2.1.1	Cumulative Frequency Distribution	Quantitative Data	7	The cumulative frequency distribution of a quantitative variable is a summary of data frequency below a given level.
0.0.0.2.1.1.4	0.0.0.2.1.1	Cumulative Frequency Graph	Quantitative Data	7	A cumulative frequency graph or ogive of a quantitative variable is a curve graphically showing the cumulative frequency distribution.
0.0.0.2.1.1.5	0.0.0.2.1.1	Cumulative Relative Frequency Distribution	Quantitative Data	7	The cumulative relative frequency distribution of a quantitative variable is a summary of frequency proportion below a given level. The relationship between cumulative frequency and relative cumulative frequency is,Cumulative Relative Frequency = Cumulative/Frequency Sample Size
0.0.0.2.1.1.6	0.0.0.2.1.1	Cumulative Relative Frequency Graph	Quantitative Data	7	A cumulative relative frequency graph of a quantitative variable is a curve graphically showing the cumulative relative frequency distribution.
0.0.0.2.1.1.7	0.0.0.2.1.1	Stem-and-Leaf Plot	Quantitative Data	7	A stem-and-leaf plot of a quantitative variable is a textual graph that classifies data items according to their most significant numeric digits. In addition, we often merge each alternating row with its next row in order to simplify the graph for readability.
0.0.0.2.1.1.8	0.0.0.2.1.1	Scatter Plot	Quantitative Data	7	A scatter plot pairs up values of two quantitative variables in a data set and display them as geometric points inside a Cartesian diagram.
0.0.0.2.2	0.0.0.2	Contingency table	Summary tables	5	In statistics, a contingency table (also known as a cross tabulation or crosstab) is a type of table in a matrix format that displays the (multivariate) frequency distribution of the variables. They are heavily used in survey research, business intelligence, engineering and scientific research. They provide a basic picture of the interrelation between two variables and can help find interactions between them.
0.0.0.3	0.0.0	Graphics	Descriptive statistics	4	Statistical graphics, also known as graphical techniques, are graphics in the field of statistics used to visualize quantitative data. 
0.0.0.3.0	0.0.0.3	Bar chart	Graphics	5	A bar chart or bar graph is a chart or graph that presents categorical data with rectangular bars with heights or lengths proportional to the values that they represent. The bars can be plotted vertically or horizontally. A vertical bar chart is sometimes called a line graph. 
0.0.0.3.1	0.0.0.3	Biplot	Graphics	5	Biplots are a type of exploratory graph used in statistics, a generalization of the simple two-variable scatterplot. A biplot allows information on both samples and variables of a data matrix to be displayed graphically. Samples are displayed as points while variables are displayed either as vectors, linear axes or nonlinear trajectories. In the case of categorical variables, category level points may be used to represent the levels of a categorical variable. A generalised biplot displays information on both continuous and categorical variables. 
0.0.0.3.2	0.0.0.3	Box plot	Graphics	5	In descriptive statistics, a box plot or boxplot is a method for graphically depicting groups of numerical data through their quartiles. Box plots may also have lines extending vertically from the boxes (whiskers) indicating variability outside the upper and lower quartiles, hence the terms box-and-whisker plot and box-and-whisker diagram. Outliers may be plotted as individual points. Box plots are non-parametric: they display variation in samples of a statistical population without making any assumptions of the underlying statistical distribution. The spacings between the different parts of the box indicate the degree of dispersion (spread) and skewness in the data, and show outliers. In addition to the points themselves, they allow one to visually estimate various L-estimators, notably the interquartile range, midhinge, range, mid-range, and trimean. Box plots can be drawn either horizontally or vertically. Box plots received their name from the box in the middle.
0.0.0.3.3	0.0.0.3	Control chart	Graphics	5	Control charts, also known as Shewhart charts (after Walter A. Shewhart) or process-behavior charts, are a statistical process control tool used to determine if a manufacturing or business process is in a state of control. 
0.0.0.3.4	0.0.0.3	Correlogram	Graphics	5	In the analysis of data, a correlogram is an image of correlation statistics. For example, in time series analysis, a correlogram, also known as an autocorrelation plot, is a plot of the sample autocorrelations r h      {\displaystyle r_{h}\,}  r_{h}\, versus h    {\displaystyle h\,}  h\, (the time lags). If cross-correlation is used, the result is called a cross-correlogram. The correlogram is a commonly used tool for checking randomness in a data set. This randomness is ascertained by computing autocorrelations for data values at varying time lags. If random, such autocorrelations should be near zero for any and all time-lag separations. If non-random, then one or more of the autocorrelations will be significantly non-zero.
0.0.0.3.5	0.0.0.3	Fan chart	Graphics	5	A fan chart is made of a group of dispersion fan diagrams, which may be positioned according to two categorising dimensions. A dispersion fan diagram is a circular diagram which reports the same information about a dispersion as a box plot: namely median, quartiles, and two extreme values. 
0.0.0.3.6	0.0.0.3	Forest plot	Graphics	5	A forest plot, also known as a blobbogram, is a graphical display of estimated results from a number of scientific studies addressing the same question, along with the overall results.[1] It was developed for use in medical research as a means of graphically representing a meta-analysis of the results of randomized controlled trials. In the last twenty years, similar meta-analytical techniques have been applied in observational studies (e.g. environmental epidemiology) and forest plots are often used in presenting the results of such studies also.
0.0.0.3.7	0.0.0.3	Histogram	Graphics	5	"A histogram is an accurate representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable (quantitative variable) and was first introduced by Karl Pearson. It differs from a bar graph, in the sense that a bar graph relates two variables, but a histogram relates only one. To construct a histogram, the first step is to ""bin"" (or ""bucket"") the range of values—that is, divide the entire range of values into a series of intervals—and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins (intervals) must be adjacent, and are often (but are not required to be) of equal size."
0.0.0.3.8	0.0.0.3	Pie chart	Graphics	5	A pie chart (or a circle chart) is a circular statistical graphic which is divided into slices to illustrate numerical proportion. In a pie chart, the arc length of each slice (and consequently its central angle and area), is proportional to the quantity it represents. While it is named for its resemblance to a pie which has been sliced, there are variations on the way it can be presented. The earliest known pie chart is generally credited to William Playfair's Statistical Breviary of 1801.
0.0.0.3.9	0.0.0.3	Q–Q plot	Graphics	5	In statistics, a Q–Q (quantile-quantile) plot is a probability plot, which is a graphical method for comparing two probability distributions by plotting their quantiles against each other.[1] First, the set of intervals for the quantiles is chosen. A point (x, y) on the plot corresponds to one of the quantiles of the second distribution (y-coordinate) plotted against the same quantile of the first distribution (x-coordinate). Thus the line is a parametric curve with the parameter which is the number of the interval for the quantile. 
0.0.0.3.10	0.0.0.3	Run chart	Graphics	5	A run chart, also known as a run-sequence plot is a graph that displays observed data in a time sequence. Often, the data displayed represent some aspect of the output or performance of a manufacturing or other business process. It is therefore a form of line chart. 
0.0.0.3.11	0.0.0.3	Scatter plot	Graphics	5	A scatter plot (also called a scatterplot, scatter graph, scatter chart, scattergram, or scatter diagram) is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. If the points are color-coded, one additional variable can be displayed. The data are displayed as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis
0.0.0.3.12	0.0.0.3	Radar chart	Graphics	5	A radar chart is a graphical method of displaying multivariate data in the form of a two-dimensional chart of three or more quantitative variables represented on axes starting from the same point. The relative position and angle of the axes is typically uninformative. The radar chart is also known as web chart, spider chart, star chart, star plot, cobweb chart, irregular polygon, polar chart, or Kiviat diagram.
0.0.0.3.13	0.0.0.3	Stem-and-leaf display	Graphics	5	A stem-and-leaf display or stem-and-leaf plot is a device for presenting quantitative data in a graphical format, similar to a histogram, to assist in visualizing the shape of a distribution. They evolved from Arthur Bowley's work in the early 1900s, and are useful tools in exploratory data analysis. Stemplots became more commonly used in the 1980s after the publication of John Tukey's book on exploratory data analysis in 1977. The popularity during those years is attributable to their use of monospaced (typewriter) typestyles that allowed computer technology of the time to easily produce the graphics. Modern computers' superior graphic capabilities have meant these techniques are less often used.
0.0.1	0.0	Inferential statistics	Summarizing	3	Statistical inference is the process of using data analysis to deduce properties of an underlying probability distribution. Inferential statistical analysis infers properties of a population, for example by testing hypotheses and deriving estimates. It is assumed that the observed data set is sampled from a larger population. Inferential statistics can be contrasted with descriptive statistics. Descriptive statistics is solely concerned with properties of the observed data, and it does not rest on the assumption that the data come from a larger population.
0.0.1.0	0.0.1	Terminology	Inferential statistics	4	Terms used with a particular technical application in this case, Inferential Statistics.
0.0.1.0.0	0.0.1.0	Estimation theory	Terminology	5	Estimation theory is a branch of statistics that deals with estimating the values of parameters based on measured empirical data that has a random component. The parameters describe an underlying physical setting in such a way that their value affects the distribution of the measured data.
0.0.1.0.0.0	0.0.1.0.0	estimator	Estimation theory	6	A statistic, when used to estimate a population parameter, is called an estimator several statistical  ingredients  need to be known.
0.0.1.0.0.1	0.0.1.0.0	expected value	Estimation theory	6	In probability theory, the expected value of a random variable, intuitively, is the long-run average value of repetitions of the experiment it represents.
0.0.1.0.0.2	0.0.1.0.0	unbiased	Estimation theory	6	In statistics, the bias (or bias function) of an estimator is the difference between this estimator's expected value and the true value of the parameter being estimated. An estimator or decision rule with zero bias is called unbiased.
0.0.1.0.0.3	0.0.1.0.0	Minimum-variance unbiased estimator UMVUE	Estimation theory	6	In statistics a minimum-variance unbiased estimator (MVUE) or uniformly minimum-variance unbiased estimator (UMVUE) is an unbiased estimator that has lower variance than any other unbiased estimator for all possible values of the parameter.
0.0.1.0.1	0.0.1.0	Parameter	Terminology	5	A statistical parameter or population parameter is a quantity that indexes a family of probability distributions. It can be regarded as a numerical characteristic of a population or a statistical model. E.g. location. scale and shape
0.0.1.0.2	0.0.1.0	Statistic	Terminology	5	A statistic (singular) or sample statistic is a single measure of some attribute of a sample (e.g., its arithmetic mean value). It is calculated by applying a function (statistical algorithm) to the values of the items of the sample, which are known together as a set of data.Function of the random variables that form the sample. Therefore, it is also a random variable
0.0.1.0.3	0.0.1.0	Population	Terminology	5	In statistics, a population is a set of similar items or events which is of interest for some question or experiment.  A statistical population can be a group of actually existing objects. Set of elements with certain attributes of interest. For one study attribute, the population is represented by a r.v. X
0.0.1.0.4	0.0.1.0	Probability distribution	Terminology	5	In probability theory and statistics, a probability distribution is a mathematical function that, stated in simple terms, can be thought of as providing the probabilities of occurrence of different possible outcomes in an experiment.
0.0.1.0.5	0.0.1.0	Independent identically distributed (IID) random variables	Terminology	5	In probability theory and statistics, a sequence or other collection of random variables is independent and identically distributed (i.i.d. or iid or IID) if each random variable has the same probability distribution as the others and all are mutually independent.
0.0.1.0.6	0.0.1.0	Census	Terminology	5	Complete enumeration of the population elements
0.0.1.0.7	0.0.1.0	Sample	Terminology	5	finite subset of the population
0.0.1.0.8	0.0.1.0	Random sampling	Terminology	5	Random process of selecting the sample elements in which any element can be selected from the population according to a known probability. A random sampleof sizen of a population Xis represented by the set ofiid r.v. {X1, X2, …, Xn}
0.0.1.0.9	0.0.1.0	Sampling	Terminology	5	In statistics, quality assurance, and survey methodology, sampling is the selection of a subset (a statistical sample) of individuals from within a statistical population to estimate characteristics of the whole population. Two advantages of sampling are that the cost is lower and data collection is faster than measuring the entire population. Each observation measures one or more properties (such as weight, location, colour) of observable bodies distinguished as independent objects or individuals. In survey sampling, weights can be applied to the data to adjust for the sample design, particularly stratified sampling. Results from probability theory and statistical theory are employed to guide the practice. In business and medical research, sampling is widely used for gathering information about a population. Acceptance sampling is used to determine if a production lot of material meets the governing specifications.
0.0.1.0.9.0	0.0.1.0.9	Random sample	Sampling	6	In statistics, quality assurance, and survey methodology, sampling is the selection of a subset (a statistical sample) of individuals from within a statistical population to estimate characteristics of the whole population. Two advantages of sampling are that the cost is lower and data collection is faster than measuring the entire population. Each observation measures one or more properties (such as weight, location, colour) of observable bodies distinguished as independent objects or individuals. In survey sampling, weights can be applied to the data to adjust for the sample design, particularly stratified sampling. Results from probability theory and statistical theory are employed to guide the practice. In business and medical research, sampling is widely used for gathering information about a population. Acceptance sampling is used to determine if a production lot of material meets the governing specifications.
0.0.1.0.9.0.0	0.0.1.0.9.0	Random vector	Random sample	7	In probability, and statistics, a multivariate random variable or random vector is a list of mathematical variables each of whose value is unknown, either because the value has not yet occurred or because there is imperfect knowledge of its value.
0.0.1.0.9.1	0.0.1.0.9	Sample mean	Sampling	6	The sample mean vector contains the average of the observations for each variable
0.0.1.0.9.2	0.0.1.0.9	Sample variance	Sampling	6	When dealing with extremely large populations, it is not possible to count every object in the population, so the computation must be performed on a sample of the population. Sample variance can also be applied to the estimation of the variance of a continuous distribution from a sample of that distribution.
0.0.1.0.9.3	0.0.1.0.9	Sample covariance	Sampling	6	The sample covariance matrix is a K-by-K matrix with entrieswhere q j is an estimate of the covariance between the jth variable and the kth variable of the population underlying the data. In terms of the observation vectors, the sample covariance is
0.0.1.0.10	0.0.1.0	Density estimation	Terminology	5	"In probability and statistics, density estimation is the construction of an estimate, based on observed data, of an unobservable underlying probability density function. The unobservable density function is thought of as the density according to which a large population is distributed; the data are usually thought of as a random sample from that population."
0.0.1.0.11	0.0.1.0	Lp space	Terminology	5	In mathematics, the Lp spaces are function spaces defined using a natural generalization of the p-norm for finite-dimensional vector spaces. They are sometimes called Lebesgue spaces, named after Henri Lebesgue (Dunford & Schwartz 1958, III.3), although according to the Bourbaki group (Bourbaki 1987) they were first introduced by Frigyes Riesz (Riesz 1910). Lp spaces form an important class of Banach spaces in functional analysis, and of topological vector spaces.
0.0.1.0.12	0.0.1.0	Estimator	Terminology	5	Function of the random variables that form the sample, which is used for estimating an unknown parameter. Therefore, it is a r.v.
0.0.1.0.13	0.0.1.0	Estimator	Terminology	5	Function of the random variables that form the sample, which is used for estimating an unknown parameter. Therefore, it is a r.v.
0.0.1.0.13.0	0.0.1.0.13	Maximum likelihood estimation	Estimator	6	In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters. MLE can be seen as a special case of the maximum a posteriori estimation (MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized.The method of maximum likelihood corresponds to many well-known estimation methods in statistics. For example, one may be interested in the heights of adult female penguins, but is unable to measure the height of every single penguin in a population due to cost or time constraints. Assuming that the heights are normally distributed with some unknown mean and variance, the mean and variance can be estimated with MLE while only knowing the heights of some sample of the overall population. MLE would accomplish this by taking the mean and variance as parameters and finding particular parametric values that make the observed results the most probable given the model.
0.0.1.0.13.1	0.0.1.0.13	Prior probability distribution	Estimator	6	"In Bayesian statistical inference, a prior probability distribution, often simply called the prior, of an uncertain quantity is the probability distribution that would express one's beliefs about this quantity before some evidence is taken into account. For example, the prior could be the probability distribution representing the relative proportions of voters who will vote for a particular politician in a future election. The unknown quantity may be a parameter of the model or a latent variable rather than an observable variable. Bayes' theorem calculates the renormalized pointwise product of the prior and the likelihood function, to produce the posterior probability distribution, which is the conditional distribution of the uncertain quantity given the data. Similarly, the prior probability of a random event or an uncertain proposition is the unconditional probability that is assigned before any relevant evidence is taken into account. Priors can be created using a number of methods. A prior can be determined from past information, such as previous experiments. A prior can be elicited from the purely subjective assessment of an experienced expert. An uninformative prior can be created to reflect a balance among outcomes when no information is available. Priors can also be chosen according to some principle, such as symmetry or maximizing entropy given constraints; examples are the Jeffreys prior or Bernardo's reference prior. When a family of conjugate priors exists, choosing a prior from that family simplifies calculation of the posterior distribution. Parameters of prior distributions are a kind of hyperparameter. For example, if one uses a beta distribution to model the distribution of the parameter p of a Bernoulli distribution"
0.0.1.0.13.1.0	0.0.1.0.13.1	Conjugate prior	Prior probability distribution	7	In Bayesian probability theory, if the posterior distributions p(θ|x) are in the same family as the prior probability distribution p(θ), the prior and posterior are then called conjugate distributions, and the prior is called a conjugate prior for the likelihood function. For example, the Gaussian family is conjugate to itself (or self-conjugate) with respect to a Gaussian likelihood function: if the likelihood function is Gaussian, choosing a Gaussian prior over the mean will ensure that the posterior distribution is also Gaussian. This means that the Gaussian distribution is a conjugate prior for the likelihood that is also Gaussian.
0.0.1.0.13.1.1	0.0.1.0.13.1	Posterior probability distribution	Prior probability distribution	7	In Bayesian statistics, the posterior probability of a random event or an uncertain proposition is the conditional probability that is assigned after the relevant evidence or background is taken into account. Similarly, the posterior probability distribution is the probability distribution of an unknown quantity, treated as a random variable, conditional on the evidence obtained from an experiment or survey. Posterior, in this context, means after taking into account the relevant evidence related to the particular case being examined.
0.0.1.0.13.2	0.0.1.0.13	Bayes estimators	Estimator	6	Suppose an unknown parameter {\displaystyle \theta } \theta  is known to have a prior distribution {\displaystyle \pi } \pi . Let {\displaystyle {\widehat {\theta }}={\widehat {\theta }}(x)} {\widehat {\theta }}={\widehat {\theta }}(x) be an estimator of {\displaystyle \theta } \theta  (based on some measurements x), and let {\displaystyle L(\theta ,{\widehat {\theta }})} L(\theta ,{\widehat {\theta }}) be a loss function, such as squared error. The Bayes risk of {\displaystyle {\widehat {\theta }}} {\widehat {\theta }} is defined as {\displaystyle E_{\pi }(L(\theta ,{\widehat {\theta }}))} E_{\pi }(L(\theta ,{\widehat {\theta }})), where the expectation is taken over the probability distribution of {\displaystyle \theta } \theta : this defines the risk function as a function of {\displaystyle {\widehat {\theta }}} {\widehat {\theta }}. An estimator {\displaystyle {\widehat {\theta }}} {\widehat {\theta }} is said to be a Bayes estimator if it minimizes the Bayes risk among all estimators. Equivalently, the estimator which minimizes the posterior expected loss {\displaystyle E(L(\theta ,{\widehat {\theta }})|x)} E(L(\theta ,{\widehat {\theta }})|x) for each {\displaystyle x} x also minimizes the Bayes risk and therefore is a Bayes estimator. If the prior is improper then an estimator which minimizes the posterior expected loss for each {\displaystyle x} x is called a generalized Bayes estimator
0.0.1.0.13.3	0.0.1.0.13	Generalized method of moments	Estimator	6	In econometrics and statistics, the generalized method of moments (GMM) is a generic method for estimating parameters in statistical models. Usually it is applied in the context of semiparametric models, where the parameter of interest is finite-dimensional, whereas the full shape of the distribution function of the data may not be known, and therefore maximum likelihood estimation is not applicable. The method requires that a certain number of moment conditions were specified for the model. These moment conditions are functions of the model parameters and the data, such that their expectation is zero at the true values of the parameters. The GMM method then minimizes a certain norm of the sample averages of the moment conditions. The GMM estimators are known to be consistent, asymptotically normal, and efficient in the class of all estimators that do not use any extra information aside from that contained in the moment conditions.
0.0.1.0.13.4	0.0.1.0.13	Minimum mean squared error	Estimator	6	In statistics and signal processing, a minimum mean square error (MMSE) estimator is an estimation method which minimizes the mean square error (MSE), which is a common measure of estimator quality, of the fitted values of a dependent variable. In the Bayesian setting, the term MMSE more specifically refers to estimation with quadratic loss function. In such case, the MMSE estimator is given by the posterior mean of the parameter to be estimated. Since the posterior mean is cumbersome to calculate, the form of the MMSE estimator is usually constrained to be within a certain class of functions. Linear MMSE estimators are a popular choice since they are easy to use, calculate, and very versatile. It has given rise to many popular estimators such as the Wiener–Kolmogorov filter and Kalman filter.
0.0.1.0.13.5	0.0.1.0.13	Maximum a posteriori	Estimator	6	In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. The MAP can be used to obtain a point estimate of an unobserved quantity on the basis of empirical data. It is closely related to the method of maximum likelihood (ML) estimation, but employs an augmented optimization objective which incorporates a prior distribution (that quantifies the additional information available through prior knowledge of a related event) over the quantity one wants to estimate. MAP estimation can therefore be seen as a regularization of ML estimation.
0.0.1.0.13.6	0.0.1.0.13	Best linear unbiased estimator	Estimator	6	In statistics, the Gauss–Markov theorem, named after Carl Friedrich Gauss and Andrey Markov, states that in a linear regression model in which the errors have expectation zero and are uncorrelated and have equal variances, the best linear unbiased estimator (BLUE) of the coefficients is given by the ordinary least squares (OLS) estimator, provided it exists. Here  best  means giving the lowest variance of the estimate, as compared to other unbiased, linear estimators. The errors do not need to be normal, nor do they need to be independent and identically distributed (only uncorrelated with mean zero and homoscedastic with finite variance). The requirement that the estimator be unbiased cannot be dropped, since biased estimators exist with lower variance. See, for example, the James–Stein estimator (which also drops linearity) or ridge regression.
0.0.1.0.13.7	0.0.1.0.13	Estimator bias	Estimator	6	"In statistics, the bias (or bias function) of an estimator is the difference between this estimator's expected value and the true value of the parameter being estimated. An estimator or decision rule with zero bias is called unbiased. Otherwise the estimator is said to be biased. In statistics,  bias  is an objective property of an estimator, and while not a desired property, it is not pejorative, unlike the ordinary English use of the term  bias . Bias can also be measured with respect to the median, rather than the mean (expected value), in which case one distinguishes median-unbiased from the usual mean-unbiasedness property. Bias is related to consistency in that consistent estimators are convergent and asymptotically unbiased (hence converge to the correct value), though individual estimators in a consistent sequence may be biased (so long as the bias converges to zero); see bias versus consistency."
0.0.1.0.13.8	0.0.1.0.13	Markov chain Monte Carlo	Estimator	6	In statistics, Markov chain Monte Carlo (MCMC) methods are a class of algorithms for sampling from a probability distribution based on constructing a Markov chain that has the desired distribution as its equilibrium distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps. Convergence of the Metropolis-Hastings algorithm. MCMC attempts to approximate the blue distribution with the orange distribution Random walk Monte Carlo methods make up a large subclass of MCMC methods.
0.0.1.0.13.9	0.0.1.0.13	Kalman filter	Estimator	6	Kalman filtering, also known as linear quadratic estimation (LQE), is an algorithm that uses a series of measurements observed over time, containing statistical noise and other inaccuracies, and produces estimates of unknown variables that tend to be more accurate than those based on a single measurement alone, by using Bayesian inference and estimating a joint probability distribution over the variables for each timeframe. The filter is named after Rudolf E. Kálmán, one of the primary developers of its theory. The Kalman filter has numerous applications in technology. A common application is for guidance, navigation, and control of vehicles, particularly aircraft and spacecraft.Furthermore, the Kalman filter is a widely applied concept in time series analysis used in fields such as signal processing and econometrics. Kalman filters also are one of the main topics in the field of robotic motion planning and control, and they are sometimes included in trajectory optimization. The Kalman filter also works for modeling the central nervous system's control of movement. Due to the time delay between issuing motor commands and receiving sensory feedback, usage of the Kalman filter supports the realistic model for making estimates of the current state of the motor system and issuing updated commands.
0.0.1.0.13.10	0.0.1.0.13	Wiener filter	Estimator	6	The goal of the Wiener filter is to compute a statistical estimate of an unknown signal using a related signal as an input and filtering that known signal to produce the estimate as an output. For example, the known signal might consist of an unknown signal of interest that has been corrupted by additive noise. The Wiener filter can be used to filter out the noise from the corrupted signal to provide an estimate of the underlying signal of interest. The Wiener filter is based on a statistical approach, and a more statistical account of the theory is given in the minimum mean square error (MMSE) estimator article.
0.0.1.0.13.11	0.0.1.0.13	M-estimator	Estimator	6	"In statistics, M-estimators are a broad class of estimators, which are obtained as the minima of sums of functions of the data. Least-squares estimators are a special case of M-estimators. The definition of M-estimators was motivated by robust statistics, which contributed new types of M-estimators. The statistical procedure of evaluating an M-estimator on a data set is called M-estimation. More generally, an M-estimator may be defined to be a zero of an estimating function. This estimating function is often the derivative of another statistical function. For example, a maximum-likelihood estimate is often defined to be a zero of the derivative of the likelihood function with respect to the parameter; thus, a maximum-likelihood estimator is often a critical point of the score function. In many applications, such M-estimators can be thought of as estimating characteristics of the population."
0.0.1.0.13.12	0.0.1.0.13	Maximum spacing estimation	Estimator	6	In statistics, maximum spacing estimation (MSE or MSP), or maximum product of spacing estimation (MPS), is a method for estimating the parameters of a univariate statistical model. The method requires maximization of the geometric mean of spacings in the data, which are the differences between the values of the cumulative distribution function at neighbouring data points.The concept underlying the method is based on the probability integral transform, in that a set of independent random samples derived from any random variable should on average be uniformly distributed with respect to the cumulative distribution function of the random variable. The MPS method chooses the parameter values that make the observed data as uniform as possible, according to a specific quantitative measure of uniformity.One of the most common methods for estimating the parameters of a distribution from data, the method of maximum likelihood (MLE), can break down in various cases, such as involving certain mixtures of continuous distributions. In these cases the method of maximum spacing estimation may be successful
0.0.1.0.13.13	0.0.1.0.13	Minimum distance estimation	Estimator	6	Minimum distance estimation (MDE) is a statistical method for fitting a mathematical model to data, usually the empirical distribution.
0.0.1.0.13.14	0.0.1.0.13	Quasi-maximum likelihood	Estimator	6	A quasi-maximum likelihood estimate (QMLE, also known as a pseudo-likelihood estimate or a composite likelihood estimate) is an estimate of a parameter θ in a statistical model that is formed by maximizing a function that is related to the logarithm of the likelihood function, but is not equal to it. In contrast, the maximum likelihood estimate maximizes the actual log likelihood function for the data and model. The function that is maximized to form a QMLE is often a simplified form of the actual log likelihood function. A common way to form such a simplified function is to use the log-likelihood function of a misspecified model that treats certain data values as being independent, even when in actuality they may not be. This removes any parameters from the model that are used to characterize these dependencies. Doing this only makes sense if the dependency structure is a nuisance parameter with respect to the goals of the analysis. As long as the quasi-likelihood function that is maximized is not oversimplified, the QMLE (or composite likelihood estimate) is consistent and asymptotically normal. It is less efficient than the maximum likelihood estimate, but may only be slightly less efficient if the quasi-likelihood is constructed so as to minimize the loss of information relative to the actual likelihood.  Standard approaches to statistical inference that are used with maximum likelihood estimates, such as the formation of confidence intervals, and statistics for model comparison,[4] can be generalized to the quasi-maximum likelihood setting.
0.0.1.0.13.15	0.0.1.0.13	Restricted maximum likelihood	Estimator	6	In statistics, the restricted (or residual, or reduced) maximum likelihood (REML) approach is a particular form of maximum likelihood estimation which does not base estimates on a maximum likelihood fit of all the information, but instead uses a likelihood function calculated from a transformed set of data, so that nuisance parameters have no effect.In the case of variance component estimation, the original data set is replaced by a set of contrasts calculated from the data, and the likelihood function is calculated from the probability distribution of these contrasts, according to the model for the complete data set. In particular, REML is used as a method for fitting linear mixed models. In contrast to the earlier maximum likelihood estimation, REML can produce unbiased estimates of variance and covariance parameters
0.0.1.0.13.16	0.0.1.0.13	Information entropy	Estimator	6	Information entropy is defined as the average amount of information produced by a probabilistic stochastic source of data.The measure of information entropy associated with each possible data value is the negative logarithm of the probability mass function for the value. Thus, when the data source has a lower-probability value (i.e., when a low-probability event occurs), the event carries more  information  ( surprisal ) than when the source data has a higher-probability value. The amount of information conveyed by each event defined in this way becomes a random variable whose expected value is the information entropy. Generally, entropy refers to disorder or uncertainty, and the definition of entropy used in information theory is directly analogous to the definition used in statistical thermodynamics. The concept of information entropy was introduced by Claude Shannon in his 1948 paper  A Mathematical Theory of Communication .The basic model of a data communication system is composed of three elements, a source of data, a channel, and a receiver, and – as expressed by Shannon, who essentially single-handedly created the field of information theory – the  fundamental problem of communication  is for the receiver to be able to identify what data was generated by the source, based on the signal it receives through the channel. The entropy provides an absolute limit on the shortest possible average length of a lossless compression encoding of the data produced by a source, and if the entropy of the source is less than the channel capacity of the communication channel, the data generated by the source can be reliably communicated to the receiver (at least in theory, possibly neglecting some practical considerations such as the complexity of the system needed to convey the data and the amount of time it may take for the data to be conveyed).
0.0.1.0.13.17	0.0.1.0.13	Fisher information	Estimator	6	In mathematical statistics, the Fisher information (sometimes simply called information ) is a way of measuring the amount of information that an observable random variable X carries about an unknown parameter θ of a distribution that models X. Formally, it is the variance of the score, or the expected value of the observed information. In Bayesian statistics, the asymptotic distribution of the posterior mode depends on the Fisher information and not on the prior (according to the Bernstein–von Mises theorem, which was anticipated by Laplace for exponential families). The role of the Fisher information in the asymptotic theory of maximum-likelihood estimation was emphasized by the statistician Ronald Fisher (following some initial results by Francis Ysidro Edgeworth). The Fisher information is also used in the calculation of the Jeffreys prior, which is used in Bayesian statistics.The Fisher-information matrix is used to calculate the covariance matrices associated with maximum-likelihood estimates. It can also be used in the formulation of test statistics, such as the Wald test.
0.0.1.0.13.18	0.0.1.0.13	Cramér–Rao bound	Estimator	6	"In estimation theory and statistics, the Cramér–Rao bound (CRB) or Cramér–Rao lower bound (CRLB), named in honor of Harald Cramér and Calyampudi Radhakrishna Rao who were among the first to derive it, expresses a lower bound on the variance of estimators of a deterministic (fixed, though unknown) parameter. The bound is also known as the Cramér–Rao inequality or the information inequality.In its simplest form, the bound states that the variance of any unbiased estimator is at least as high as the inverse of the Fisher information. An unbiased estimator which achieves this lower bound is said to be (fully) efficient. Such a solution achieves the lowest possible mean squared error among all unbiased methods, and is therefore the minimum variance unbiased (MVU) estimator. However, in some cases, no unbiased technique exists which achieves the bound. This may occur even when an MVU estimator exists.The Cramér–Rao bound can also be used to bound the variance of biased estimators of given bias. In some cases, a biased approach can result in both a variance and a mean squared error that are below the unbiased Cramér–Rao lower bound; see estimator bias."
0.0.1.0.13.19	0.0.1.0.13	Minimum variance unbiased estimator	Estimator	6	"In statistics a minimum-variance unbiased estimator (MVUE) or uniformly minimum-variance unbiased estimator (UMVUE) is an unbiased estimator that has lower variance than any other unbiased estimator for all possible values of the parameter.For practical statistics problems, it is important to determine the MVUE if one exists, since less-than-optimal procedures would naturally be avoided, other things being equal. This has led to substantial development of statistical theory related to the problem of optimal estimation.While combining the constraint of unbiasedness with the desirability metric of least variance leads to good results in most practical settings—making MVUE a natural starting point for a broad range of analyses—a targeted specification may perform better for a given problem; thus, MVUE is not always the best stopping point."
0.0.1.0.13.20	0.0.1.0.13	Nonlinear system identification	Estimator	6	System identification is a method of identifying or measuring the mathematical model of a system from measurements of the system inputs and outputs. The applications of system identification include any system where the inputs and outputs can be measured and include industrial processes, control systems, economic data, biology and the life sciences, medicine, social systems and many more.A nonlinear system is defined as any system that is not linear, that is any system that does not satisfy the superposition principle. This negative definition tends to obscure that there are very many different types of nonlinear systems. Historically, system identification for nonlinear systems has developed by focusing on specific classes of system and can be broadly categorised into four basic approaches, each defined by a model class, Volterra series models, block structured models, neural network models, and NARMAX models.
0.0.1.0.14	0.0.1.0	Estimate	Terminology	5	Numerical value assumed by an estimator for a specific sample. Therefore, it is a numerical value taken by a r.v.
0.0.1.0.15	0.0.1.0	Standard Error	Terminology	5	Put simply, the standard error of the sample mean is an estimate of how far the sample mean is likely to be from the population mean, whereas the standard deviation of the sample is the degree to which individuals within the sample differ from the sample mean. If the population standard deviation is finite, the standard error of the mean of the sample will tend to zero with increasing sample size, because the estimate of the population mean will improve, while the standard deviation of the sample will tend to approximate the population standard deviation as the sample size increases.
0.0.1.0.16	0.0.1.0	Pivotal quantity	Terminology	5	Let g ( X , θ ) {\displaystyle g(X,\theta )} be a random variable whose distribution is the same for all θ {\displaystyle \theta } . Then g {\displaystyle g} is called a pivotal quantity (or simply a pivot).
0.0.1.0.17	0.0.1.0	Extrapolation	Terminology	5	Extrapolation means creating a tangent line at the end of the known data and extending it beyond that limit. Linear extrapolation will only provide good results when used to extend the graph of an approximately linear function or not too far beyond the known data.
0.0.1.0.18	0.0.1.0	Interpolation	Terminology	5	In the mathematical field of numerical analysis, interpolation is a method of constructing new data points within the range of a discrete set of known data points.
0.0.1.0.19	0.0.1.0	Inequality	Terminology	5	Inequalities are useful for bounding quantities that might otherwise be hard to compute.They will also be used in the theory of convergence.
0.0.1.0.19.0	0.0.1.0.19	Cauchy-Schwarz	Inequality	6	In mathematics, the Cauchy–Schwarz inequality, also known as the Cauchy–Bunyakovsky–Schwarz inequality, is a useful inequality encountered in many different settings, such as linear algebra, analysis, probability theory, vector algebra and other areas. It is considered to be one of the most important inequalities in all of mathematics.  It has a number of generalizations, among them Hölder's inequality.
0.0.1.0.19.1	0.0.1.0.19	Chebyshev's	Inequality	6	In probability theory, Chebyshev's inequality (also spelled as Tchebysheff's inequality, also called Bienaymé-Chebyshev inequality) guarantees that, for a wide class of probability distributions, no more than a certain fraction of values can be more than a certain distance from the mean. Specifically, no more than 1/k2 of the distribution's values can be more than k standard deviations away from the mean (or equivalently, at least 1−1/k2 of the distribution's values are within k standard deviations of the mean). The rule is often called Chebyshev's theorem, about the range of standard deviations around the mean, in statistics. The inequality has great utility because it can be applied to any probability distribution in which the mean and variance are defined. For example, it can be used to prove the weak law of large numbers.
0.0.1.0.19.2	0.0.1.0.19	Markov	Inequality	6	In probability theory, Markov's inequality gives an upper bound for the probability that a non-negative function of a random variable is greater than or equal to some positive constant. It is named after the Russian mathematician Andrey Markov, although it appeared earlier in the work of Pafnuty Chebyshev (Markov's teacher), and many sources, especially in analysis, refer to it as Chebyshev's inequality (sometimes, calling it the first Chebyshev inequality, while referring to Chebyshev's inequality as the second Chebyshev's inequality) or Bienaymé's inequality.
0.0.1.0.19.3	0.0.1.0.19	Chernoff	Inequality	6	In probability theory, the Chernoff bound, named after Herman Chernoff but due to Herman Rubin, gives exponentially decreasing bounds on tail distributions of sums of independent random variables.
0.0.1.0.19.4	0.0.1.0.19	Jensen	Inequality	6	"In mathematics, Jensen's inequality, named after the Danish mathematician Johan Jensen, relates the value of a convex function of an integral to the integral of the convex function. It was proven by Jensen in 1906. Given its generality, the inequality appears in many forms depending on the context, some of which are presented below. In its simplest form the inequality states that the convex transformation of a mean is less than or equal to the mean applied after convex transformation; it is a simple corollary that the opposite is true of concave transformations."
0.0.1.0.20	0.0.1.0	Probability distribution	Terminology	5	The probability distributionis a theoretical concept, regarding the population, and should be considered a mathematical model of the reality (adjusted to the observed distribution) The probability of an event can be understood as the relative frequency of this event in a theoretical population model Random variable (r.v.) characteristic or attribute (X) of a population We use a lowercase letter xto designate a specific amount Xof the population
0.0.1.0.21	0.0.1.0	Frequency distribution	Terminology	5	The frequency distributionis an empirical concept that, in most cases, concerns a sample
0.0.1.0.22	0.0.1.0	Probabilistic model or probability distribution	Terminology	5	It is an algebraic expression that describes the relative frequency (height of the frequencies curve) for all possible values of the variable
0.0.1.0.23	0.0.1.0	Random variable	Terminology	5	characteristic or attribute (X) of a population
0.0.1.0.24	0.0.1.0	Point estimation	Terminology	5	Determining a numeric value which is intended to be best for a given population parameter based on the sample information
0.0.1.0.25	0.0.1.0	Interval estimation	Terminology	5	Construction of a range of real values that, with some degree of certainty previously stated, contains the true value of the population parameter
0.0.1.1	0.0.1	Frequentist inference	Inferential statistics	4	"Frequentist inference is a type of statistical inference that draws conclusions from sample data by emphasizing the frequency or proportion of the data. An alternative name is frequentist statistics. This is the inference framework in which the well-established methodologies of statistical hypothesis testing and confidence intervals are based. Other than frequentistic inference, the main alternative approach to statistical inference is Bayesian inference, while another is fiducial inference. While ""Bayesian inference"" is sometimes held to include the approach to inference leading to optimal decisions, a more restricted view is taken here for simplicity."
0.0.1.1.0	0.0.1.1	Point estimation Methods	Frequentist inference	5	"In statistics, point estimation involves the use of sample data to calculate a single value (known as a point estimate or statistic) which is to serve as a ""best guess"" or ""best estimate"" of an unknown population parameter (for example, the population mean). More formally, it is the application of a point estimator to the data to obtain a point estimate. Point estimation can be contrasted with interval estimation: such interval estimates are typically either confidence intervals in the case of frequentist inference, or credible intervals in the case of Bayesian inference."
0.0.1.1.0.0	0.0.1.1.0	Estimating equations	Point estimation Methods	6	In statistics, the method of estimating equations is a way of specifying how the parameters of a statistical model should be estimated. This can be thought of as a generalisation of many classical methods --- the method of moments, least squares, and maximum likelihood --- as well as some recent methods like M-estimators.
0.0.1.1.0.1	0.0.1.1.0	Maximum likelihood	Point estimation Methods	6	In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters. MLE can be seen as a special case of the maximum a posteriori estimation (MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized.
0.0.1.1.0.2	0.0.1.1.0	Method of moments	Point estimation Methods	6	In statistics, the method of moments is a method of estimation of population parameters. One starts with deriving equations that relate the population moments (i.e., the expected values of powers of the random variable under consideration) to the parameters of interest. Then a sample is drawn and the population moments are estimated from the sample.
0.0.1.1.0.3	0.0.1.1.0	M-estimator	Point estimation Methods	6	In statistics, M-estimators are a broad class of estimators, which are obtained as the minima of sums of functions of the data. Least-squares estimators are a special case of M-estimators. The definition of M-estimators was motivated by robust statistics, which contributed new types of M-estimators. The statistical procedure of evaluating an M-estimator on a data set is called M-estimation.
0.0.1.1.0.4	0.0.1.1.0	Minimum distance	Point estimation Methods	6	Minimum distance estimation (MDE) is a statistical method for fitting a mathematical model to data, usually the empirical distribution.
0.0.1.1.0.5	0.0.1.1.0	Unbiased estimators	Point estimation Methods	6	In statistics, the bias (or bias function) of an estimator is the difference between this estimator's expected value and the true value of the parameter being estimated. An estimator or decision rule with zero bias is called unbiased. Otherwise the estimator is said to be biased. In statistics,  bias  is an objective property of an estimator, and while not a desired property, it is not pejorative, unlike the ordinary English use of the term  bias .
0.0.1.1.0.6	0.0.1.1.0	Mean-unbiased minimum-variance	Point estimation Methods	6	In statistics a minimum-variance unbiased estimator (MVUE) or uniformly minimum-variance unbiased estimator (UMVUE) is an unbiased estimator that has lower variance than any other unbiased estimator for all possible values of the parameter.
0.0.1.1.0.7	0.0.1.1.0	Median unbiased	Point estimation Methods	6	Any mean-unbiased estimator minimizes the risk (expected loss) with respect to the squared-error loss function, as observed by Gauss. A median-unbiased estimator minimizes the risk with respect to the absolute-deviation loss function, as observed by Laplace. Other loss functions are used in statistical theory, particularly in robust statistics.
0.0.1.1.0.8	0.0.1.1.0	Plug-in	Point estimation Methods	6	"In statistics, the plug-in principle is the method of estimation of functionals of a population distribution by evaluating the same functionals at the empirical distribution based on a sample. The best example of the plug-in principle, the bootstrapping method. For example, when estimating the population mean, this method uses the sample mean; to estimate the population median, it uses the sample median; to estimate the population regression line, it uses the sample regression line."
0.0.1.1.1	0.0.1.1	Interval estimation Methods	Frequentist inference	5	"In statistics, interval estimation is the use of sample data to calculate an interval of plausible values of an unknown population parameter; this is in contrast to point estimation, which gives a single value. Jerzy Neyman (1937) identified interval estimation (""estimation by interval"") as distinct from point estimation (""estimation by unique estimate""). In doing so, he recognized that then-recent work quoting results in the form of an estimate plus-or-minus a standard deviation indicated that interval estimation was actually the problem statisticians really had in mind."
0.0.1.1.1.0	0.0.1.1.1	Interval Estimation	Interval estimation Methods	6	It is a common requirement to efficiently estimate population parameters based on simple random sample data.
0.0.1.1.1.0.0	0.0.1.1.1.0	Point Estimate of Population Mean	Interval Estimation	7	For any particular random sample, we can always compute its sample mean. Although most often it is not the actual population mean, it does serve as a good point estimate. For example, in the data set survey, the survey is performed on a sample of the student population. We can compute the sample mean and use it as an estimate of the corresponding population parameter.
0.0.1.1.1.0.1	0.0.1.1.1.0	Interval Estimate of Population Mean with Known Variance	Interval Estimation	7	Let us denote the 100(1 −α∕2) percentile of the standard normal distribution as zα∕2. For random sample of sufficiently large size, the end points of the interval estimate at (1 − α) confidence level is given as follows:
0.0.1.1.1.0.2	0.0.1.1.1.0	Interval Estimate of Population Mean with Unknown Variance	Interval Estimation	7	Let us denote the 100(1 −α∕2) percentile of the Student t distribution with n− 1 degrees of freedom as tα∕2. For random samples of sufficiently large size, and with standard deviation s, the end points of the interval estimate at (1 −α) confidence level
0.0.1.1.1.0.3	0.0.1.1.1.0	Sampling Size of Population Mean	Interval Estimation	7	The quality of a sample survey can be improved by increasing the sample size. The formula below provide the sample size needed under the requirement of population mean interval estimate at (1 −α) confidence level, margin of error E, and population variance σ2. Here, zα∕2 is the 100(1 − α∕2) percentile of the standard normal distribution.
0.0.1.1.1.0.4	0.0.1.1.1.0	Point Estimate of Population Proportion	Interval Estimation	7	Multiple choice questionnaires in a survey are often used to determine the proportion of a population with certain characteristic. For example, we can estimate the proportion of female students in the university based on the result in the sample data set survey.
0.0.1.1.1.0.5	0.0.1.1.1.0	Interval Estimate of Population Proportion	Interval Estimation	7	After we found a point sample estimate of the population proportion, we would need to estimate its confidence interval.  Let us denote the 100(1 −α∕2) percentile of the standard normal distribution as zα∕2. If the samples size n and population proportion p satisfy the condition that np ≥ 5 and n(1 − p) ≥ 5, than the end points of the interval estimate at (1 − α) confidence level is defined in terms of the sample proportion as follows.
0.0.1.1.1.0.6	0.0.1.1.1.0	Sampling Size of Population Proportion	Interval Estimation	7	The quality of a sample survey can be improved by increasing the sample size. The formula below provide the sample size needed under the requirement of population proportion interval estimate at (1 − α) confidence level, margin of error E, and planned proportion estimate p. Here, zα∕2 is the 100(1 − α∕2) percentile of the standard normal distribution
0.0.1.1.1.1	0.0.1.1.1	Pivot	Interval estimation Methods	6	In statistics, a pivotal quantity or pivot is a function of observations and unobservable parameters such that the function's probability distribution does not depend on the unknown parameters (including nuisance parameters). A pivot quantity need not be a statistic the function and its value can depend on the parameters of the model, but its distribution must not. If it is a statistic, then it is known as an ancillary statistic.
0.0.1.1.1.2	0.0.1.1.1	Likelihood interval	Interval estimation Methods	6	Suppose that the maximum likelihood estimate for θ is θ ^      {\displaystyle {\hat {\theta }}}  {\hat {\theta }}. Relative plausibilities of other θ values may be found by comparing the likelihood of those other values with the likelihood of θ ^      {\displaystyle {\hat {\theta }}}  {\hat {\theta }}. The relative likelihood of θ is defined[3][4] as   (θ | x) ∕  ( θ ^      {\displaystyle {\hat {\theta }}}  {\hat {\theta }} | x).
0.0.1.1.1.3	0.0.1.1.1	Prediction interval	Interval estimation Methods	6	In statistical inference, specifically predictive inference, a prediction interval is an estimate of an interval in which future observations will fall, with a certain probability, given what has already been observed. Prediction intervals are often used in regression analysis.
0.0.1.1.1.4	0.0.1.1.1	Resampling	Interval estimation Methods	6	1.Estimating the precision of sample 2.Exchanging labels on data points when performing significance tests 3.Validating models by using random subsets
0.0.1.1.1.5	0.0.1.1.1	Bootstrap	Interval estimation Methods	6	In statistics, bootstrapping is any test or metric that relies on random sampling with replacement. Bootstrapping allows assigning measures of accuracy (defined in terms of bias, variance, confidence intervals, prediction error or some other such measure) to sample estimates. This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods. Generally, it falls in the broader class of resampling methods.
0.0.1.1.1.6	0.0.1.1.1	Jackknife	Interval estimation Methods	6	In statistics, the jackknife is a resampling technique especially useful for variance and bias estimation. The jackknife predates other common resampling methods such as the bootstrap.
0.0.1.1.2	0.0.1.1	Hypothesis testing tests	Frequentist inference	5	A statistical hypothesis, sometimes called confirmatory data analysis, is a hypothesis that is testable on the basis of observing a process that is modeled via a set of random variables. A statistical hypothesis test is a method of statistical inference. Commonly, two statistical data sets are compared, or a data set obtained by sampling is compared against a synthetic data set from an idealized model. A hypothesis is proposed for the statistical relationship between the two data sets, and this is compared as an alternative to an idealized null hypothesis that proposes no relationship between two data sets. The comparison is deemed statistically significant if the relationship between the data sets would be an unlikely realization of the null hypothesis according to a threshold probability—the significance level. Hypothesis tests are used in determining what outcomes of a study would lead to a rejection of the null hypothesis for a pre-specified level of significance. The process of distinguishing between the null hypothesis and the alternative hypothesis is aided by identifying two conceptual types of errors, type 1 and type 2, and by specifying parametric limits on e.g. how much type 1 error will be permitted.
0.0.1.1.2.0	0.0.1.1.2	Hypothesis Testing	Hypothesis testing tests	6	A statistical hypothesis, sometimes called confirmatory data analysis, is a hypothesis that is testable on the basis of observing a process that is modeled via a set of random variables. A statistical hypothesis test is a method of statistical inference. Commonly, two statistical data sets are compared, or a data set obtained by sampling is compared against a synthetic data set from an idealized model. A hypothesis is proposed for the statistical relationship between the two data sets, and this is compared as an alternative to an idealized null hypothesis that proposes no relationship between two data sets. The comparison is deemed statistically significant if the relationship between the data sets would be an unlikely realization of the null hypothesis according to a threshold probability—the significance level. Hypothesis tests are used in determining what outcomes of a study would lead to a rejection of the null hypothesis for a pre-specified level of significance. The process of distinguishing between the null hypothesis and the alternative hypothesis is aided by identifying two conceptual types of errors, type 1 and type 2, and by specifying parametric limits on e.g. how much type 1 error will be permitted.
0.0.1.1.2.0.0	0.0.1.1.2.0	Lower Tail Test of Population Mean with Known Variance	Hypothesis Testing	7	μ ≥ μ0
0.0.1.1.2.0.1	0.0.1.1.2.0	Upper Tail Test of Population Mean with Known Variance	Hypothesis Testing	7	μ ≤ μ0
0.0.1.1.2.0.2	0.0.1.1.2.0	Two-Tailed Test of Population Mean with Known Variance	Hypothesis Testing	7	μ = μ0
0.0.1.1.2.0.3	0.0.1.1.2.0	Lower Tail Test of Population Mean with Unknown Variance	Hypothesis Testing	7	μ ≥ μ0
0.0.1.1.2.0.4	0.0.1.1.2.0	Upper Tail Test of Population Mean with Unknown Variance	Hypothesis Testing	7	μ ≤ μ0
0.0.1.1.2.0.5	0.0.1.1.2.0	Two-Tailed Test of Population Mean with Unknown Variance 	Hypothesis Testing	7	μ = μ0
0.0.1.1.2.0.6	0.0.1.1.2.0	Lower Tail Test of Population Proportion	Hypothesis Testing	7	p ≥ p0
0.0.1.1.2.0.7	0.0.1.1.2.0	Upper Tail Test of Population Proportion	Hypothesis Testing	7	p ≤ p0
0.0.1.1.2.0.8	0.0.1.1.2.0	Two-Tailed Test of Population Proportion	Hypothesis Testing	7	p = p0
0.0.1.1.2.1	0.0.1.1.2	Uniformly most powerful test	Hypothesis testing tests	6	In statistical hypothesis testing, a uniformly most powerful (UMP) test is a hypothesis test which has the greatest power β   {\displaystyle \beta }  \beta  among all possible tests of a given size α. For example, according to the Neyman–Pearson lemma, the likelihood-ratio test is UMP for testing simple (point) Hypothesis.
0.0.1.1.2.2	0.0.1.1.2	Permutation test	Hypothesis testing tests	6	A permutation test (also called a randomization test, re-randomization test, or an exact test) is a type of statistical significance test in which the distribution of the test statistic under the null hypothesis is obtained by calculating all possible values of the test statistic under rearrangements of the labels on the observed data points. In other words, the method by which treatments are allocated to subjects in an experimental design is mirrored in the analysis of that design.
0.0.1.1.2.3	0.0.1.1.2	Randomization test	Hypothesis testing tests	6	Resampling (statistics)
0.0.1.1.2.4	0.0.1.1.2	Multiple comparisons	Hypothesis testing tests	6	In statistics, the multiple comparisons, multiplicity or multiple testing problem occurs when one considers a set of statistical inferences simultaneously  or infers a subset of parameters selected based on the observed values.  In certain fields it is known as the look-elsewhere effect.
0.0.1.1.3	0.0.1.1	Sampling distributions	Frequentist inference	5	In statistics, a sampling distribution or finite-sample distribution is the probability distribution of a given random-sample-based statistic. If an arbitrarily large number of samples, each involving multiple observations (data points), were separately used in order to compute one value of a statistic (such as, for example, the sample mean or sample variance) for each sample, then the sampling distribution is the probability distribution of the values that the statistic takes on. In many contexts, only one sample is observed, but the sampling distribution can be found theoretically. Sampling distributions are important in statistics because they provide a major simplification en route to statistical inference. More specifically, they allow analytical considerations to be based on the probability distribution of a statistic, rather than on the joint probability distribution of all the individual sample values.
0.0.1.1.3.0	0.0.1.1.3	Sampling statistics	Sampling distributions	6	In statistics, quality assurance, and survey methodology, sampling is the selection of a subset (a statistical sample) of individuals from within a statistical population to estimate characteristics of the whole population.
0.0.1.1.3.1	0.0.1.1.3	Different samples of the same size produce different sample statistics values	Sampling distributions	6	Different samples of the same size produce different sample statistics values
0.0.1.1.3.2	0.0.1.1.3	Sampling distribution	Sampling distributions	6	The sampling distribution is the probability distribution of the sample statistic: All statistics have a sampling distribution. Some statistical values of a statistic are more likely to occur than others. The sampling distribution indicates the likelihood (probability) of obtaining certain values. The sampling distribution of a statistic can be described by parameters
0.0.1.1.3.3	0.0.1.1.3	Sampling error 	Sampling distributions	6	Sampling error is the difference between the estimate obtained from the sample and the corresponding unknown parameter of the population:θ^-θ
0.0.1.1.3.4	0.0.1.1.3	Central Limit Theorem (CLT)	Sampling distributions	6	"Let X1, X2, …, Xn be a random sample of n iid r.v. from a population with mean  and finite variance ; and X is the mean of this sample"
0.0.1.1.3.5	0.0.1.1.3	Distribution of the sampling mean – Case I	Sampling distributions	6	Suppose several samples of the same size are taken from a population , and that for each sample its mean is calculated. The standard deviation of the distribution of the mean, or any other sampling statistic, describes how the calculated means (statistics) differ from each other. The greater the standard deviation, the greater the difference between the calculated statistics
0.0.1.1.3.6	0.0.1.1.3	Distribution of the sampling mean – Case II	Sampling distributions	6	Suppose several samples of the same size are taken from a population , and that for each sample its mean is calculated. The standard deviation of the distribution of the mean, or any other sampling statistic, describes how the calculated means (statistics) differ from each other. The greater the standard deviation, the greater the difference between the calculated statistics
0.0.1.1.3.7	0.0.1.1.3	Distribution of the sampling mean – Case III	Sampling distributions	6	Suppose several samples of the same size are taken from a population , and that for each sample its mean is calculated. The standard deviation of the distribution of the mean, or any other sampling statistic, describes how the calculated means (statistics) differ from each other. The greater the standard deviation, the greater the difference between the calculated statistics
0.0.1.1.3.8	0.0.1.1.3	Distribution of the difference between means –Case I	Sampling distributions	6	If the variances of the two populations have equal values
0.0.1.1.3.9	0.0.1.1.3	Distribution of the difference between means – Case II	Sampling distributions	6	If the variances of the two populations have equal values
0.0.1.1.3.10	0.0.1.1.3	Distribution of the difference between means – Case III	Sampling distributions	6	If the variances of the two populations have equal values
0.0.1.1.3.11	0.0.1.1.3	Difference between means for paired samples (I)	Sampling distributions	6	When two samples are not independent they are said paired, i.e. The pairs of observations (xi,yi) are dependent and all other pairs (xi, yk), i k are independent
0.0.1.1.3.12	0.0.1.1.3	Difference between means for paired samples (II)	Sampling distributions	6	When two samples are not independent they are said paired, i.e. The pairs of observations (xi,yi) are dependent and all other pairs (xi, yk), i k are independent
0.0.1.1.3.13	0.0.1.1.3	Distribution of the sampling variance	Sampling distributions	6	The sampling variance is a statistic used to measure the variability of the sample and to estimate the population variance
0.0.1.1.3.14	0.0.1.1.3	Distribution of the ratio between sampling variances	Sampling distributions	6	The sampling variance is a statistic used to measure the variability of the sample and to estimate the population variance
0.0.1.1.3.15	0.0.1.1.3	Distribution of the sampling proportion	Sampling distributions	6	Indicates the proportion of successes (elements with the desired characteristic) in a sample of n independent r.v. drawn from a population with Bernoulli(p) distribution
0.0.1.1.3.16	0.0.1.1.3	Distribution of the difference between sampling proportions	Sampling distributions	6	Indicates the proportion of successes (elements with the desired characteristic) in a sample of n independent r.v. drawn from a population with Bernoulli(p) distribution
0.0.1.1.4	0.0.1.1	Point estimation	Frequentist inference	5	"In statistics, point estimation involves the use of sample data to calculate a single value (known as a point estimate or statistic) which is to serve as a ""best guess"" or ""best estimate"" of an unknown population parameter (for example, the population mean). More formally, it is the application of a point estimator to the data to obtain a point estimate. Point estimation can be contrasted with interval estimation: such interval estimates are typically either confidence intervals in the case of frequentist inference, or credible intervals in the case of Bayesian inference."
0.0.1.1.4.0	0.0.1.1.4	Notation and concepts	Point estimation	6	Notation and concepts
0.0.1.1.4.0.0	0.0.1.1.4.0	Point estimator	Notation and concepts	7	In statistics, point estimation involves the use of sample data to calculate a single value (known as a statistic) which is to serve as a best guess or best estimate of an unknown (fixed or random) population parameter. More formally, it is the application of a point estimator to the data.
0.0.1.1.4.0.1	0.0.1.1.4.0	Point estimate	Notation and concepts	7	Estimation (or estimating) is the process of finding an estimate, or approximation, which is a value that is usable for some purpose even if input data may be incomplete, uncertain, or unstable. The value is nonetheless usable because it is derived from the best information available.
0.0.1.1.4.1	0.0.1.1.4	The method of maximum likelihood	Point estimation	6	A statistical method for estimating population parameters (such as the mean and variance) from sample data that selects as estimates those parameter values maximizing the probability of obtaining the observed data.
0.0.1.1.5	0.0.1.1	Interval estimation	Frequentist inference	5	"In statistics, interval estimation is the use of sample data to calculate an interval of plausible values of an unknown population parameter; this is in contrast to point estimation, which gives a single value. Jerzy Neyman (1937) identified interval estimation (""estimation by interval"") as distinct from point estimation (""estimation by unique estimate""). In doing so, he recognized that then-recent work quoting results in the form of an estimate plus-or-minus a standard deviation indicated that interval estimation was actually the problem statisticians really had in mind."
0.0.1.1.5.0	0.0.1.1.5	Interval estimation	Interval estimation	6	"In statistics, interval estimation is the use of sample data to calculate an interval of plausible values of an unknown population parameter; this is in contrast to point estimation, which gives a single value. Jerzy Neyman (1937) identified interval estimation (""estimation by interval"") as distinct from point estimation (""estimation by unique estimate""). In doing so, he recognized that then-recent work quoting results in the form of an estimate plus-or-minus a standard deviation indicated that interval estimation was actually the problem statisticians really had in mind."
0.0.1.1.5.0.0	0.0.1.1.5.0	Confidence limits	Interval estimation	7	The confidence level is the frequency of possible confidence intervals that contain the true value of their corresponding parameter.
0.0.1.1.5.0.1	0.0.1.1.5.0	Confidence level	Interval estimation	7	Confidence limits are the numbers at the upper and lower end of a confidence interval
0.0.1.1.5.0.2	0.0.1.1.5.0	Significance level	Interval estimation	7	The null hypothesis is rejected if the p-value is less than a predetermined level, α. α is called the significance level, and is the probability of rejecting the null hypothesis given that it is true (a type I error). It is usually set at or below 5%.
0.0.1.1.5.0.3	0.0.1.1.5.0	Fulcral variable	Interval estimation	7	T=t(X1, X2,…,Xn | parameter) is called a fulcral variable if its probability distribution does not depend on parameter.
0.0.1.1.5.1	0.0.1.1.5	Confidence intervals for the mean	Interval estimation	6	In statistics, a confidence interval (CI) is a type of interval estimate, computed from the statistics of the observed data, that might contain the true value of an unknown population parameter. Most commonly, the 95% confidence level is used.
0.0.1.1.5.1.0	0.0.1.1.5.1	Absolute precision of the Confidence Interval	Confidence intervals for the mean	7	Corresponds to a measure of precision of the estimate of the population .
0.0.1.1.5.1.1	0.0.1.1.5.1	Relative precision of the Confidence Interval	Confidence intervals for the mean	7	The estimator will tend to have a small relative precision value at a given confidence level. (Small precision values are desirable.)
0.0.1.1.5.1.2	0.0.1.1.5.1	Case I	Confidence intervals for the mean	7	Suppose several samples of the same size are taken from a population , and that for each sample its mean is calculated. The standard deviation of the distribution of the mean, or any other sampling statistic, describes how the calculated means (statistics) differ from each other. The greater the standard deviation, the greater the difference between the calculated statistics
0.0.1.1.5.1.3	0.0.1.1.5.1	Case II	Confidence intervals for the mean	7	Suppose several samples of the same size are taken from a population , and that for each sample its mean is calculated. The standard deviation of the distribution of the mean, or any other sampling statistic, describes how the calculated means (statistics) differ from each other. The greater the standard deviation, the greater the difference between the calculated statistics
0.0.1.1.5.1.4	0.0.1.1.5.1	Case III	Confidence intervals for the mean	7	Suppose several samples of the same size are taken from a population , and that for each sample its mean is calculated. The standard deviation of the distribution of the mean, or any other sampling statistic, describes how the calculated means (statistics) differ from each other. The greater the standard deviation, the greater the difference between the calculated statistics
0.0.1.1.5.2	0.0.1.1.5	CI for the difference between means	Interval estimation	6	In statistics, a confidence interval (CI) is a type of interval estimate, computed from the statistics of the observed data, that might contain the true value of an unknown population parameter. ... Most commonly, the 95% confidence level is used.
0.0.1.1.5.2.0	0.0.1.1.5.2	Case I	CI for the difference between means	7	If the variances of the two populations have equal values
0.0.1.1.5.2.1	0.0.1.1.5.2	Case II	CI for the difference between means	7	If the variances of the two populations have equal values
0.0.1.1.5.2.2	0.0.1.1.5.2	Case III	CI for the difference between means	7	If the variances of the two populations have equal values
0.0.1.1.5.2.3	0.0.1.1.5.2	Case IV	CI for the difference between means	7	If the variances of the two populations have equal values
0.0.1.1.5.2.4	0.0.1.1.5.2	Case V	CI for the difference between means	7	If the variances of the two populations have equal values
0.0.1.1.5.2.5	0.0.1.1.5.2	Paired samples (I)	CI for the difference between means	7	If the variances of the two populations have equal values
0.0.1.1.5.2.6	0.0.1.1.5.2	Paired samples (II)	CI for the difference between means	7	If the variances of the two populations have equal values
0.0.1.1.5.2.7	0.0.1.1.5.2	Paired samples (III)	CI for the difference between means	7	If the variances of the two populations have equal values
0.0.1.1.5.3	0.0.1.1.5	CI for the variance	Interval estimation	6	The sampling variance is a statistic used to measure the variability of the sample and to estimate the population variance
0.0.1.1.5.4	0.0.1.1.5	CI for the ration between variances	Interval estimation	6	The sampling variance is a statistic used to measure the variability of the sample and to estimate the population variance
0.0.1.1.5.5	0.0.1.1.5	CI for the proportion	Interval estimation	6	Indicates the proportion of successes (elements with the desired characteristic) in a sample of n independent r.v. drawn from a population with Bernoulli(p) distribution
0.0.1.1.5.6	0.0.1.1.5	CI for the difference between proportions	Interval estimation	6	Indicates the proportion of successes (elements with the desired characteristic) in a sample of n independent r.v. drawn from a population with Bernoulli(p) distribution
0.0.1.1.6	0.0.1.1	Hypothesis testing	Frequentist inference	5	Hypothesis testing is an act in statistics whereby an analyst tests an assumption regarding a population parameter. The methodology employed by the analyst depends on the nature of the data used and the reason for the analysis. Hypothesis testing is used to infer the result of a hypothesis performed on sample data from a larger population.
0.0.1.1.6.0	0.0.1.1.6	Concepts and methodology	Hypothesis testing	6	Concepts and methodology
0.0.1.1.6.0.0	0.0.1.1.6.0	 H0: Null hypothesisis	Concepts and methodology	7	H0: Null hypothesisis a maintained hypothesis that is held true unless sufficient evidence to the contrary is obtained \\ Always contains an equality \\ It is the hypothesis that is accept by default, without proof
0.0.1.1.6.0.1	0.0.1.1.6.0	 H1: Alternativehypothesis	Concepts and methodology	7	H1: Alternativehypothesisis the hypothesis against which the null hypothesis is tested and which will be held to be true if the null hypothesis is held false \\ Always contains an inequality (>, <or \diff) \\ It is the hypothesis stated by the researcher, i.e. the one we believe is likely
0.0.1.1.6.0.2	0.0.1.1.6.0	 Parametric tests considered here	Concepts and methodolog	7	Parametric tests considered here
0.0.1.1.6.0.2.0	0.0.1.1.6.0.2	Two-Tailed test	 Parametric tests considered here	8	A two-tailed test is a statistical test in which the critical area of a distribution is two-sided and tests whether a sample is greater than or less than a certain range of values. If the sample being tested falls into either of the critical areas, the alternative hypothesis is accepted instead of the null hypothesis.
0.0.1.1.6.0.2.1	0.0.1.1.6.0.2	One-Tailed test (to the right)	 Parametric tests considered here	8	A one-tailed test is a statistical test in which the critical area of a distribution is one-sided so that it is either greater than or less than a certain value, but not both. If the sample being tested falls into the one-sided critical area, the alternative hypothesis will be accepted instead of the null hypothesis.
0.0.1.1.6.0.2.2	0.0.1.1.6.0.2	One-Tailed test (to the left)	 Parametric tests considered here	8	A one-tailed test is a statistical test in which the critical area of a distribution is one-sided so that it is either greater than or less than a certain value, but not both. If the sample being tested falls into the one-sided critical area, the alternative hypothesis will be accepted instead of the null hypothesis.
0.0.1.1.6.0.3	0.0.1.1.6.0	Type I and Type II errors	Concepts and methodology	7	Type I error: reject H0 when H0 is true \\ Type II error: accept H0 when H0 is false 
0.0.1.1.6.0.4	0.0.1.1.6.0	Significance level and power of the test	Concepts and methodology	7	Simultaneously minimize these two types of errors is increasing the sample size Neyman-Pearson approach to control the errors: \\ Fix the probability \alpha associated with Type I error \\ P(reject H0| H0true) = \alpha \\ Minimize the probability \beta associated with Type II error \\ (not reject H0| H0false) = \beta \\  \alpha is named significance level of the testand corresponds to the probability of committing a Type I error 1 –\ beta is named power of the testand corresponds to the probability of not committing a Type II error
0.0.1.1.6.0.5	0.0.1.1.6.0	Test statistic	Concepts and methodology	7	A test statisticis a function of the sample observations whose value will determine the conclusion from the statistical test. When we want to test the value of a parameter, the test statistic is usually an estimator of that parameter
0.0.1.1.6.0.6	0.0.1.1.6.0	Critical values	Concepts and methodology	7	Critical values determine the set of values of the test statistic that leads to rejection of the null hypothesis. This set of values is called the critical region or rejection region of the null hypothesis
0.0.1.1.6.0.7	0.0.1.1.6.0	Rejection region of the null hypothesis	Concepts and methodology	7	The rejection region of the null hypothesis is the region that, if the null hypothesis is true, contains the test statistic with probability. One rejects H0 if the observed value of the test statistic falls in the rejection region (i.e. the critical region)
0.0.1.1.6.0.8	0.0.1.1.6.0	P-value	Concepts and methodology	7	The p-valueis the smallest significance levelat which H0can be rejected with the observed sample. For any test with significance level equal to \alpha, If p-value \leq \alpha then H0 is rejected
0.0.1.1.6.1	0.0.1.1.6	Hypothesis testing for the mean	Hypothesis testing	6	The Hypothesis Testing is a statistical test used to determine whether the hypothesis assumed for the sample of data stands true for the entire population or not. Simply, the hypothesis is an assumption which is tested to determine the relationship between two data sets.
0.0.1.1.6.1.0	0.0.1.1.6.1	Case I	Hypothesis testing for the mean	7	Suppose several samples of the same size are taken from a population , and that for each sample its mean is calculated. The standard deviation of the distribution of the mean, or any other sampling statistic, describes how the calculated means (statistics) differ from each other. The greater the standard deviation, the greater the difference between the calculated statistics
0.0.1.1.6.1.1	0.0.1.1.6.1	Case II	Hypothesis testing for the mean	7	Suppose several samples of the same size are taken from a population , and that for each sample its mean is calculated. The standard deviation of the distribution of the mean, or any other sampling statistic, describes how the calculated means (statistics) differ from each other. The greater the standard deviation, the greater the difference between the calculated statistics
0.0.1.1.6.1.2	0.0.1.1.6.1	Case III	Hypothesis testing for the mean	7	Suppose several samples of the same size are taken from a population , and that for each sample its mean is calculated. The standard deviation of the distribution of the mean, or any other sampling statistic, describes how the calculated means (statistics) differ from each other. The greater the standard deviation, the greater the difference between the calculated statistics
0.0.1.1.6.2	0.0.1.1.6	Testing for the difference between means	Hypothesis testing	6	The mean difference (more correctly, 'difference in means') is a standard statistic that measures the absolute difference between the mean value in two groups in a clinical trial. It estimates the amount by which the experimental intervention changes the outcome on average compared with the control.
0.0.1.1.6.2.0	0.0.1.1.6.2	Case I	Testing for the difference between means	7	If the variances of the two populations
0.0.1.1.6.2.1	0.0.1.1.6.2	Case II	Testing for the difference between means	7	If the variances of the two populations
0.0.1.1.6.2.2	0.0.1.1.6.2	Case III	Testing for the difference between means	7	If the variances of the two populations
0.0.1.1.6.2.3	0.0.1.1.6.2	Case IV	Testing for the difference between means	7	If the variances of the two populations
0.0.1.1.6.2.4	0.0.1.1.6.2	Case V	Testing for the difference between means	7	If the variances of the two populations
0.0.1.1.6.2.5	0.0.1.1.6.2	Paired samples (I)	Testing for the difference between means	7	If the variances of the two populations
0.0.1.1.6.2.6	0.0.1.1.6.2	Paired samples (II)	Testing for the difference between means	7	If the variances of the two populations
0.0.1.1.6.2.7	0.0.1.1.6.2	Paired samples (III)	Testing for the difference between means	7	If the variances of the two populations
0.0.1.1.6.2.8	0.0.1.1.6.2	Paired samples (IIII)	Testing for the difference between means	7	If the variances of the two populations
0.0.1.1.6.3	0.0.1.1.6	Testing for the variance	Hypothesis testing	6	The sampling variance is a statistic used to measure the variability of the sample and to estimate the population variance
0.0.1.1.6.4	0.0.1.1.6	Testing for the ratio between variances	Hypothesis testing	6	The sampling variance is a statistic used to measure the variability of the sample and to estimate the population variance
0.0.1.1.6.5	0.0.1.1.6	Testing for the proportion	Hypothesis testing	6	A hypothesis test, or test of two contradictory potential solutions to a problem, used to draw inferences about the proportion of members of a population that have a specific characteristic.
0.0.1.1.6.6	0.0.1.1.6	Testing for the difference between proportions	Hypothesis testing	6	This tests for a difference in proportions. A two proportion z-test allows you to compare two proportions to see if they are the same. The null hypothesis (H0) for the test is that the proportions are the same. The alternate hypothesis (H1) is that the proportions are not the same.
0.0.1.1.6.6.0	0.0.1.1.6.6	Difference between proportions (I)	Testing for the difference between proportions	7	If the variances of the two populations
0.0.1.1.6.6.1	0.0.1.1.6.6	Difference between proportions (II)	Testing for the difference between proportions	7	If the variances of the two populations
0.0.1.1.6.7	0.0.1.1.6	Correlation coefficient	Hypothesis testing	6	A correlation coefficient is a numerical measure of some type of correlation, meaning a statistical relationship between two variables. Several types of correlation coefficient exist, each with their own definition and own range of usability and characteristics.
0.0.1.1.6.7.0	0.0.1.1.6.7	Case I	Correlation coefficient	7	Consider the population associated with the random pair (X, Y) with bivariate normal distribution,
0.0.1.1.6.7.1	0.0.1.1.6.7	Case II	Correlation coefficient	7	Consider the population associated with the random pair (X, Y) with bivariate normal distribution,
0.0.1.1.6.8	0.0.1.1.6	Protportion	Hypothesis testing	6	A hypothesis test, or test of two contradictory potential solutions to a problem, used to draw inferences about the proportion of members of a population that have a specific characteristic.
0.0.1.1.6.8.0	0.0.1.1.6.8	Case I	Protportion	7	Indicates the proportion of successes (elements with the desired characteristic) in a sample of n independent r.v. drawn from a population with Bernoulli(p) distribution
0.0.1.1.6.8.1	0.0.1.1.6.8	Case II	Protportion	7	Indicates the proportion of successes (elements with the desired characteristic) in a sample of n independent r.v. drawn from a population with Bernoulli(p) distribution
0.0.1.2	0.0.1	Tests 	Inferential statistics	4	List of tests:
0.0.1.2.0	0.0.1.2	Parametric tests	Tests 	5	In the literal meaning of the terms, a parametric statistical test is one that makes assumptions about the parameters (defining properties) of the population distribution(s) from which one's data are drawn, while a non-parametric test is one that makes no such assumptions.
0.0.1.2.0.0	0.0.1.2.0	Location tests	Parametric tests	6	Central location tests are a type of Quantitative research technique. They are product marketing tests performed in controlled environments, contrary to home-user tests, which take place where the products would actually be used. ... This marketing-related article is a stub.
0.0.1.2.0.0.0	0.0.1.2.0.0	One sample Z or t for mu	Location tests	7	A Z-test is any statistical test for which the distribution of the test statistic under the null hypothesis can be approximated by a normal distribution. ... Therefore, many statistical tests can be conveniently performed as approximate Z-tests if the sample size is large or the population variance is known.
0.0.1.2.0.0.0.0	0.0.1.2.0.0.0	Z (normal)	One sample Z or t for mu	8	A Z-test is any statistical test for which the distribution of the test statistic under the null hypothesis can be approximated by a normal distribution. Because of the central limit theorem, many test statistics are approximately normally distributed for large samples. For each significance level, the Z-test has a single critical value (for example, 1.96 for 5% two tailed) which makes it more convenient than the Student's t-test which has separate critical values for each sample size. Therefore, many statistical tests can be conveniently performed as approximate Z-tests if the sample size is large or the population variance is known. If the population variance is unknown (and therefore has to be estimated from the sample itself) and the sample size is not large (n <30), the Student's t-test may be more appropriate.
0.0.1.2.0.0.0.1	0.0.1.2.0.0.0	Student's t-test	One sample Z or t for mu	8	The t-test is any statistical hypothesis test in which the test statistic follows a Student's t-distribution under the null hypothesis. A t-test is most commonly applied when the test statistic would follow a normal distribution if the value of a scaling term in the test statistic were known. When the scaling term is unknown and is replaced by an estimate based on the data, the test statistics (under certain conditions) follow a Student's t distribution. The t-test can be used, for example, to determine if two sets of data are significantly different from each other.
0.0.1.2.0.0.1	0.0.1.2.0.0	Two independent samples Z or t for mu1-mu2	Location tests	7	A hypothesis test that is used to compare two sample groups to determine if they have originated from the same population. The two sample z-test requires the standard deviation to be known or the original size of the sample taken to be larger than 30, with a population that falls within a system of normal distribution
0.0.1.2.0.0.1.0	0.0.1.2.0.0.1	Z (normal)	Two independent samples Z or t for mu1-mu2	8	A Z-test is any statistical test for which the distribution of the test statistic under the null hypothesis can be approximated by a normal distribution. Because of the central limit theorem, many test statistics are approximately normally distributed for large samples. For each significance level, the Z-test has a single critical value (for example, 1.96 for 5% two tailed) which makes it more convenient than the Student's t-test which has separate critical values for each sample size. Therefore, many statistical tests can be conveniently performed as approximate Z-tests if the sample size is large or the population variance is known. If the population variance is unknown (and therefore has to be estimated from the sample itself) and the sample size is not large (n <30), the Student's t-test may be more appropriate.
0.0.1.2.0.0.1.1	0.0.1.2.0.0.1	Student's t-test	Two independent samples Z or t for mu1-mu2	8	The t-test is any statistical hypothesis test in which the test statistic follows a Student's t-distribution under the null hypothesis. A t-test is most commonly applied when the test statistic would follow a normal distribution if the value of a scaling term in the test statistic were known. When the scaling term is unknown and is replaced by an estimate based on the data, the test statistics (under certain conditions) follow a Student's t distribution. The t-test can be used, for example, to determine if two sets of data are significantly different from each other.
0.0.1.2.0.0.2	0.0.1.2.0.0	Two paired samples Z or t for muD	Location tests	7	In statistics, a paired difference test is a type of location test that is used when comparing two sets of measurements to assess whether their population means differ. ... The most familiar example of a paired difference test occurs when subjects are measured before and after a treatment.
0.0.1.2.0.0.2.0	0.0.1.2.0.0.2	Z (normal)	Two paired samples Z or t for muD	8	A Z-test is any statistical test for which the distribution of the test statistic under the null hypothesis can be approximated by a normal distribution. Because of the central limit theorem, many test statistics are approximately normally distributed for large samples. For each significance level, the Z-test has a single critical value (for example, 1.96 for 5% two tailed) which makes it more convenient than the Student's t-test which has separate critical values for each sample size. Therefore, many statistical tests can be conveniently performed as approximate Z-tests if the sample size is large or the population variance is known. If the population variance is unknown (and therefore has to be estimated from the sample itself) and the sample size is not large (n <30), the Student's t-test may be more appropriate.
0.0.1.2.0.0.2.1	0.0.1.2.0.0.2	Student's t-test	Two paired samples Z or t for muD	8	The t-test is any statistical hypothesis test in which the test statistic follows a Student's t-distribution under the null hypothesis. A t-test is most commonly applied when the test statistic would follow a normal distribution if the value of a scaling term in the test statistic were known. When the scaling term is unknown and is replaced by an estimate based on the data, the test statistics (under certain conditions) follow a Student's t distribution. The t-test can be used, for example, to determine if two sets of data are significantly different from each other.
0.0.1.2.0.0.3	0.0.1.2.0.0	Two or more independent samples ANOVA (F test)	Location tests	7	The one-way analysis of variance (ANOVA) is used to determine whether there are any statistically significant differences between the means of two or more independent (unrelated) groups (although you tend to only see it used when there are a minimum of three, rather than two groups).
0.0.1.2.0.0.3.0	0.0.1.2.0.0.3	F	Two or more independent samples ANOVA (F test)	8	An F-test is any statistical test in which the test statistic has an F-distribution under the null hypothesis. It is most often used when comparing statistical models that have been fitted to a data set, in order to identify the model that best fits the population from which the data were sampled. Exact  F-tests  mainly arise when the models have been fitted to the data using least squares. The name was coined by George W. Snedecor, in honour of Sir Ronald A. Fisher. Fisher initially developed the statistic as the variance ratio in the 1920s
0.0.1.2.0.0.3.1	0.0.1.2.0.0.3	Analysis of Variance (ANOVA) 	Two or more independent samples ANOVA (F test)	8	The one-way analysis of variance (ANOVA) is used to determine whether there are any statistically significant differences between the means of two or more independent (unrelated) groups (although you tend to only see it used when there are a minimum of three, rather than two groups).
0.0.1.2.0.0.3.1.0	0.0.1.2.0.0.3.1	Definitions	Analysis of Variance (ANOVA) 	9	General Definition
0.0.1.2.0.0.3.1.0.0	0.0.1.2.0.0.3.1.0	Experimental units	Definitions	10	Objects/subjects on which observations are made
0.0.1.2.0.0.3.1.0.1	0.0.1.2.0.0.3.1.0	Factor	Definitions	10	independent variable (characteristic) completely controlled in an experience, withk levels. \\ The different degrees of intensity, or different categories, of the factor are thelevels. \\ If the factor levels correspond to different intensities measured on a scale, the factor is said to be quantitative. \\ If the levels of a factor differ only in some characteristics, the factor is said to be qualitative
0.0.1.2.0.0.3.1.0.2	0.0.1.2.0.0.3.1.0	Groupor Treatment 	Definitions	10	Groupor Treatment: specific combination of factors’ levels. In case of one single factor, each group corresponds to a level of the factor.
0.0.1.2.0.0.3.1.1	0.0.1.2.0.0.3.1	One-way ANOVA with fixed effects 	Analysis of Variance (ANOVA) 	9	In statistics, a fixed effects model is a statistical model in which the model parameters are fixed or non-random quantities. This is in contrast to random effects models and mixed models in which all or some of the model parameters are considered as random variables. In many applications including econometrics and biostatistics a fixed effects model refers to a regression model in which the group means are fixed (non-random) as opposed to a random effects model in which the group means are a random sample from a population.[6] Generally, data can be grouped according to several observed factors. The group means could be modeled as fixed or random effects for each grouping. In a fixed effects model each group mean is a group-specific fixed quantity. In panel data where longitudinal observations exist for the same subject, fixed effects represent the subject-specific means. In panel data analysis the term fixed effects estimator (also known as the within estimator) is used to refer to an estimator for the coefficients in the regression model including those fixed effects (one time-invariant intercept for each subject).
0.0.1.2.0.0.3.1.1.0	0.0.1.2.0.0.3.1.1	One-way ANOVA	One-way ANOVA with fixed effects 	10	The only factor has k-levels.\\ Each group/treatment corresponds to a level of the factor. \\ ANOVA allows to compare the equality ofkpopulations’ means based on the samples obtained for each of the k groups/treatments
0.0.1.2.0.0.3.1.1.1	0.0.1.2.0.0.3.1.1	Fixed effects model	One-way ANOVA with fixed effects 	10	Case in which the levels of the factor are fixed, i.e. groups/treatments are fixed at the outset (in opposition to randomly determined).
0.0.1.2.0.0.3.1.1.2	0.0.1.2.0.0.3.1.1	Notation	One-way ANOVA with fixed effects 	10	Notation used
0.0.1.2.0.0.3.1.1.2.0	0.0.1.2.0.0.3.1.1.2	K Populations	Notation	11	No. of populations
0.0.1.2.0.0.3.1.1.2.1	0.0.1.2.0.0.3.1.1.2	Observations in populations	Notation	11	Number of observations of the i (population) level
0.0.1.2.0.0.3.1.1.2.2	0.0.1.2.0.0.3.1.1.2	Response variable	Notation	11	Response variable of the i (population) level for the experimental unit (individual) j
0.0.1.2.0.0.3.1.1.2.3	0.0.1.2.0.0.3.1.1.2	Population total	Notation	11	Total number of observations
0.0.1.2.0.0.3.1.1.2.4	0.0.1.2.0.0.3.1.1.2	Sample total	Notation	11	Sample total corresponding to the i (population) level
0.0.1.2.0.0.3.1.1.2.5	0.0.1.2.0.0.3.1.1.2	Sample mean	Notation	11	Sample mean corresponding to the i (population) level
0.0.1.2.0.0.3.1.1.2.6	0.0.1.2.0.0.3.1.1.2	Global sample mean	Notation	11	Global sample mean
0.0.1.2.0.0.3.1.1.2.7	0.0.1.2.0.0.3.1.1.2	Global sample variance	Notation	11	Global sample variance
0.0.1.2.0.0.3.1.1.2.8	0.0.1.2.0.0.3.1.1.2	Sample variance of populations	Notation	11	Sample variance of the i (population) level
0.0.1.2.0.0.3.1.1.2.9	0.0.1.2.0.0.3.1.1.2	Total deviations	Notation	11	Sum of squares of the total deviations around the global mean (total variability of responses)
0.0.1.2.0.0.3.1.1.2.10	0.0.1.2.0.0.3.1.1.2	Sum of squares of the deviations between	Notation	11	"Sum of squares of the deviations between the levels of the factor (variation due to the treatments; variation between groups)"
0.0.1.2.0.0.3.1.1.2.11	0.0.1.2.0.0.3.1.1.2	Sum of squares of the deviations within	Notation	11	"Sum of squares of the deviations within the levels of factor (variation due to error; variation within groups)"
0.0.1.2.0.0.3.1.1.2.12	0.0.1.2.0.0.3.1.1.2	Total variation	Notation	11	Total variation = Variation explained by the treatments + Variation due to error
0.0.1.2.0.0.3.1.1.2.13	0.0.1.2.0.0.3.1.1.2	Mean squares of the total deviations	Notation	11	Mean squares of the total deviations
0.0.1.2.0.0.3.1.1.2.14	0.0.1.2.0.0.3.1.1.2	Mean squares of the deviations between	Notation	11	Mean squares of the deviations between the levels of factor. If H0 is true, it is an unbiased estimator of the population variance with k-1 degrees of freedom
0.0.1.2.0.0.3.1.1.2.15	0.0.1.2.0.0.3.1.1.2	Mean squares of the deviations within	Notation	11	Mean squares of the deviations within the levels of factor. It is an unbiased estimator of the population variance with n-k degrees of freedom
0.0.1.2.0.0.3.1.1.2.16	0.0.1.2.0.0.3.1.1.2	F	Notation	11	An F-test is any statistical test in which the test statistic has an F-distribution under the null hypothesis. It is most often used when comparing statistical models that have been fitted to a data set, in order to identify the model that best fits the population from which the data were sampled.
0.0.1.2.0.0.3.1.1.3	0.0.1.2.0.0.3.1.1	Hypothesis	One-way ANOVA with fixed effects 	10	A statistical hypothesis is a hypothesis concerning the parameters or from of the probability distribution for a designated population or populations, or, more generally, of a probabilistic mechanism which is supposed to generate the observations.
0.0.1.2.0.0.3.1.1.4	0.0.1.2.0.0.3.1.1	Test statistic	One-way ANOVA with fixed effects 	10	A test statistic is a random variable that is calculated from sample data and used in a hypothesis test. You can use test statistics to determine whether to reject the null hypothesis. The test statistic compares your data with what is expected under the null hypothesis.
0.0.1.2.0.0.3.1.1.5	0.0.1.2.0.0.3.1.1	Decision rule	One-way ANOVA with fixed effects 	10	A decision rule is a procedure that the researcher uses to decide whether to accept or reject the null hypothesis . For example, a researcher might hypothesize that a population mean is equal to 10. He/she might collect a random sample of observations to test this hypothesis.
0.0.1.2.0.0.3.1.1.6	0.0.1.2.0.0.3.1.1	P-value	One-way ANOVA with fixed effects 	10	P Values. The P value, or calculated probability, is the probability of finding the observed, or more extreme, results when the null hypothesis (H 0) of a study question is true – the definition of 'extreme' depends on how the hypothesis is being tested.
0.0.1.2.0.0.3.1.1.7	0.0.1.2.0.0.3.1.1	Confidence interval for the mean	One-way ANOVA with fixed effects 	10	In statistics, a confidence interval (CI) is a type of interval estimate, computed from the statistics of the observed data, that might contain the true value of an unknown population parameter. Most commonly, the 95% confidence level is used.
0.0.1.2.0.0.3.1.1.8	0.0.1.2.0.0.3.1.1	Confidence interval for the difference of mean values	One-way ANOVA with fixed effects 	10	Confidence intervals for differences between means. Definition of confidence interval for difference between population means. Given two random samples, from two populations, two-sided confidence intervals with % coverage for the difference between the unknown population means, and , are shown in the table below.
0.0.1.2.0.0.3.1.2	0.0.1.2.0.0.3.1	 Normal populations	Analysis of Variance (ANOVA) 	9	Normal data are data that are drawn (come from) a population that has a normal distribution. This distribution is inarguably the most important and the most frequently used distribution in both the theory and application of statistics. If is a normal random variable, then the probability distribution of is.
0.0.1.2.0.0.3.1.2.0	0.0.1.2.0.0.3.1.2	Kolmogorov-Smirnov test	 Normal populations	10	In statistics, the Kolmogorov–Smirnov test (K–S test or KS test) is a nonparametric test of the equality of continuous, one-dimensional probability distributions that can be used to compare a sample with a reference probability distribution (one-sample K–S test), or to compare two samples (two-sample K–S test).
0.0.1.2.0.0.3.1.2.1	0.0.1.2.0.0.3.1.2	Shapiro-Wilk test	 Normal populations	10	The Shapiro-Wilks test for normality is one of three general normality tests designed to detect all departures from normality. It is comparable in power to the other two tests. The test rejects the hypothesis of normality when the p-value is less than or equal to 0.05.
0.0.1.2.0.0.3.1.3	0.0.1.2.0.0.3.1	Multiple comparison tests	Analysis of Variance (ANOVA) 	9	Multiple testing refers to any instance that involves the simultaneous testing of more than one hypothesis. In particular, recent developments based on resampling result in an improved ability to reject false hypotheses compared to classical methods such as Bonferroni.
0.0.1.2.0.0.3.1.3.0	0.0.1.2.0.0.3.1.3	Fisher's LSD test (Least Significant Difference)	Multiple comparison tests	10	The application of these t-tests simultaneously does not allow to control the global significance level. \\ Only suitable to obtain prior comparisons before the ANOVA
0.0.1.2.0.0.3.1.3.1	0.0.1.2.0.0.3.1.3	Tukey's HSD Test (Honestly Significant Difference)	Multiple comparison tests	10	Tukey's range test, also known as the Tukey's test, Tukey method, Tukey's honest significance test, Tukey's HSD (honest significant difference) test, or the Tukey–Kramer method, is a single-step multiple comparison procedure and statistical test.
0.0.1.2.0.0.3.1.3.2	0.0.1.2.0.0.3.1.3	Tukey-Kramer Test	Multiple comparison tests	10	Tukey's range test, also known as the Tukey's test, Tukey method, Tukey's honest significance test, Tukey's HSD (honest significant difference) test, or the Tukey–Kramer method, is a single-step multiple comparison procedure and statistical test.
0.0.1.2.0.0.3.1.3.3	0.0.1.2.0.0.3.1.3	Scheffé’s test	Multiple comparison tests	10	The Scheffe Test (also called Scheffe’s procedure or Scheffe’s method) is a post-hoc test used in Analysis of Variance. It is named for the American statistician Henry Scheffe. After you have run ANOVA and got a significant F-statistic (i.e. you have rejected the null hypothesis that the means are the same), then you run Sheffe’s test to find out which pairs of means are significant. The Scheffe test corrects alpha for simple and complex mean comparisons. Complex mean comparisons involve comparing more than one pair of means simultaneously.
0.0.1.2.0.0.3.1.3.4	0.0.1.2.0.0.3.1.3	Multiple comparison tests: observations	Multiple comparison tests	10	Observations
0.0.1.2.0.1	0.0.1.2.0	Tests of scale	Parametric tests	6	Scalability testing, is the testing of a software application to measure its capability to scale up or scale out in terms of any of its non-functional capability. Performance, scalability and reliability testing are usually grouped together by software quality analysts.
0.0.1.2.0.1.0	0.0.1.2.0.1	Two paired samples	Tests of scale	7	Paired samples (also called dependent samples) are samples in which natural or matched couplings occur. This generates a data set in which each data point in one sample is uniquely paired to a data point in the second sample.
0.0.1.2.0.1.0.0	0.0.1.2.0.1.0	F for the ratio of two variances	Two paired samples	8	An F-test is any statistical test in which the test statistic has an F-distribution under the null hypothesis. It is most often used when comparing statistical models that have been fitted to a data set, in order to identify the model that best fits the population from which the data were sampled. Exact  F-tests  mainly arise when the models have been fitted to the data using least squares. The name was coined by George W. Snedecor, in honour of Sir Ronald A. Fisher. Fisher initially developed the statistic as the variance ratio in the 1920s
0.0.1.2.0.1.0.1	0.0.1.2.0.1.0	Bartlett’s test	Two paired samples	8	Bartlett's test is sensitive to departures from normality. That is, if the samples come from non-normal distributions, then Bartlett's test may simply be testing for non-normality. Levene's test and the Brown–Forsythe test are alternatives to the Bartlett test that are less sensitive to departures from normality
0.0.1.2.0.1.0.2	0.0.1.2.0.1.0	Levene’s test	Two paired samples	8	Levene's test is an inferential statistic used to assess the equality of variances for a variable calculated for two or more groups. Some common statistical procedures assume that variances of the populations from which different samples are drawn are equal. Levene's test assesses this assumption. It tests the null hypothesis that the population variances are equal (called homogeneity of variance or homoscedasticity). If the resulting p-value of Levene's test is less than some significance level (typically 0.05), the obtained differences in sample variances are unlikely to have occurred based on random sampling from a population with equal variances. Thus, the null hypothesis of equal variances is rejected and it is concluded that there is a difference between the variances in the population.
0.0.1.2.0.2	0.0.1.2.0	Association	Parametric tests	6	"The measures of association refer to a wide variety of coefficients that measure the statistical strength of the relationship on the variables of interest; these measures of strength, or association, can be described in several ways, depending on the analysis."
0.0.1.2.0.2.0	0.0.1.2.0.2	One sample	Association	7	One sample
0.0.1.2.0.2.0.0	0.0.1.2.0.2.0	Pearson's correlation test	One sample	8	Pearson correlation coefficient , also referred to as Pearson's r, the Pearson product-moment correlation coefficient (PPMCC) or the bivariate correlation,[1] is a measure of the linear correlation between two variables X and Y. It has a value between +1 and −1, where 1 is total positive linear correlation, 0 is no linear correlation, and −1 is total negative linear correlation. It is widely used in the sciences. It was developed by Karl Pearson from a related idea introduced by Francis Galton in the 1880s
0.0.1.2.0.2.0.1	0.0.1.2.0.2.0	Simple linear regression (F test)	One sample	8	In statistics, simple linear regression is a linear regression model with a single explanatory variable. That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variables. The adjective simple refers to the fact that the outcome variable is related to a single predictor.
0.0.1.2.1	0.0.1.2	Non-parametric tests	Tests 	5	Nonparametric statistics refer to a statistical method in which the data is not required to fit a normal distribution. Nonparametric statistics uses data that is often ordinal, meaning it does not rely on numbers, but rather a ranking or order of sorts.
0.0.1.2.1.0	0.0.1.2.1	Location tests	Non-parametric tests	6	Central location tests are a type of Quantitative research technique. They are product marketing tests performed in controlled environments, contrary to home-user tests, which take place where the products would actually be used. This marketing-related article is a stub.
0.0.1.2.1.0.0	0.0.1.2.1.0	One sample	Location tests	7	One sample
0.0.1.2.1.0.0.0	0.0.1.2.1.0.0	Test of signals	One sample	8	The sign test is a statistical method to test for consistent differences between pairs of observations, such as the weight of subjects before and after treatment. Given pairs of observations (such as weight pre- and post-treatment) for each subject, the sign test determines if one member of the pair (such as pre-treatment) tends to be greater than (or less than) the other member of the pair (such as post-treatment).The paired observations may be designated x and y. For comparisons of paired observations (x,y), the sign test is most useful if comparisons can only be expressed as x > y, x = y, or x <y. If, instead, the observations can be expressed as numeric quantities (x = 7, y = 18), or as ranks (rank of x = 1st, rank of y = 8th), then the paired t-test[1] or the Wilcoxon signed-rank test[2] will usually have greater power than the sign test to detect consistent differences.
0.0.1.2.1.0.0.1	0.0.1.2.1.0.0	Wilcoxon signed-ranks test	One sample	8	The Wilcoxon signed-rank test is a non-parametric statistical hypothesis test used when comparing two related samples, matched samples, or repeated measurements on a single sample to assess whether their population mean ranks differ (i.e. it is a paired difference test). It can be used as an alternative to the paired Student's t-test, t-test for matched pairs, or the t-test for dependent samples when the population cannot be assumed to be normally distributed. A Wilcoxon signed-rank test is a nonparametric test that can be used to determine whether two dependent samples were selected from populations having the same distribution.
0.0.1.2.1.0.0.2	0.0.1.2.1.0.0	Van der Waerden’stest (Normal scores)	One sample	8	Named after the Dutch mathematician Bartel Leendert van der Waerden, the Van der Waerden test is a statistical test that k population distribution functions are equal. The Van der Waerden test converts the ranks from a standard Kruskal-Wallis one-way analysis of variance to quantiles of the standard normal distribution (details given below). These are called normal scores and the test is computed from these normal scores.
0.0.1.2.1.0.1	0.0.1.2.1.0	Two independent samples	Location tests	7	Two independent samples
0.0.1.2.1.0.1.0	0.0.1.2.1.0.1	Wilcoxon–Mann–Whitney test	Two independent samples	8	In statistics, the Mann–Whitney U test (also called the Mann–Whitney–Wilcoxon (MWW), Wilcoxon rank-sum test, or Wilcoxon–Mann–Whitney test) is a nonparametric test of the null hypothesis that it is equally likely that a randomly selected value from one sample will be less than or greater than a randomly selected value from a second sample. Unlike the t-test it does not require the assumption of normal distributions. It is nearly as efficient as the t-test on normal distributions.
0.0.1.2.1.0.1.1	0.0.1.2.1.0.1	Conover’s test	Two independent samples	8	"Computes the Conover-Iman test (1979) for stochastic dominance and reports the results among multiple pairwise comparisons after a Kruskal-Wallis test for stochastic dominance among k groups (Kruskal and Wallis, 1952). The interpretation of stochastic dominance requires an assumption that the CDF of one group does not cross the CDF of the other. conover.test makes k(k1)/2 multiple pairwise comparisons based on Conover-Iman t-test-statistic of the rank differences. The null hypothesis for each pairwise comparison is that the probability of observing a randomly selected value from the first group that is larger than a randomly selected value from the second group equals one half; this null hypothesis corresponds to that of the Wilcoxon-MannWhitney rank-sum test. Like the rank-sum test, if the data can be assumed to be continuous, and the distributions are assumed identical except for a difference in location, ConoverIman test may be understood as a test for median difference. conover.test accounts for tied ranks. The Conover-Iman test is strictly valid if and only if the corresponding Kruskal-Wallis null hypothesis is rejected."
0.0.1.2.1.0.2	0.0.1.2.1.0	Two paired samples	Location tests	7	Two paired samples
0.0.1.2.1.0.2.0	0.0.1.2.1.0.2	Test of signals	Two paired samples	8	The sign test is a statistical method to test for consistent differences between pairs of observations, such as the weight of subjects before and after treatment. Given pairs of observations (such as weight pre- and post-treatment) for each subject, the sign test determines if one member of the pair (such as pre-treatment) tends to be greater than (or less than) the other member of the pair (such as post-treatment).The paired observations may be designated x and y. For comparisons of paired observations (x,y), the sign test is most useful if comparisons can only be expressed as x > y, x = y, or x <y. If, instead, the observations can be expressed as numeric quantities (x = 7, y = 18), or as ranks (rank of x = 1st, rank of y = 8th), then the paired t-test[1] or the Wilcoxon signed-rank test[2] will usually have greater power than the sign test to detect consistent differences.
0.0.1.2.1.0.2.1	0.0.1.2.1.0.2	Wilcoxon signed-ranks test (two sample median test)	Two paired samples	8	The Wilcoxon signed-rank test is a non-parametric statistical hypothesis test used when comparing two related samples, matched samples, or repeated measurements on a single sample to assess whether their population mean ranks differ (i.e. it is a paired difference test). It can be used as an alternative to the paired Student's t-test, t-test for matched pairs, or the t-test for dependent samples when the population cannot be assumed to be normally distributed. A Wilcoxon signed-rank test is a nonparametric test that can be used to determine whether two dependent samples were selected from populations having the same distribution.
0.0.1.2.1.0.2.2	0.0.1.2.1.0.2	McNemar’stest	Two paired samples	8	In statistics, McNemar,s test is a statistical test used on paired nominal data. It is applied to 2 × 2 contingency tables with a dichotomous trait, with matched pairs of subjects, to determine whether the row and column marginal frequencies are equal (that is, whether there is marginal homogeneity). It is named after Quinn McNemar, who introduced it in 1947. An application of the test in genetics is the transmission disequilibrium test for detecting linkage disequilibrium.
0.0.1.2.1.0.3	0.0.1.2.1.0	Three or more independent samples	Location tests	7	Three or more independent samples
0.0.1.2.1.0.3.0	0.0.1.2.1.0.3	Kruskal-Wallis test	Three or more independent samples	8	Consists on applying the ANOVA to the ranks of the observations (Wilcoxon scores)
0.0.1.2.1.0.4	0.0.1.2.1.0	Three or more dependent samples	Location tests	7	Three or more independent samples
0.0.1.2.1.0.4.0	0.0.1.2.1.0.4	Friedman’s test	Three or more dependent samples	8	The Friedman test is a non-parametric statistical test developed by Milton Friedman. Similar to the parametric repeated measures ANOVA, it is used to detect differences in treatments across multiple test attempts. The procedure involves ranking each row (or block) together, then considering the values of ranks by columns. Applicable to complete block designs, it is thus a special case of the Durbin test.
0.0.1.2.1.1	0.0.1.2.1	Tests of scale	Non-parametric tests	6	Tests of scale
0.0.1.2.1.1.0	0.0.1.2.1.1	Two or more independent samples	Tests of scale	7	Two or more independent samples
0.0.1.2.1.1.0.0	0.0.1.2.1.1.0	Siegel-Tukey test	Two or more independent samples	8	In statistics, the Siegel–Tukey test, named after Sidney Siegel and John Tukey, is a non-parametric test which may be applied to data measured at least on an ordinal scale. It tests for differences in scale between two groups. The test is used to determine if one of two groups of data tends to have more widely dispersed values than the other. In other words, the test determines whether one of the two groups tends to move, sometimes to the right, sometimes to the left, but away from the center (of the ordinal scale).
0.0.1.2.1.1.0.1	0.0.1.2.1.1.0	Ansari-Bradley test	Two or more independent samples	8	The Ansari-Bradley test is a nonparametric alternative to the two-sample F-test of equal variances. This test requires that the samples have equal medians. Under that assumption, and if the distributions of the samples are continuous and identical, the test is independent of the distributions.
0.0.1.2.1.1.0.2	0.0.1.2.1.1.0	Klotz’s test	Two or more independent samples	8	The advantage of many tests based on normal scores is that they perform well when the assumptions of the standard parametric test are satisfied while still providing protection when the assumptions are not satisfied.
0.0.1.2.1.1.0.3	0.0.1.2.1.1.0	Mood’s test	Two or more independent samples	8	In statistics, Mood's median test is a special case of Pearson's chi-squared test. It is a nonparametric test that tests the null hypothesis that the medians of the populations from which two or more samples are drawn are identical.
0.0.1.2.1.1.0.4	0.0.1.2.1.1.0	Conover’stest	Two or more independent samples	8	Conover (1999) present a nonparametric test of homogeneity (equal variance) based on ranks. The test does not assume that all populations are normally distributed and is recommended hen the normality assumption is not viable.
0.0.1.2.1.1.0.5	0.0.1.2.1.1.0	Fligner´stest	Two or more independent samples	8	Performs a Fligner-Killeen (median) test of the null that the variances in each of the groups (samples) are the same.
0.0.1.2.1.1.0.6	0.0.1.2.1.1.0	Taha_test	Two or more independent samples	8	Taha test
0.0.1.2.1.2	0.0.1.2.1	Association	Non-parametric tests	6	Association
0.0.1.2.1.2.0	0.0.1.2.1.2	0.0.1.2.1.2.0 two paired samples	Association	7	Two paired samples
0.0.1.2.1.2.0.0	0.0.1.2.1.2.0	Spearman’s rank correlation test	0.0.1.2.1.2.0 two paired samples	8	"In statistics, Spearman's rank correlation coefficient or Spearman's rho, named after Charles Spearman is a nonparametric measure of rank correlation (statistical dependence between the rankings of two variables). It assesses how well the relationship between two variables can be described using a monotonic function. The Spearman correlation between two variables is equal to the Pearson correlation between the rank values of those two variables; while Pearson's correlation assesses linear relationships, Spearman's correlation assesses monotonic relationships (whether linear or not). If there are no repeated data values, a perfect Spearman correlation of +1 or −1 occurs when each of the variables is a perfect monotone function of the other."
0.0.1.2.1.2.0.1	0.0.1.2.1.2.0	Kendall's tau-b	0.0.1.2.1.2.0 two paired samples	8	A variation of the definition of the Kendall correlation coefficient is necessary in order to deal with data samples with tied ranks. It known as the Kendall’s tau-b coefficient and is more effective in determining whether two non-parametric data samples with ties are correlated. Formally, the Kendall’s tau-b is defined as follows. It replaces the denominator of the original definition with the product of square roots of data pair counts not tied in the target features.
0.0.1.2.1.2.0.2	0.0.1.2.1.2.0	Chi 2 Independence test	0.0.1.2.1.2.0 two paired samples	8	This lesson explains how to conduct a chi-square test for independence. The test is applied when you have two categorical variables from a single population. It is used to determine whether there is a significant association between the two variables.
0.0.1.2.1.3	0.0.1.2.1	Homogeneity	Non-parametric tests	6	A test of homogeneity tests the null hypothesis that different popu- lations have the same proportions of some characteristics. The key difference from the test of independence is that there are multiple populations that the data is drawn from.
0.0.1.2.1.3.0	0.0.1.2.1.3	One sample	Homogeneity	7	One sample
0.0.1.2.1.3.0.0	0.0.1.2.1.3.0	Chi 2 Homogeneity test	One sample	8	The test is applied to a single categorical variable from two or more different populations. It is used to determine whether frequency counts are distributed identically across different populations.
0.0.1.2.1.3.0.1	0.0.1.2.1.3.0	Mann-Kendall trend test(Kendall's tau-statistic)	One sample	8	The Mann-Kendall trend test is a non parametric way to detect a trend in a series of values. Available in Excel using the XLSTAT statistical software. Mann-Kendall trend test is a nonparametric test used to identify a trend in a series
0.0.1.2.1.3.0.2	0.0.1.2.1.3.0	Wald-Wolfowitz one-sample runs test	One sample	8	The Wald–Wolfowitz runs test (or simply runs test), named after Abraham Wald and Jacob Wolfowitz, is a non-parametric statistical test that checks a randomness hypothesis for a two-valued data sequence. More precisely, it can be used to test the hypothesis that the elements of the sequence are mutually independent.
0.0.1.2.1.3.0.3	0.0.1.2.1.3.0	Von Neumann’s ratio test	One sample	8	The rank von Neumann ratio test for randomness provides an easy and powerful alternative to nonparametric tests now in common use.
0.0.1.2.1.4	0.0.1.2.1	Godness of fit (Adjustment tests)	Non-parametric tests	6	The goodness of fit of a statistical model describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model in question.
0.0.1.2.1.4.0	0.0.1.2.1.4	Chi-Square test	Godness of fit (Adjustment tests)	7	Printer-friendly version. Chi-Square Test of Independence. Do you remember how to test the independence of two categorical variables? This test is performed by using a Chi-square test of independence.
0.0.1.2.1.4.1	0.0.1.2.1.4	Kolmogorov-Smirnov test	Godness of fit (Adjustment tests)	7	In statistics, the Kolmogorov–Smirnov test (K–S test or KS test) is a nonparametric test of the equality of continuous, one-dimensional probability distributions that can be used to compare a sample with a reference probability distribution (one-sample K–S test), or to compare two samples (two-sample K–S test).
0.0.1.2.1.4.2	0.0.1.2.1.4	Shapiro-Wilk test	Godness of fit (Adjustment tests)	7	The Shapiro-Wilks test for normality is one of three general normality tests designed to detect all departures from normality. It is comparable in power to the other two tests. The test rejects the hypothesis of normality when the p-value is less than or equal to 0.05.
0.0.1.2.1.5	0.0.1.2.1	Check if identical distributions 	Non-parametric tests	6	Check if identical distributions 
0.0.1.2.1.5.0	0.0.1.2.1.5	Two independent samples	Check if identical distributions 	7	Two independent samples
0.0.1.2.1.5.0.0	0.0.1.2.1.5.0	 Kuiper’stest	Two independent samples	8	Kuiper's test is closely related to the better-known Kolmogorov–Smirnov test (or K-S test as it is often called). As with the K-S test, the discrepancy statistics D+ and D− represent the absolute sizes of the most positive and most negative differences between the two cumulative distribution functions that are being compared. The trick with Kuiper's test is to use the quantity D+ + D− as the test statistic. This small change makes Kuiper's test as sensitive in the tails as at the median and also makes it invariant under cyclic transformations of the independent variable. The Anderson–Darling test is another test that provides equal sensitivity at the tails as the median, but it does not provide the cyclic invariance.
0.0.1.2.1.5.0.1	0.0.1.2.1.5.0	Location tests	Two independent samples	8	Location tests
0.0.1.2.1.5.1	0.0.1.2.1.5	Two or more independent samples	Check if identical distributions 	7	Two or more independent samples
0.0.1.2.1.5.1.0	0.0.1.2.1.5.1	Kolmogorov-Smirnov test	Two or more independent samples	8	In statistics, the Kolmogorov-Smirnov test test (K-S test or KS test) is a nonparametric test of the equality of continuous, one-dimensional probability distributions that can be used to compare a sample with a reference probability distribution (one-sample K-S test), or to compare two samples (two-sample K-S test).
0.0.1.2.1.5.1.1	0.0.1.2.1.5.1	Cramer-von Mises test	Two or more independent samples	8	A non-parametric test for testing a hypothesis  which states that independent and identically-distributed random variables  have a given continuous distribution function . 
0.0.1.2.1.6	0.0.1.2.1	Verify if two or more groups of observations are independent	Non-parametric tests	6	Verify if two or more groups of observations are independent
0.0.1.2.1.6.0	0.0.1.2.1.6	Two or more samples	Verify if two or more groups of observations are independent	7	Two or more samples
0.0.1.2.1.6.0.0	0.0.1.2.1.6.0	Fisher's exact test	Two or more samples	8	Fisher's exact test is a statistical significance test used in the analysis of contingency tables. Although in practice it is employed when sample sizes are small, it is valid for all sample sizes.
0.0.1.2.1.7	0.0.1.2.1	Comparison of two populations with paired samples	Non-parametric tests	6	Comparison of two populations with paired samples
0.0.1.2.1.7.0	0.0.1.2.1.7	Wilcoxon signed-ranks test	Comparison of two populations with paired samples	7	The Wilcoxon signed-rank test is a non-parametric statistical hypothesis test used when comparing two related samples, matched samples, or repeated measurements on a single sample to assess whether their population mean ranks differ (i.e. it is a paired difference test). It can be used as an alternative to the paired Student's t-test, t-test for matched pairs, or the t-test for dependent samples when the population cannot be assumed to be normally distributed. A Wilcoxon signed-rank test is a nonparametric test that can be used to determine whether two dependent samples were selected from populations having the same distribution.
0.0.1.3	0.0.1	Bayesian inference	Inferential statistics	4	Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics. Bayesian updating is particularly important in the dynamic analysis of a sequence of data. Bayesian inference has found application in a wide range of activities, including science, engineering, philosophy, medicine, sport, and law. In the philosophy of decision theory, Bayesian inference is closely related to subjective probability, often called  Bayesian probability .
0.0.2	0.0	Probability theory	Summarizing	3	Probability theory is the branch of mathematics concerned with probability. Although there are several different probability interpretations, probability theory treats the concept in a rigorous mathematical manner by expressing it through a set of axioms.
0.0.2.0	0.0.2	Probability distributions	Probability theory	4	The probability distribution is a description of a random phenomenon in terms of the probabilities of events. Examples of random phenomena can include the results of an experiment or survey. A probability distribution is defined in terms of an underlying sample space, which is the set of all possible outcomes of the random phenomenon being observed. The sample space may be the set of real numbers or a higher-dimensional vector space, or it may be a list of non-numerical values. the probability distribution is a description of a random phenomenon in terms of the probabilities of events. Examples of random phenomena can include the results of an experiment or survey. A probability distribution is defined in terms of an underlying sample space, which is the set of all possible outcomes of the random phenomenon being observed. The sample space may be the set of real numbers or a higher-dimensional vector space, or it may be a list of non-numerical values
0.0.2.1	0.0.2	Probability distribution function	Probability theory	4	In probability theory, a probability density function (PDF), or density of a continuous random variable, is a function, whose value at any given sample (or point) in the sample space (the set of possible values taken by the random variable) can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample.[citation needed] In other words, while the absolute likelihood for a continuous random variable to take on any particular value is 0 (since there are an infinite set of possible values to begin with), the value of the PDF at two different samples can be used to infer, in any particular draw of the random variable, how much more likely it is that the random variable would equal one sample compared to the other sample.
0.0.2.1.0	0.0.2.1	Cumulative distribution function	Probability distribution function	5	The cumulative distribution function (CDF) of a real-valued random variable X, or just distribution function of X, evaluated at x, is the probability that X will take a value less than or equal to x.
0.0.2.1.1	0.0.2.1	Probability mass function	Probability distribution function	5	In probability and statistics, a probability mass function (pmf) is a function that gives the probability that a discrete random variable is exactly equal to some value.  The probability mass function is often the primary means of defining a discrete probability distribution, and such functions exist for either scalar or multivariate random variables whose domain is discrete.
0.0.2.1.2	0.0.2.1	Probability density function	Probability distribution function	5	In probability theory, a probability density function (PDF), or density of a continuous random variable, is a function, whose value at any given sample (or point) in the sample space (the set of possible values taken by the random variable) can be interpreted as providing a relative likelihood that the value of the random variable would equal that sample.
0.0.2.2	0.0.2	Discrete probability distribution	Probability theory	4	A discrete probability distribution is a probability distribution characterized by a probability mass function. Thus, the distribution of a random variable X is discrete, and X is called a discrete random variable, if {\displaystyle \sum _{u}\operatorname {P} (X=u)=1} {\displaystyle \sum _{u}\operatorname {P} (X=u)=1} as u runs through the set of all possible values of X. A discrete random variable can assume only a finite or countably infinite number of values. For the number of potential values to be countably infinite, even though their probabilities sum to 1, the probabilities have to decline to zero fast enough.
0.0.2.2.0	0.0.2.2	Poisson distribution	Discrete probability distribution	5	Is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event.  The Poisson distribution can also be used for the number of events in other specified intervals such as distance, area or volume.
0.0.2.2.1	0.0.2.2	Bernoulli distribution	Discrete probability distribution	5	"In probability theory and statistics, the Bernoulli distribution, named after Swiss mathematician Jacob Bernoulli,  is the probability distribution of a random variable which takes the value 1 with probability {\displaystyle p} p and the value 0 with probability {\displaystyle q=1-p} q=1-p — i.e., the probability distribution of any single experiment that asks a yes–no question; the question results in a boolean-valued outcome, a single bit of information whose value is success/yes/true/one with probability p and failure/no/false/zero with probability q. It can be used to represent a coin toss where 1 and 0 would represent  head  and  tail  (or vice versa), respectively. In particular, unfair coins would have {\displaystyle p\neq 0.5} p\neq 0.5.The Bernoulli distribution is a special case of the binomial distribution where a single experiment/trial is conducted (n=1). It is also a special case of the two-point distribution, for which the outcome need not be a bit, i.e., the two possible outcomes need not be 0 and 1."
0.0.2.2.2	0.0.2.2	Binomial distribution	Discrete probability distribution	5	"In probability theory and statistics, the binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes–no question, and each with its own boolean-valued outcome: a random variable containing single bit of information: success/yes/true/one (with probability p) or failure/no/false/zero (with probability q = 1 − p). A single success/failure experiment is also called a Bernoulli trial or Bernoulli experiment and a sequence of outcomes is called a Bernoulli process; for a single trial, i.e., n = 1, the binomial distribution is a Bernoulli distribution. The binomial distribution is the basis for the popular binomial test of statistical significance. The binomial distribution is frequently used to model the number of successes in a sample of size n drawn with replacement from a population of size N. If the sampling is carried out without replacement, the draws are not independent and so the resulting distribution is a hypergeometric distribution, not a binomial one. However, for N much larger than n, the binomial distribution remains a good approximation, and is widely used."
0.0.2.2.3	0.0.2.2	Discrete uniform	Discrete probability distribution	5	"In probability theory and statistics, the discrete uniform distribution is a symmetric probability distribution whereby a finite number of values are equally likely to be observed; every one of n values has equal probability 1/n. Another way of saying  discrete uniform distribution  would be  a known, finite number of outcomes equally likely to happen .A simple example of the discrete uniform distribution is throwing a fair dice. The possible values are 1, 2, 3, 4, 5, 6, and each time the die is thrown the probability of a given score is 1/6. If two dice are thrown and their values added, the resulting distribution is no longer uniform since not all sums have equal probability.The discrete uniform distribution itself is inherently non-parametric. It is convenient, however, to represent its values generally by all integers in an interval [a,b], so that a and b become the main parameters of the distribution (often one simply considers the interval [1,n] with the single parameter n)."
0.0.2.2.4	0.0.2.2	Geometric distribution	Discrete probability distribution	5	"These two different geometric distributions should not be confused with each other. Often, the name shifted geometric distribution is adopted for the former one (distribution of the number X); however, to avoid ambiguity, it is considered wise to indicate which is intended, by mentioning the support explicitly. The geometric distribution gives the probability that the first occurrence of success requires k independent trials, each with success probability p. If the probability of success on each trial is p, then the probability that the kth trial (out of k trials) is the first success is {\displaystyle \Pr(X=k)=(1-p)^{k-1}\,p\,} \Pr(X=k)=(1-p)^{k-1}\,p\,"
0.0.2.2.5	0.0.2.2	Negative binomial distribution	Discrete probability distribution	5	In probability theory and statistics, the negative binomial distribution is a discrete probability distribution of the number of successes in a sequence of independent and identically distributed Bernoulli trials before a specified (non-random) number of failures (denoted r) occurs. For example, if we define a 1 as failure, all non-1s as successes, and we throw a dice repeatedly until the third time 1 appears (r = three failures), then the probability distribution of the number of non-1s that had appeared will be a negative binomial.
0.0.2.2.6	0.0.2.2	Hypergeometric	Discrete probability distribution	5	In probability theory and statistics, the hypergeometric distribution is a discrete probability distribution that describes the probability of {\displaystyle k} k successes (random draws for which the object drawn has a specified feature) in {\displaystyle n} n draws, without replacement, from a finite population of size {\displaystyle N} N that contains exactly {\displaystyle K} K objects with that feature, wherein each draw is either a success or a failure. In contrast, the binomial distribution describes the probability of {\displaystyle k} k successes in {\displaystyle n} n draws with replacement.
0.0.2.3	0.0.2	Continuous probability distribution	Probability theory	4	"A continuous probability distribution is a probability distribution that has a cumulative distribution function that is continuous. Most often they are generated by having a probability density function. Mathematicians call distributions with probability density functions absolutely continuous, since their cumulative distribution function is absolutely continuous with respect to the Lebesgue measure ?. If the distribution of X is continuous, then X is called a continuous random variable. There are many examples of continuous probability distributions: normal, uniform, chi-squared, and others. Intuitively, a continuous random variable is the one which can take a continuous range of values—as opposed to a discrete distribution, where the set of possible values for the random variable is at most countable. While for a discrete distribution an event with probability zero is impossible[citation needed] (e.g., rolling ? on a standard die has probability zero and is impossible), this is not so in the case of a continuous random variable. For example, if one measures the width of an oak leaf, the result of 3½ cm is possible; however, it has probability zero because uncountably many other potential values exist even between 3 cm and 4 cm. Each of these individual outcomes has probability zero, yet the probability that the outcome will fall into the interval (3 cm, 4 cm) is nonzero. This apparent paradox is resolved by the fact that the probability that X attains some value within an infinite set, such as an interval, cannot be found by naively adding the probabilities for individual values. Formally, each value has an infinitesimally small probability, which statistically is equivalent to zero."
0.0.2.3.0	0.0.2.3	Normal	Continuous probability distribution	5	The normal distribution is useful because of the central limit theorem. In its most general form, under some conditions (which include finite variance), it states that averages of samples of observations of random variables independently drawn from independent distributions converge in distribution to the normal, that is, become normally distributed when the number of observations is sufficiently large. Physical quantities that are expected to be the sum of many independent processes (such as measurement errors) often have distributions that are nearly normal. Moreover, many results and methods (such as propagation of uncertainty and least squares parameter fitting) can be derived analytically in explicit form when the relevant variables are normally distributed.The normal distribution is sometimes informally called the bell curve. However, many other distributions are bell-shaped (such as the Cauchy, Student's t, and logistic distributions). Even the term Gaussian bell curve is ambiguous because it may be used to refer to some function defined in terms of the Gaussian function which is not a probability distribution because it is not normalized (does not integrate to 1).
0.0.2.3.1	0.0.2.3	Uniform	Continuous probability distribution	5	In probability theory and statistics, the continuous uniform distribution or rectangular distribution is a family of symmetric probability distributions such that for each member of the family, all intervals of the same length on the distribution's support are equally probable. The support is defined by the two parameters, a and b, which are its minimum and maximum values. The distribution is often abbreviated U(a,b). It is the maximum entropy probability distribution for a random variate X under no constraint other than that it is contained in the distribution's support
0.0.2.3.2	0.0.2.3	Chi-squared	Continuous probability distribution	5	In probability theory and statistics, the chi-squared distribution (also chi-square or χ2-distribution) with {\displaystyle k} k degrees of freedom is the distribution of a sum of the squares of k independent standard normal random variables. The chi-square distribution is a special case of the gamma distribution and is one of the most widely used probability distributions in inferential statistics, e. g., in hypothesis testing or in construction of confidence intervals. When it is being distinguished from the more general noncentral chi-squared distribution, this distribution is sometimes called the central chi-squared distribution.
0.0.2.3.3	0.0.2.3	F	Continuous probability distribution	5	In probability theory and statistics, the F-distribution, also known as Snedecor's F distribution or the Fisher–Snedecor distribution (after Ronald Fisher and George W. Snedecor) is a continuous probability distribution that arises frequently as the null distribution of a test statistic, most notably in the analysis of variance, e.g., F-test
0.0.2.3.4	0.0.2.3	Student's t	Continuous probability distribution	5	In probability and statistics, Student's t-distribution (or simply the t-distribution) is any member of a family of continuous probability distributions that arises when estimating the mean of a normally distributed population in situations where the sample size is small and population standard deviation is unknown. It was developed by William Sealy Gosset under the pseudonym Student.The t-distribution plays a role in a number of widely used statistical analyses, including Student's t-test for assessing the statistical significance of the difference between two sample means, the construction of confidence intervals for the difference between two population means, and in linear regression analysis. The Student's t-distribution also arises in the Bayesian analysis of data from a normal family.
0.0.2.3.5	0.0.2.3	Gamma	Continuous probability distribution	5	In probability theory and statistics, the gamma distribution is a two-parameter family of continuous probability distributions. The exponential distribution, Erlang distribution, and chi-squared distribution are special cases of the gamma distribution.
0.0.2.3.6	0.0.2.3	Laplace	Continuous probability distribution	5	In probability theory and statistics, the Laplace distribution is a continuous probability distribution named after Pierre-Simon Laplace. It is also sometimes called the double exponential distribution, because it can be thought of as two exponential distributions (with an additional location parameter) spliced together back-to-back, although the term 'double exponential distribution' is also sometimes used to refer to the Gumbel distribution. The difference between two independent identically distributed exponential random variables is governed by a Laplace distribution, as is a Brownian motion evaluated at an exponentially distributed random time. Increments of Laplace motion or a variance gamma process evaluated over the time scale also have a Laplace distribution.
0.0.2.3.7	0.0.2.3	Log-normal	Continuous probability distribution	5	In probability theory, a log-normal (or lognormal) distribution is a continuous probability distribution of a random variable whose logarithm is normally distributed. Thus, if the random variable X is log-normally distributed, then Y = ln(X) has a normal distribution. Likewise, if Y has a normal distribution, then the exponential function of Y, X = exp(Y), has a log-normal distribution. A random variable which is log-normally distributed takes only positive real values. The distribution is occasionally referred to as the Galton distribution or Galton's distribution, after Francis Galton. The log-normal distribution also has been associated with other names, such as McAlister, Gibrat and Cobb–Douglas.
0.0.2.3.8	0.0.2.3	Pareto	Continuous probability distribution	5	If X is a random variable with a Pareto (Type I) distribution,  then the probability that X is greater than some number x, i.e. the survival function (also called tail function), is given by {\displaystyle {\overline {F}}(x)=\Pr(X>x)={\begin{cases}\left({\frac {x_{\mathrm {m} }}{x}}\right)^{\alpha }&x\geq x_{\mathrm {m} },\\1&x<x_{\mathrm {m} },\end{cases}}} {\displaystyle {\overline {F}}(x)=\Pr(X>x)={\begin{cases}\left({\frac {x_{\mathrm {m} }}{x}}\right)^{\alpha }&x\geq x_{\mathrm {m} },\\1&x<x_{\mathrm {m} },\end{cases}}}
0.0.2.3.9	0.0.2.3	Exponential	Continuous probability distribution	5	In probability theory and statistics, the exponential distribution (also known as negative exponential distribution) is the probability distribution that describes the time between events in a Poisson process, i.e. a process in which events occur continuously and independently at a constant average rate. It is a particular case of the gamma distribution. It is the continuous analogue of the geometric distribution, and it has the key property of being memoryless. In addition to being used for the analysis of Poisson processes, it is found in various other contexts.The exponential distribution is not the same as the class of exponential families of distributions, which is a large class of probability distributions that includes the exponential distribution as one of its members, but also includes the normal distribution, binomial distribution, gamma distribution, Poisson, and many others.
0.0.2.3.10	0.0.2.3	Beta	Continuous probability distribution	5	In probability theory and statistics, the beta distribution is a family of continuous probability distributions defined on the interval [0, 1] parametrized by two positive shape parameters, denoted by α and β, that appear as exponents of the random variable and control the shape of the distribution. The beta distribution has been applied to model the behavior of random variables limited to intervals of finite length in a wide variety of disciplines. In Bayesian inference, the beta distribution is the conjugate prior probability distribution for the Bernoulli, binomial, negative binomial and geometric distributions. For example, the beta distribution can be used in Bayesian analysis to describe initial knowledge concerning probability of success such as the probability that a space vehicle will successfully complete a specified mission. The beta distribution is a suitable model for the random behavior of percentages and proportions. The usual formulation of the beta distribution is also known as the beta distribution of the first kind, whereas beta distribution of the second kind is an alternative name for the beta prime distribution.
0.0.2.3.11	0.0.2.3	Cauchy	Continuous probability distribution	5	"The Cauchy distribution is often used in statistics as the canonical example of a  pathological  distribution since both its expected value and its variance are undefined. (But see the section Explanation of undefined moments below.) The Cauchy distribution does not have finite moments of order greater than or equal to one; only fractional absolute moments exist. The Cauchy distribution has no moment generating function. In mathematics, it is closely related to the Poisson kernel, which is the fundamental solution for the Laplace equation in the upper half-plane. In spectroscopy, it is the description of the shape of spectral lines which are subject to homogeneous broadening in which all atoms interact in the same way with the frequency range contained in the line shape. Many mechanisms cause homogeneous broadening, most notably collision broadening"
0.0.2.3.12	0.0.2.3	Weibull	Continuous probability distribution	5	In probability theory and statistics, the Weibull distribution /ˈveɪbʊl/ is a continuous probability distribution.
0.0.2.4	0.0.2	Multivariate Distributions	Probability theory	4	In the study of probability, given at least two random variables X, Y, ..., that are defined on a probability space, the joint probability distribution for X, Y, ... is a probability distribution that gives the probability that each of X, Y, ... falls in any particular range or discrete set of values specified for that variable. In the case of only two random variables, this is called a bivariate distribution, but the concept generalizes to any number of random variables, giving a multivariate distribution.
0.1	0	Analysis	Statistics	2	Statistical analysis is a component of data analytics. In the context of business intelligence (BI), statistical analysis involves collecting and scrutinizing every data sample in a set of items from which samples can be drawn. A sample, in statistics, is a representative selection drawn from a total population.
0.1.0	0.1	Correlation	Analysis	3	In the broadest sense correlation is any statistical association, though in common usage it most often refers to how close two variables are to having a linear relationship with each other.
0.1.0.0	0.1.0	Confounding variable	Correlation	4	In statistics, a confounder (also confounding variable or confounding factor) is a variable that influences both the dependent variable and independent variable causing a spurious association. Confounding is a causal concept, and as such, cannot be described in terms of correlations or associations
0.1.0.1	0.1.0	Probabilistic independence	Correlation	4	In probability theory, two events are independent, statistically independent, or stochastically independent if the occurrence of one does not affect the probability of occurrence of the other. Similarly, two random variables are independent if the realization of one does not affect the probability distribution of the other.
0.1.0.2	0.1.0	Correlation coefficients	Correlation	4	A correlation coefficient is a numerical measure of some type of correlation, meaning a statistical relationship between two variables. Several types of correlation coefficient exist, each with their own definition and own range of usability and characteristics.
0.1.0.2.0	0.1.0.2	Pearson product-moment correlation coefficient	Correlation coefficients	5	"Pearson's correlation coefficient is the covariance of the two variables divided by the product of their standard deviations. The form of the definition involves a  product moment , that is, the mean (the first moment about the origin) of the product of the mean-adjusted random variables; hence the modifier product-moment in the name."
0.1.0.2.1	0.1.0.2	Intraclass correlation	Correlation coefficients	5	the intraclass correlation (or the intraclass correlation coefficient, abbreviated ICC) is an inferential statistic that can be used when quantitative measurements are made on units that are organized into groups. It describes how strongly units in the same group resemble each other. While it is viewed as a type of correlation, unlike most other correlation measures it operates on data structured as groups, rather than data structured as paired observations
0.1.0.2.2	0.1.0.2	Rank correlation	Correlation coefficients	5	In statistics, a rank correlation is any of several statistics that measure an ordinal association—the relationship between rankings of different ordinal variables or different rankings of the same variable, where a  ranking  is the assignment of the ordering labels  first ,  second ,  third , etc. to different observations of a particular variable. A rank correlation coefficient measures the degree of similarity between two rankings, and can be used to assess the significance of the relation between them. For example, two common nonparametric methods of significance that use rank correlation are the Mann–Whitney U test and the Wilcoxon signed-rank test.
0.1.0.2.3	0.1.0.2	Spearman's rho	Correlation coefficients	5	The Spearman correlation coefficient is defined as the Pearson correlation coefficient between the ranked variables
0.1.0.2.4	0.1.0.2	Kendall's tau	Correlation coefficients	5	In statistics, the Kendall rank correlation coefficient, commonly referred to as Kendall's tau coefficient (after the Greek letter τ), is a statistic used to measure the ordinal association between two measured quantities. A tau test is a non-parametric hypothesis test for statistical dependence based on the tau coefficient.
0.1.0.3	0.1.0	Distance correlation	Correlation	4	statistics and in probability theory, distance correlation is a measure of statistical dependence between two random variables or two random vectors of arbitrary, not necessarily equal, dimension. It is zero if and only if the random variables are statistically independent, unlike Pearson's correlation, which can be zero for dependent random variables.
0.1.0.4	0.1.0	Maximal information coefficient	Correlation	4	the maximal information coefficient (MIC) is a measure of the strength of the linear or non-linear association between two variables X and Y.
0.1.0.5	0.1.0	Multiple correlation	Correlation	4	In statistics, the coefficient of multiple correlation is a measure of how well a given variable can be predicted using a linear function of a set of other variables. It is the correlation between the variable's values and the best predictions that can be computed linearly from the predictive variables
0.1.0.6	0.1.0	Partial correlation	Correlation	4	In probability theory and statistics, partial correlation measures the degree of association between two random variables, with the effect of a set of controlling random variables removed. If we are interested in finding whether or to what extent there is a numerical relationship between two variables of interest, using their correlation coefficient will give misleading results if there is another, confounding, variable that is numerically related to both variables of interest. This misleading information can be avoided by controlling for the confounding variable, which is done by computing the partial correlation coefficient. This is precisely the motivation for including other right-side variables in a multiple regression.
0.1.0.7	0.1.0	RV coefficient	Correlation	4	The definition of the RV-coefficient makes use of ideas  concerning the definition of scalar-valued quantities which are called the  variance  and  covariance  of vector-valued random variables.
0.1.1	0.1	Regression 	Analysis	3	"Most commonly, regression analysis estimates the conditional expectation of the dependent variable given the independent variables – that is, the average value of the dependent variable when the independent variables are fixed. Less commonly, the focus is on a quantile, or other location parameter of the conditional distribution of the dependent variable given the independent variables. In all cases, a function of the independent variables called the regression function is to be estimated. In regression analysis, it is also of interest to characterize the variation of the dependent variable around the prediction of the regression function using a probability distribution. A related but distinct approach is Necessary Condition Analysis[1] (NCA), which estimates the maximum (rather than average) value of the dependent variable for a given value of the independent variable (ceiling line rather than central line) in order to identify what value of the independent variable is necessary but not sufficient for a given value of the dependent variable. _Regression analysis is widely used for prediction and forecasting, where its use has substantial overlap with the field of machine learning. Regression analysis is also used to understand which among the independent variables are related to the dependent variable, and to explore the forms of these relationships. In restricted circumstances, regression analysis can be used to infer causal relationships between the independent and dependent variables. However this can lead to illusions or false relationships, so caution is advisable; for example, correlation does not prove causation._ Many techniques for carrying out regression analysis have been developed. Familiar methods such as linear regression and ordinary least squares regression are parametric, in that the regression function is defined in terms of a finite number of unknown parameters that are estimated from the data. Nonparametric regression refers to techniques that allow the regression function to lie in a specified set of functions, which may be infinite-dimensional._ The performance of regression analysis methods in practice depends on the form of the data generating process, and how it relates to the regression approach being used. Since the true form of the data-generating process is generally not known, regression analysis often depends to some extent on making assumptions about this process. These assumptions are sometimes testable if a sufficient quantity of data is available. Regression models for prediction are often useful even when the assumptions are moderately violated, although they may not perform optimally. However, in many applications, especially with small effects or questions of causality based on observational data, regression methods can give misleading results."
0.1.1.0	0.1.1	Ordinary least squares	Regression 	4	In statistics, ordinary least squares (OLS) or linear least squares is a method for estimating the unknown parameters in a linear regression model, with the goal of minimizing the sum of the squares of the differences between the observed responses (values of the variable being predicted) in the given dataset and those predicted by a linear function of a set of explanatory variables. Visually this is seen as the sum of the squared vertical distances between each data point in the set and the corresponding point on the regression line – the smaller the differences, the better the model fits the data. The resulting estimator can be expressed by a simple formula, especially in the case of a single regressor on the right-hand side.
0.1.1.1	0.1.1	Partial least squares	Regression 	4	"Is a statistical method that bears some relation to principal components regression; instead of finding hyperplanes of maximum variance between the response and independent variables, it finds a linear regression model by projecting the predicted variables and the observable variables to a new space. Because both the X and Y data are projected to new spaces, the PLS family of methods are known as bilinear factor models. Partial least squares Discriminant Analysis (PLS-DA) is a variant used when the Y is categorical."
0.1.1.2	0.1.1	Total least squares	Regression 	4	In applied statistics, total least squares is a type of errors-in-variables regression, a least squares data modeling technique in which observational errors on both dependent and independent variables are taken into account. It is a generalization of Deming regression and also of orthogonal regression, and can be applied to both linear and non-linear models.
0.1.1.3	0.1.1	Ridge regression	Regression 	4	Tikhonov regularization, named for Andrey Tikhonov, is the most commonly used method of regularization of ill-posed problems. In statistics, the method is known as ridge regression, in machine learning it is known as weight decay, and with multiple independent discoveries, it is also variously known as the Tikhonov–Miller method, the Phillips–Twomey method, the constrained linear inversion method, and the method of linear regularization. It is related to the Levenberg–Marquardt algorithm for non-linear least-squares problems.
0.1.1.4	0.1.1	Errors and residuals	Regression 	4	In statistics and optimization, errors and residuals are two closely related and easily confused measures of the deviation of an observed value of an element of a statistical sample from its  theoretical value . The error (or disturbance) of an observed value is the deviation of the observed value from the (unobservable) true value of a quantity of interest (for example, a population mean), and the residual of an observed value is the difference between the observed value and the estimated value of the quantity of interest (for example, a sample mean).
0.1.1.5	0.1.1	Regression model validation	Regression 	4	In statistics, regression validation is the process of deciding whether the numerical results quantifying hypothesized relationships between variables, obtained from regression analysis, are acceptable as descriptions of the data. The validation process can involve analyzing the goodness of fit of the regression, analyzing whether the regression residuals are random, and checking whether the model's predictive performance deteriorates substantially when applied to data that were not used in model estimation.
0.1.1.6	0.1.1	Mixed effects models	Regression 	4	A mixed model is a statistical model containing both fixed effects and random effects. These models are useful in a wide variety of disciplines in the physical, biological and social sciences. They are particularly useful in settings where repeated measurements are made on the same statistical units (longitudinal study), or where measurements are made on clusters of related statistical units.
0.1.1.7	0.1.1	Simultaneous equations models	Regression 	4	Simultaneous equation models are a type of statistical model in the form of a set of linear simultaneous equations. They are often used in econometrics. In Simultaneous Equations Models (SEM), one can estimate equation by equation, however estimation methods that exploit the system of equations, such as General Method of Moments (GMM) and Instrumental variables estimation (IV) tends to be more efficient
0.1.1.8	0.1.1	Multivariate adaptive regression splines (MARS)	Regression 	4	In statistics, multivariate adaptive regression splines (MARS) is a form of regression analysis introduced by Jerome H. Friedman in 1991. It is a non-parametric regression technique and can be seen as an extension of linear models that automatically models nonlinearities and interactions between variables.
0.1.1.9	0.1.1	Multilevel model	Regression 	4	Multilevel models (also known as hierarchical linear models, nested data models, mixed models, random coefficient, random-effects models, random parameter models, or split-plot designs) are statistical models of parameters that vary at more than one level. An example could be a model of student performance that contains measures for individual students as well as measures for classrooms within which the students are grouped. These models can be seen as generalizations of linear models (in particular, linear regression), although they can also extend to non-linear models. These models became much more popular after sufficient computing power and software became available.
0.1.1.10	0.1.1	Fixed effects	Regression 	4	In statistics, a fixed effects model is a statistical model in which the model parameters are fixed or non-random quantities. This is in contrast to random effects models and mixed models in which all or some of the model parameters are considered as random variables. In many applications including econometrics and biostatistics a fixed effects model refers to a regression model in which the group means are fixed (non-random) as opposed to a random effects model in which the group means are a random sample from a population.[6] Generally, data can be grouped according to several observed factors. The group means could be modeled as fixed or random effects for each grouping. In a fixed effects model each group mean is a group-specific fixed quantity.
0.1.1.11	0.1.1	Random effects	Regression 	4	In statistics, a random effects model, also called a variance components model, is a kind of hierarchical linear model. It assumes that the data being analysed are drawn from a hierarchy of different populations whose differences relate to that hierarchy. In econometrics, random effects models are used in the analysis of hierarchical or panel data when one assumes no fixed effects (it allows for individual effects).
0.1.1.12	0.1.1	 Principal components	Regression 	4	In statistics, principal component regression (PCR) is a regression analysis technique that is based on principal component analysis (PCA). Typically, it considers regressing the outcome (also known as the response or the dependent variable) on a set of covariates (also known as predictors, or explanatory variables, or independent variables) based on a standard linear regression model, but uses PCA for estimating the unknown regression coefficients in the model.In PCR, instead of regressing the dependent variable on the explanatory variables directly, the principal components of the explanatory variables are used as regressors. One typically uses only a subset of all the principal components for regression, thus making PCR some kind of a regularized procedure.
0.1.1.13	0.1.1	Least angle	Regression 	4	In statistics, least-angle regression (LARS) is an algorithm for fitting linear regression models to high-dimensional data, developed by Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani. Suppose we expect a response variable to be determined by a linear combination of a subset of potential covariates. Then the LARS algorithm provides a means of producing an estimate of which variables to include, as well as their coefficients. Instead of giving a vector result, the LARS solution consists of a curve denoting the solution for each value of the L1 norm of the parameter vector. The algorithm is similar to forward stepwise regression, but instead of including variables at each step, the estimated parameters are increased in a direction equiangular to each one's correlations with the residual.
0.1.1.14	0.1.1	Local	Regression 	4	"LOWESS (locally weighted scatterplot smoothing) are two strongly related non-parametric regression methods that combine multiple regression models in a k-nearest-neighbor-based meta-model.  LOESS  is a later generalization of LOWESS; although it is not a true acronym, it may be understood as standing for  LOcal regrESSion”.LOESS and LOWESS thus build on  classical  methods, such as linear and nonlinear least squares regression. They address situations in which the classical procedures do not perform well or cannot be effectively applied without undue labor. LOESS combines much of the simplicity of linear least squares regression with the flexibility of nonlinear regression. It does this by fitting simple models to localized subsets of the data to build up a function that describes the deterministic part of the variation in the data, point by point. In fact, one of the chief attractions of this method is that the data analyst is not required to specify a global function of any form to fit a model to the data, only to fit segments of the data."
0.1.1.15	0.1.1	Segmented	Regression 	4	Segmented regression, also known as piecewise regression or  broken-stick regression , is a method in regression analysis in which the independent variable is partitioned into intervals and a separate line segment is fit to each interval. Segmented regression analysis can also be performed on multivariate data by partitioning the various independent variables. Segmented regression is useful when the independent variables, clustered into different groups, exhibit different relationships between the variables in these regions. The boundaries between the segments are breakpoints. Segmented linear regression is segmented regression whereby the relations in the intervals are obtained by linear regression.
0.1.1.16	0.1.1	Errors-in-variables	Regression 	4	"In statistics, errors-in-variables models or measurement error models are regression models that account for measurement errors in the independent variables. In contrast, standard regression models assume that those regressors have been measured exactly, or observed without error; as such, those models account only for errors in the dependent variables, or responses."
0.1.1.17	0.1.1	Robust regression	Regression 	4	"In robust statistics, robust regression is a form of regression analysis designed to circumvent some limitations of traditional parametric and non-parametric methods. Regression analysis seeks to find the relationship between one or more independent variables and a dependent variable. Certain widely used methods of regression, such as ordinary least squares, have favourable properties if their underlying assumptions are true, but can give misleading results if those assumptions are not true; thus ordinary least squares is said to be not robust to violations of its assumptions. Robust regression methods are designed to be not overly affected by violations of assumptions by the underlying data-generating process."
0.1.2	0.1	Categorical	Analysis	3	In statistics, a categorical variable is a variable that can take on one of a limited, and usually fixed number of possible values, assigning each individual or other unit of observation to a particular group or nominal category on the basis of some qualitative property.
0.1.2.0	0.1.2	 Cohen's kappa	Categorical	4	Cohen's kappa coefficient is a statistic which measures inter-rater agreement for qualitative (categorical) items. It is generally thought to be a more robust measure than simple percent agreement calculation, since κ takes into account the possibility of the agreement occurring by chance. There is controversy surrounding Cohen’s Kappa due to the difficulty in interpreting indices of agreement. Some researchers have suggested that it is conceptually simpler to evaluate disagreement between items. See the Limitations section for more detail.
0.1.2.1	0.1.2	Contingency table	Categorical	4	In statistics, a contingency table (also known as a cross tabulation or crosstab) is a type of table in a matrix format that displays the (multivariate) frequency distribution of the variables. They are heavily used in survey research, business intelligence, engineering and scientific research. They provide a basic picture of the interrelation between two variables and can help find interactions between them. The term contingency table was first used by Karl Pearson in  On the Theory of Contingency and Its Relation to Association and Normal Correlation , part of the Drapers' Company Research Memoirs Biometric Series I published in 1904. A crucial problem of multivariate statistics is finding (direct-)dependence structure underlying the variables contained in high-dimensional contingency tables. If some of the conditional independences are revealed, then even the storage of the data can be done in a smarter way (see Lauritzen (2002)). In order to do this one can use information theory concepts, which gain the information only from the distribution of probability, which can be expressed easily from the contingency table by the relative frequencies.
0.1.2.2	0.1.2	Graphical model	Categorical	4	A graphical model or probabilistic graphical model (PGM) is a probabilistic model for which a graph expresses the conditional dependence structure between random variables. They are commonly used in probability theory, statistics—particularly Bayesian statistics—and machine learning.
0.1.2.3	0.1.2	Log-linear model	Categorical	4	A log-linear model is a mathematical model that takes the form of a function whose logarithm equals a linear combination of the parameters of the model, which makes it possible to apply (possibly multivariate) linear regression. That is, it has the general form {\displaystyle \exp \left(c+\sum _{i}w_{i}f_{i}(X)\right)} \exp \left(c+\sum _{i}w_{i}f_{i}(X)\right), in which the fi(X) are quantities that are functions of the variables X, in general a vector of values, while c and the wi stand for the model parameters. The term may specifically be used for: A log-linear plot or graph, which is a type of semi-log plot. Poisson regression for contingency tables, a type of generalized linear model. 
0.1.2.4	0.1.2	McNemar's test	Categorical	4	In statistics, McNemar's test is a statistical test used on paired nominal data. It is applied to 2 × 2 contingency tables with a dichotomous trait, with matched pairs of subjects, to determine whether the row and column marginal frequencies are equal (that is, whether there is  marginal homogeneity ). It is named after Quinn McNemar, who introduced it in 1947. An application of the test in genetics is the transmission disequilibrium test for detecting linkage disequilibrium.
0.1.3	0.1	Multivariate statistics	Analysis	3	Multivariate statistics is a subdivision of statistics encompassing the simultaneous observation and analysis of more than one outcome variable. The application of multivariate statistics is multivariate analysis.
0.1.3.0	0.1.3	 Regression	Multivariate statistics	4	Multivariate regression attempts to determine a formula that can describe how elements in a vector of variables respond simultaneously to changes in others. For linear relations, regression analyses here are based on forms of the general linear model. Note that multivariate regression is distinct from multivariable regression, which has only one dependent variable.
0.1.3.1	0.1.3	MANOVA	Multivariate statistics	4	"Multivariate analysis of variance (MANOVA) extends the analysis of variance to cover cases where there is more than one dependent variable to be analyzed simultaneously; see also MANCOVA."
0.1.3.2	0.1.3	General linear model	Multivariate statistics	4	The general linear model or multivariate regression model is a statistical linear model. It may be written as  {\displaystyle \mathbf {Y} =\mathbf {X} \mathbf {B} +\mathbf {U} ,} \mathbf {Y} =\mathbf {X} \mathbf {B} +\mathbf {U} , where Y is a matrix with series of multivariate measurements (each column being a set of measurements on one of the dependent variables), X is a matrix of observations on independent variables that might be a design matrix (each column being a set of observations on one of the independent variables), B is a matrix containing parameters that are usually to be estimated and U is a matrix containing errors (noise). The errors are usually assumed to be uncorrelated across measurements, and follow a multivariate normal distribution. If the errors do not follow a multivariate normal distribution, generalized linear models may be used to relax assumptions about Y and U. The general linear model incorporates a number of different statistical models: ANOVA, ANCOVA, MANOVA, MANCOVA, ordinary linear regression, t-test and F-test. The general linear model is a generalization of multiple linear regression model to the case of more than one dependent variable. If Y, B, and U were column vectors, the matrix equation above would represent multiple linear regression. Hypothesis tests with the general linear model can be made in two ways: multivariate or as several independent univariate tests. In multivariate tests the columns of Y are tested together, whereas in univariate tests the columns of Y are tested independently, i.e., as multiple univariate tests with the same design matrix.
0.1.3.3	0.1.3	Principal components analysis	Multivariate statistics	4	Principal components analysis (PCA) creates a new set of orthogonal variables that contain the same information as the original set. It rotates the axes of variation to give a new set of orthogonal axes, ordered so that they summarize decreasing proportions of the variation.
0.1.3.4	0.1.3	Factor analysis	Multivariate statistics	4	"Factor analysis is similar to PCA but allows the user to extract a specified number of synthetic variables, fewer than the original set, leaving the remaining unexplained variation as error. The extracted variables are known as latent variables or factors; each one may be supposed to account for covariation in a group of observed variables."
0.1.3.5	0.1.3	Classification	Multivariate statistics	4	In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known. An example would be assigning a given email into  spam  or  non-spam  classes or assigning a diagnosis to a given patient as described by observed characteristics of the patient (gender, blood pressure, presence or absence of certain symptoms, etc.). Classification is an example of pattern recognition. In the terminology of machine learning, classification is considered an instance of supervised learning, i.e. learning where a training set of correctly identified observations is available. The corresponding unsupervised procedure is known as clustering, and involves grouping data into categories based on some measure of inherent similarity or distance.
0.1.3.6	0.1.3	Canonical correlation analysis	Multivariate statistics	4	"Canonical correlation analysis finds linear relationships among two sets of variables; it is the generalised (i.e. canonical) version of bivariate correlation."
0.1.3.7	0.1.3	Redundancy analysis	Multivariate statistics	4	Redundancy analysis (RDA) is similar to canonical correlation analysis but allows the user to derive a specified number of synthetic variables from one set of (independent) variables that explain as much variance as possible in another (independent) set. It is a multivariate analogue of regression
0.1.3.8	0.1.3	Correspondence analysis	Multivariate statistics	4	Correspondence analysis (CA), or reciprocal averaging, finds (like PCA) a set of synthetic variables that summarise the original set. The underlying model assumes chi-squared dissimilarities among records (cases).
0.1.3.9	0.1.3	Canonical (or  constrained ) correspondence analysis	Multivariate statistics	4	"Canonical (or  constrained ) correspondence analysis (CCA) for summarising the joint variation in two sets of variables (like redundancy analysis); combination of correspondence analysis and multivariate regression analysis. The underlying model assumes chi-squared dissimilarities among records (cases)."
0.1.3.10	0.1.3	Multidimensional scaling	Multivariate statistics	4	"Multidimensional scaling comprises various algorithms to determine a set of synthetic variables that best represent the pairwise distances between records. The original method is principal coordinates analysis (PCoA; based on PCA)."
0.1.3.11	0.1.3	Discriminant analysis	Multivariate statistics	4	Discriminant analysis, or canonical variate analysis, attempts to establish whether a set of variables can be used to distinguish between two or more groups of cases.
0.1.3.12	0.1.3	Linear discriminant analysis	Multivariate statistics	4	Linear discriminant analysis (LDA) computes a linear predictor from two sets of normally distributed data to allow for classification of new observations.
0.1.3.13	0.1.3	Clustering systems	Multivariate statistics	4	Clustering systems assign objects into groups (called clusters) so that objects (cases) from the same cluster are more similar to each other than objects from different clusters.
0.1.3.14	0.1.3	Recursive partitioning	Multivariate statistics	4	Recursive partitioning creates a decision tree that attempts to correctly classify members of the population based on a dichotomous dependent variable.
0.1.3.15	0.1.3	Artificial neural networks	Multivariate statistics	4	Artificial neural networks extend regression and clustering methods to non-linear multivariate models.
0.1.3.16	0.1.3	Statistical graphics	Multivariate statistics	4	Statistical graphics such as tours, parallel coordinate plots, scatterplot matrices can be used to explore multivariate data.
0.1.3.17	0.1.3	Simultaneous equations models	Multivariate statistics	4	Simultaneous equations models involve more than one regression equation, with different dependent variables, estimated together.
0.1.3.18	0.1.3	Vector autoregression	Multivariate statistics	4	Vector autoregression involves simultaneous regressions of various time series variables on their own and each other's lagged values.
0.1.3.19	0.1.3	Principal response curves	Multivariate statistics	4	Principal response curves analysis (PRC) is a method based on RDA that allows the user to focus on treatment effects over time by correcting for changes in control treatments over time
0.1.4	0.1	Time series	Analysis	3	A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Time series forecasting is the use of a model to predict future values based on previously observed values.
0.1.4.0	0.1.4	 General	Time series	4	General information
0.1.4.0.0	0.1.4.0	Decomposition	 General	5	The decomposition of time series is a statistical method that deconstructs a time series into several components, each representing one of the underlying categories of patterns.There are two principal types of decomposition which are outlined below.
0.1.4.0.1	0.1.4.0	Trend	 General	5	Trend estimation is a statistical technique to aid interpretation of data. When a series of measurements of a process are treated as a time series, trend estimation can be used to make and justify statements about tendencies in the data, by relating the measurements to the times at which they occurred. This model can then be used to describe the behaviour of the observed data, without explaining it. Linear trend estimation expresses data as a linear function of time.
0.1.4.0.2	0.1.4.0	Stationarity	 General	5	In mathematics and statistics, a stationary process (a.k.a. a strict(ly) stationary process or strong(ly) stationary process) is a stochastic process whose unconditional joint probability distribution does not change when shifted in time. Consequently, parameters such as mean and variance, if they are present, also do not change over time. Since stationarity is an assumption underlying many statistical procedures used in time series analysis, non-stationary data is often transformed to become stationary. The most common cause of violation of stationarity is a trend in the mean, which can be due either to the presence of a unit root or of a deterministic trend. In the former case of a unit root, stochastic shocks have permanent effects and the process is not mean-reverting. In the latter case of a deterministic trend, the process is called a trend stationary process, and stochastic shocks have only transitory effects after which the variable tends toward a deterministically evolving (non-constant) mean.
0.1.4.0.3	0.1.4.0	Seasonal adjustment	 General	5	Seasonal adjustment is a statistical method for removing the seasonal component of a time series that exhibits a seasonal pattern. It is usually done when wanting to analyse the trend, and cyclical deviations from trend, of a time series independently of the seasonal components. It is normal to report seasonally adjusted data for unemployment rates to reveal the underlying trends and cycles in labor markets. Many economic phenomena have seasonal cycles, such as agricultural production and consumer consumption, e.g. greater consumption leading up to Christmas. It is necessary to adjust for this component in order to understand what underlying trends are in the economy and so official statistics are often adjusted to remove seasonal components
0.1.4.0.4	0.1.4.0	Exponential smoothing	 General	5	Exponential smoothing is a rule of thumb technique for smoothing time series data. Whereas in the simple moving average the past observations are weighted equally, exponential functions are used to assign exponentially decreasing weights over time. It is an easily learned and easily applied procedure for making some determination based on prior assumptions by the user, such as seasonality. Exponential smoothing is used for analysis of financial time-series data as well as the field of signal processing.
0.1.4.0.5	0.1.4.0	Cointegration	 General	5	Cointegration is a statistical property of a collection (X1, X2, ..., Xk) of time series variables. First, all of the series must be integrated of order 1 (see Order of integration). Next, if a linear combination of this collection is integrated of order zero, then the collection is said to be co-integrated. Formally, if (X,Y,Z) are each integrated of order 1, and there exist coefficients a,b,c such that aX + bY + cZ is integrated of order 0, then X, Y, and Z are cointegrated. Cointegration has become an important property in contemporary time series analysis. Time series often have trends—either deterministic or stochastic. In an influential paper, Charles Nelson and Charles Plosser (1982) provided statistical evidence that many US macroeconomic time series (like GNP, wages, employment, etc.) have stochastic trends—these are also called unit root processes, or processes integrated of order 1 − I ( 1 )   {\displaystyle 1-I(1)}  {\displaystyle 1-I(1)}. They also showed that unit root processes have non-standard statistical properties, so that conventional econometric theory methods do not apply to them.
0.1.4.0.6	0.1.4.0	Structural break	 General	5	In econometrics, a structural break, or structural change, is an unexpected shift in a time series that can lead to huge forecasting errors and unreliability of the model in general.  This issue was popularised by David Hendry, who argued that lack of stability of coefficients frequently caused forecast failure, and therefore we must routinely test for structural stability. Structural stability − i.e., the time-invariance of regression coefficients − is a central issue in all applications of linear regression models.
0.1.4.0.7	0.1.4.0	Granger causality	 General	5	Granger causality test is a statistical hypothesis test for determining whether one time series is useful in forecasting another, first proposed in 1969.  Ordinarily, regressions reflect  mere  correlations, but Clive Granger argued that causality in economics could be tested for by measuring the ability to predict the future values of a time series using prior values of another time series. Since the question of  true causality  is deeply philosophical, and because of the post hoc ergo propter hoc fallacy of assuming that one thing preceding another can be used as a proof of causation, econometricians assert that the Granger test finds only  predictive causality .
0.1.4.0.8	0.1.4.0	Spectral analysis	 General	5	The power spectrum S x x   ( f )   {\displaystyle S_{xx}(f)}  S_{{xx}}(f) of a time series x ( t )   {\displaystyle x(t)}  x(t) describes the distribution of power into frequency components composing that signal. According to Fourier analysis any physical signal can be decomposed into a number of discrete frequencies, or a spectrum of frequencies over a continuous range. The statistical average of a certain signal or sort of signal (including noise) as analyzed in terms of its frequency content, is called its spectrum.
0.1.4.1	0.1.4	Specific tests	Time series	4	Specific tests
0.1.4.1.0	0.1.4.1	Dickey–Fuller	Specific tests	5	In statistics, the Dickey–Fuller test tests the null hypothesis of whether a unit root is present in an autoregressive model. The alternative hypothesis is different depending on which version of the test is used, but is usually stationarity or trend-stationarity. It is named after the statisticians David Dickey and Wayne Fuller, who developed the test in 1979
0.1.4.1.1	0.1.4.1	Johansen	Specific tests	5	In statistics, the Johansen test, named after Søren Johansen, is a procedure for testing cointegration of several, say k, I(1) time series. For the presence of I(2) variables see Ch. 9 of his 1995 textbook. This test permits more than one cointegrating relationship so is more generally applicable than the Engle–Granger test which is based on the Dickey–Fuller (or the augmented) test for unit roots in the residuals from a single (estimated) cointegrating relationship
0.1.4.1.2	0.1.4.1	Q-statistic (Ljung–Box)	Specific tests	5	The Ljung–Box test (named for Greta M. Ljung and George E. P. Box) is a type of statistical test of whether any of a group of autocorrelations of a time series are different from zero. Instead of testing randomness at each distinct lag, it tests the  overall  randomness based on a number of lags, and is therefore a portmanteau test. This test is sometimes known as the Ljung–Box Q test, and it is closely connected to the Box–Pierce test (which is named after George E. P. Box and David A. Pierce). In fact, the Ljung–Box test statistic was described explicitly in the paper that led to the use of the Box-Pierce statistic, and from which that statistic takes its name. The Box-Pierce test statistic is a simplified version of the Ljung–Box statistic for which subsequent simulation studies have shown poor performance.
0.1.4.1.3	0.1.4.1	Durbin–Watson	Specific tests	5	In statistics, the Durbin–Watson statistic is a test statistic used to detect the presence of autocorrelation (a relationship between values separated from each other by a given time lag) in the residuals (prediction errors) from a regression analysis. It is named after James Durbin and Geoffrey Watson. The small sample distribution of this ratio was derived by John von Neumann (von Neumann, 1941). Durbin and Watson (1950, 1951) applied this statistic to the residuals from least squares regressions, and developed bounds tests for the null hypothesis that the errors are serially uncorrelated against the alternative that they follow a first order autoregressive process. Later, John Denis Sargan and Alok Bhargava developed several von Neumann–Durbin–Watson type test statistics for the null hypothesis that the errors on a regression model follow a process with a unit root against the alternative hypothesis that the errors follow a stationary first order autoregression (Sargan and Bhargava, 1983). Note that the distribution of this test statistic does not depend on the estimated regression coefficients and the variance of the errors.
0.1.4.1.4	0.1.4.1	Breusch–Godfrey	Specific tests	5	In statistics, the Breusch–Godfrey test, named after Trevor S. Breusch and Leslie G. Godfrey, is used to assess the validity of some of the modelling assumptions inherent in applying regression-like models to observed data series. In particular, it tests for the presence of serial correlation that has not been included in a proposed model structure and which, if present, would mean that incorrect conclusions would be drawn from other tests, or that sub-optimal estimates of model parameters are obtained if it is not taken into account. The regression models to which the test can be applied include cases where lagged values of the dependent variables are used as independent variables in the model's representation for later observations. This type of structure is common in econometric models.
0.1.4.2	0.1.4	Stochastic processes	Time series	4	The definition of a stochastic process varies, but a stochastic process is traditionally defined as a collection of random variables indexed by some set. The term random function is also used to refer to a stochastic or random process, though sometimes it is only used when the stochastic process takes real values.
0.1.4.2.0	0.1.4.2	Discrete time	Stochastic processes	5	"Discrete time views values of variables as occurring at distinct, separate """"points in time"""", or equivalently as being unchanged throughout each non-zero region of time (""""time period"""")—that is, time is viewed as a discrete variable."
0.1.4.2.0.0	0.1.4.2.0	Bernoulli process	Discrete time	6	"In probability and statistics, a Bernoulli process is a finite or infinite sequence of binary random variables, so it is a discrete-time stochastic process that takes only two values, canonically 0 and 1. The component Bernoulli variables Xi are identically distributed and independent. Prosaically, a Bernoulli process is a repeated coin flipping, possibly with an unfair coin (but with consistent unfairness). Every variable Xi in the sequence is associated with a Bernoulli trial or experiment. They all have the same Bernoulli distribution. Much of what can be said about the Bernoulli process can also be generalized to more than two outcomes (such as the process for a six-sided die); this generalization is known as the Bernoulli scheme."
0.1.4.2.0.1	0.1.4.2.0	Random walk	Discrete time	6	A random walk is a mathematical object, known as a stochastic or random process, that describes a path that consists of a succession of random steps on some mathematical space such as the integers. An elementary example of a random walk is the random walk on the integer number line, Z    {\displaystyle \mathbb {Z} }  \mathbb {Z} , which starts at 0 and at each step moves +1 or −1 with equal probability.
0.1.4.2.0.2	0.1.4.2.0	Markov process	Discrete time	6	"In probability theory and related fields, a Markov process, named after the Russian mathematician Andrey Markov, is a stochastic process that satisfies the Markov property (sometimes characterized as  memorylessness ). Roughly speaking, a process satisfies the Markov property if one can make predictions for the future of the process based solely on its present state just as well as one could knowing the process's full history, hence independently from such history; i.e., conditional on the present state of the system, its future and past states are independent."
0.1.4.2.0.3	0.1.4.2.0	Martingale (probability theory)	Discrete time	6	In probability theory, a martingale is a sequence of random variables (i.e., a stochastic process) for which, at a particular time in the realized sequence, the expectation of the next value in the sequence is equal to the present observed value even given knowledge of all prior observed values.To contrast, in a process that is not a martingale, it may still be the case that the expected value of the process at one time is equal to the expected value of the process at the next time. However, knowledge of the prior outcomes (e.g., all prior cards drawn from a card deck) may be able to reduce the uncertainty of future outcomes. Thus, the expected value of the next outcome given knowledge of the present and all prior outcomes may be higher than the current outcome if a winning strategy is used. Martingales exclude the possibility of winning strategies based on game history, and thus they are a model of fair games.
0.1.4.2.0.4	0.1.4.2.0	Lévy process	Discrete time	6	In probability theory, a Lévy process, named after the French mathematician Paul Lévy, is a stochastic process with independent, stationary increments: it represents the motion of a point whose successive displacements are random and independent, and statistically identical over different time intervals of the same length. A Lévy process may thus be viewed as the continuous-time analog of a random walk.The most well known examples of Lévy processes are the Wiener process, often called the Brownian motion process, and the Poisson process. Aside from Brownian motion with drift, all other proper Lévy processes have discontinuous paths
0.1.4.2.1	0.1.4.2	Continuous	Stochastic processes	5	A continuous signal or a continuous-time signal is a varying quantity (a signal) whose domain, which is often time, is a continuum (e.g., a connected interval of the reals). That is, the function's domain is an uncountable set. The function itself need not be continuous.
0.1.4.2.1.0	0.1.4.2.1	 Wiener process	Continuous	6	The Wiener process plays an important role in both pure and applied mathematics. In pure mathematics, the Wiener process gave rise to the study of continuous time martingales. It is a key process in terms of which more complicated stochastic processes can be described. As such, it plays a vital role in stochastic calculus, diffusion processes and even potential theory. It is the driving process of Schramm–Loewner evolution. In applied mathematics, the Wiener process is used to represent the integral of a white noise Gaussian process, and so is useful as a model of noise in electronics engineering (see Brownian noise), instrument errors in filtering theory and unknown forces in control theory.
0.1.4.2.1.1	0.1.4.2.1	Poisson process	Continuous	6	"A Poisson point process is defined on some underlying mathematical space, called a carrier space, or state space, though the latter term has a different meaning[a] in the context of stochastic processes. The Poisson point process can be defined, studied and used in one dimension, for example, on the real line, where it can be interpreted as a counting process or part of a queueing model; in higher dimensions such as the plane where it plays a role in stochastic geometry and spatial statistics; or on more general mathematical spaces. Consequently, the notation, terminology and level of mathematical rigour used to define and study the Poisson point process and points processes in general vary according to the context. Despite its different forms and varying generality, the Poisson point process has two key properties."
0.1.4.2.1.2	0.1.4.2.1	Autoregressive model	Continuous	6	"In statistics and signal processing, an autoregressive (AR) model is a representation of a type of random process; as such, it is used to describe certain time-varying processes in nature, economics, etc. The autoregressive model specifies that the output variable depends linearly on its own previous values and on a stochastic term (an imperfectly predictable term); thus the model is in the form of a stochastic difference equation. Together with the moving-average (MA) model, it is a special case and key component of the more general ARMA and ARIMA models of time series, which have a more complicated stochastic structure; it is also a special case of the vector autoregressive model (VAR), which consists of a system of more than one interlocking stochastic difference equation in more than one evolving random variable. Contrary to the moving-average model, the autoregressive model is not always stationary as it may contain a unit root."
0.1.4.2.1.3	0.1.4.2.1	Moving average model	Continuous	6	In time series analysis, the moving-average (MA) model is a common approach for modeling univariate time series. The moving-average model specifies that the output variable depends linearly on the current and various past values of a stochastic (imperfectly predictable) term.Together with the autoregressive (AR) model, the moving-average model is a special case and key component of the more general ARMA and ARIMA models of time series, which have a more complicated stochastic structure. The moving-average model should not be confused with the moving average, a distinct concept despite some similarities.
0.1.4.2.1.4	0.1.4.2.1	Markov process	Continuous	6	"In probability theory and related fields, a Markov process, named after the Russian mathematician Andrey Markov, is a stochastic process that satisfies the Markov property (sometimes characterized as  memorylessness ). Roughly speaking, a process satisfies the Markov property if one can make predictions for the future of the process based solely on its present state just as well as one could knowing the process's full history, hence independently from such history; i.e., conditional on the present state of the system, its future and past states are independent."
0.1.4.3	0.1.4	Time domain 	Time series	4	Time domain is the analysis of mathematical functions, physical signals or time series of economic or environmental data, with respect to time. In the time domain, the signal or function's value is known for all real numbers, for the case of continuous time, or at various separate instants in the case of discrete time.
0.1.4.3.0	0.1.4.3	 Autocorrelation (ACF)	Time domain 	5	Autocorrelation, also known as serial correlation, is the correlation of a signal with a delayed copy of itself as a function of delay. Informally, it is the similarity between observations as a function of the time lag between them. The analysis of autocorrelation is a mathematical tool for finding repeating patterns, such as the presence of a periodic signal obscured by noise, or identifying the missing fundamental frequency in a signal implied by its harmonic frequencies. It is often used in signal processing for analyzing functions or series of values, such as time domain signals. Unit root processes, trend stationary processes, autoregressive processes, and moving average processes are specific forms of processes with autocorrelation.
0.1.4.3.1	0.1.4.3	Partial (PACF)	Time domain 	5	In time series analysis, the partial autocorrelation function (PACF) gives the partial correlation of a time series with its own lagged values, controlling for the values of the time series at all shorter lags. It contrasts with the autocorrelation function, which does not control for other lags.This function plays an important role in data analyses aimed at identifying the extent of the lag in an autoregressive model. The use of this function was introduced as part of the Box–Jenkins approach to time series modelling, where by plotting the partial autocorrelative functions one could determine the appropriate lags p in an AR (p) model or in an extended ARIMA (p,d,q) model.
0.1.4.3.2	0.1.4.3	Cross-correlation (XCF)	Time domain 	5	In time series analysis, the partial autocorrelation function (PACF) gives the partial correlation of a time series with its own lagged values, controlling for the values of the time series at all shorter lags. It contrasts with the autocorrelation function, which does not control for other lags. This function plays an important role in data analyses aimed at identifying the extent of the lag in an autoregressive model. The use of this function was introduced as part of the Box–Jenkins approach to time series modelling, where by plotting the partial autocorrelative functions one could determine the appropriate lags p in an AR (p) model or in an extended ARIMA (p,d,q) model.
0.1.4.3.3	0.1.4.3	ARMA model	Time domain 	5	In the statistical analysis of time series, autoregressive–moving-average (ARMA) models provide a parsimonious description of a (weakly) stationary stochastic process in terms of two polynomials, one for the autoregression and the second for the moving average. The general ARMA model was described in the 1951 thesis of Peter Whittle, Hypothesis testing in time series analysis, and it was popularized in the 1970 book by George E. P. Box and Gwilym Jenkins. Given a time series of data Xt , the ARMA model is a tool for understanding and, perhaps, predicting future values in this series. The model consists of two parts, an autoregressive (AR) part and a moving average (MA) part. The AR part involves regressing the variable on its own lagged (i.e., past) values. The MA part involves modeling the error term as a linear combination of error terms occurring contemporaneously and at various times in the past. The model is usually referred to as the ARMA(p,q) model where p is the order of the autoregressive part and q is the order of the moving average part (as defined below).
0.1.4.3.4	0.1.4.3	ARIMA model (Box–Jenkins)	Time domain 	5	In time series analysis, the Box–Jenkins method, named after the statisticians George Box and Gwilym Jenkins, applies autoregressive moving average (ARMA) or autoregressive integrated moving average (ARIMA) models to find the best fit of a time-series model to past values of a time series.
0.1.4.3.5	0.1.4.3	Autoregressive conditional heteroskedasticity (ARCH)	Time domain 	5	"In econometrics, the autoregressive conditional heteroskedasticity (ARCH) model is a statistical model for time series data that describes the variance of the current error term or innovation as a function of the actual sizes of the previous time periods' error terms; often the variance is related to the squares of the previous innovations. The ARCH model is appropriate when the error variance in a time series follows an autoregressive (AR) model; if an autoregressive moving average model (ARMA) model is assumed for the error variance, the model is a generalized autoregressive conditional heteroskedasticity (GARCH) model. ARCH models are commonly employed in modeling financial time series that exhibit time-varying volatility clustering, i.e. periods of swings interspersed with periods of relative calm. ARCH-type models are sometimes considered to be in the family of stochastic volatility models, although this is strictly incorrect since at time t the volatility is completely pre-determined (deterministic) given previous values."
0.1.4.3.6	0.1.4.3	Vector autoregression (VAR)	Time domain 	5	Vector autoregression (VAR) is a stochastic process model used to capture the linear interdependencies among multiple time series. VAR models generalize the univariate autoregressive model (AR model) by allowing for more than one evolving variable. All variables in a VAR enter the model in the same way: each variable has an equation explaining its evolution based on its own lagged values, the lagged values of the other model variables, and an error term. VAR modeling does not require as much knowledge about the forces influencing a variable as do structural models with simultaneous equations: The only prior knowledge required is a list of variables which can be hypothesized to affect each other intertemporally.
0.1.4.4	0.1.4	Frequency domain	Time series	4	Time-Series Analysis in. the Frequency Domain. A sequence is a function mapping from a set of integers, described as the index set, onto the real line or into a subset thereof. A time series is a sequence whose index corresponds to consecutive dates separated by a unit time interval.
0.1.4.4.0	0.1.4.4	Spectral density estimation	Frequency domain	5	In statistical signal processing, the goal of spectral density estimation (SDE) is to estimate the spectral density (also known as the power spectral density) of a random signal from a sequence of time samples of the signal. Intuitively speaking, the spectral density characterizes the frequency content of the signal. One purpose of estimating the spectral density is to detect any periodicities in the data, by observing peaks at the frequencies corresponding to these periodicities.
0.1.4.4.1	0.1.4.4	Fourier analysis	Frequency domain	5	The decomposition process itself is called a Fourier transformation. Its output, the Fourier transform, is often given a more specific name, which depends on the domain and other properties of the function being transformed. Moreover, the original concept of Fourier analysis has been extended over time to apply to more and more abstract and general situations, and the general field is often known as harmonic analysis. Each transform used for analysis (see list of Fourier-related transforms) has a corresponding inverse transform that can be used for synthesis.
0.1.4.4.2	0.1.4.4	Wavelet	Frequency domain	5	A wavelet is a wave-like oscillation with an amplitude that begins at zero, increases, and then decreases back to zero. It can typically be visualized as a  brief oscillation  like one recorded by a seismograph or heart monitor. Generally, wavelets are intentionally crafted to have specific properties that make them useful for signal processing. Wavelets can be combined, using a  reverse, shift, multiply and integrate  technique called convolution, with portions of a known signal to extract information from the unknown signal.
0.1.4.5	0.1.4	Exploratory analysis	Time series	4	In statistics, exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task. Exploratory data analysis was promoted by John Tukey to encourage statisticians to explore the data, and possibly formulate Hypothesis that could lead to new data collection and experiments. EDA is different from initial data analysis (IDA),  which focuses more narrowly on checking assumptions required for model fitting and hypothesis testing, and handling missing values and making transformations of variables as needed. EDA encompasses IDA.
0.1.4.6	0.1.4	Forecasting	Time series	4	Forecasting is the process of making predictions of the future based on past and present data and most commonly by analysis of trends. A commonplace example might be estimation of some variable of interest at some specified future date. Prediction is a similar, but more general term.
0.1.4.6.0	0.1.4.6	Qualitative forecasting methods	Forecasting	5	Qualitative forecasting is an estimation methodology that uses expert judgment, rather than numerical analysis. This type of forecasting relies upon the knowledge of highly experienced employees and consultants to provide insights into future outcomes.
0.1.4.6.0.0	0.1.4.6.0	Delphi method	Qualitative forecasting methods	6	The Delphi method (/ˈdɛlfaɪ/ DEL-fy) is a structured communication technique or method, originally developed as a systematic, interactive forecasting method which relies on a panel of experts. The experts answer questionnaires in two or more rounds. After each round, a facilitator or change agent provides an anonymised summary of the experts' forecasts from the previous round as well as the reasons they provided for their judgments. Thus, experts are encouraged to revise their earlier answers in light of the replies of other members of their panel. It is believed that during this process the range of the answers will decrease and the group will converge towards the  correct  answer. Finally, the process is stopped after a predefined stop criterion (e.g. number of rounds, achievement of consensus, stability of results) and the mean or median scores of the final rounds determine the results.
0.1.4.6.1	0.1.4.6	Quantitative forecasting methods	Forecasting	5	Qualitative forecasting is an estimation methodology that uses expert judgment, rather than numerical analysis. This approach is substantially different from quantitative forecasting, where historical data is compiled and analyzed to discern future trends.
0.1.4.6.1.0	0.1.4.6.1	Historical data forecasts	Quantitative forecasting methods	6	Forecasting is a technique that uses historical data as inputs to make informed estimates that are predictive in determining the direction of future trends. Businesses utilize forecasting to determine how to allocate their budgets or plan for anticipated expenses for an upcoming period of time.
0.1.4.6.1.0.0	0.1.4.6.1.0	Moving average	Historical data forecasts	7	In statistics, a moving average (rolling average or running average) is a calculation to analyze data points by creating series of averages of different subsets of the full data set. It is also called a moving mean (MM) or rolling mean and is a type of finite impulse response filter. Variations include: simple, and cumulative, or weighted forms (described below).
0.1.4.6.1.0.1	0.1.4.6.1.0	Exponential smoothing	Historical data forecasts	7	Exponential smoothing is a rule of thumb technique for smoothing time series data. Whereas in the simple moving average the past observations are weighted equally, exponential functions are used to assign exponentially decreasing weights over time. It is an easily learned and easily applied procedure for making some determination based on prior assumptions by the user, such as seasonality. Exponential smoothing is used for analysis of financial time-series data as well as the field of signal processing.
0.1.4.6.1.0.2	0.1.4.6.1.0	Trend analysis	Historical data forecasts	7	Trend analysis is the rampant practice of collecting information and attempting to spot a pattern. In some fields of study, the term  trend analysis  has more formally defined meanings. Although trend analysis is often used to predict future events, it could be used to estimate uncertain events in the past, such as how many ancient kings probably ruled between two dates, based on data such as the average years which other known kings reigned.
0.1.4.6.1.0.3	0.1.4.6.1.0	Decomposition of time series	Historical data forecasts	7	The decomposition of time series is a statistical method that deconstructs a time series into several components, each representing one of the underlying categories of patterns There are two principal types of decomposition which are outlined below.
0.1.4.6.1.0.4	0.1.4.6.1.0	Average approach	Historical data forecasts	7	In this approach, the predictions of all future values are equal to the mean of the past data. This approach can be used with any sort of data where past data is available.
0.1.4.6.1.0.5	0.1.4.6.1.0	Naïve approach	Historical data forecasts	7	Naïve forecasts are the most cost-effective forecasting model, and provide a benchmark against which more sophisticated models can be compared. This forecasting method is only suitable for time series data. Using the naïve approach, forecasts are produced that are equal to the last observed value. This method works quite well for economic and financial time series, which often have patterns that are difficult to reliably and accurately predict. If the time series is believed to have seasonality, seasonal naïve approach may be more appropriate where the forecasts are equal to the value from last season. The naïve method may also use a drift, which will take the last observation plus the average change from the first observation to the last observation.
0.1.4.6.1.0.6	0.1.4.6.1.0	Drift method	Historical data forecasts	7	A variation on the naïve method is to allow the forecasts to increase or decrease over time, where the amount of change over time (called the drift) is set to be the average change seen in the historical data.
0.1.4.6.1.0.7	0.1.4.6.1.0	Seasonal naïve approach	Historical data forecasts	7	The seasonal naïve method accounts for seasonality by setting each prediction to be equal to the last observed value of the same season. For example, the prediction value for all subsequent months of April will be equal to the previous value observed for April.
0.1.4.6.1.1	0.1.4.6.1	Associative (causal) forecasts	Quantitative forecasting methods	6	A forecast based upon the known causal relationship between the variable begin forecast, called the dependent variable, to other internal or external variables, called independent variables.
0.1.4.6.1.1.0	0.1.4.6.1.1	Moving average	Associative (causal) forecasts	7	"In statistics, a moving average (rolling average or running average) is a calculation to analyze data points by creating series of averages of different subsets of the full data set. It is also called a moving mean (MM) or rolling mean and is a type of finite impulse response filter. Variations include: simple, and cumulative, or weighted forms (described below).Given a series of numbers and a fixed subset size, the first element of the moving average is obtained by taking the average of the initial fixed subset of the number series. Then the subset is modified by  shifting forward ; that is, excluding the first number of the series and including the next value in the subset."
0.1.4.6.1.1.1	0.1.4.6.1.1	Simple linear regression	Associative (causal) forecasts	7	In statistics, simple linear regression is a linear regression model with a single explanatory variable. That is, it concerns two-dimensional sample points with one independent variable and one dependent variable (conventionally, the x and y coordinates in a Cartesian coordinate system) and finds a linear function (a non-vertical straight line) that, as accurately as possible, predicts the dependent variable values as a function of the independent variables. The adjective simple refers to the fact that the outcome variable is related to a single predictor.It is common to make the additional hypothesis that the ordinary least squares method should be used to minimize the residuals (vertical distances between the points of the data set and the fitted line). Under this hypothesis, the accuracy of a line through the sample points is measured by the sum of squared residuals, and the goal is to make this sum as small as possible. Other regression methods that can be used in place of ordinary least squares include least absolute deviations (minimizing the sum of absolute values of residuals) and the Theil–Sen estimator (which chooses a line whose slope is the median of the slopes determined by pairs of sample points). Deming regression (total least squares) also finds a line that fits a set of two-dimensional sample points, but (unlike ordinary least squares, least absolute deviations, and median slope regression) it is not really an instance of simple linear regression, because it does not separate the coordinates into one dependent and one independent variable and could potentially return a vertical line as its fit.
0.1.4.6.1.1.2	0.1.4.6.1.1	Regression analysis	Associative (causal) forecasts	7	In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or 'predictors'). More specifically, regression analysis helps one understand how the typical value of the dependent variable (or 'criterion variable') changes when any one of the independent variables is varied, while the other independent variables are held fixed. Most commonly, regression analysis estimates the conditional expectation of the dependent variable given the independent variables – that is, the average value of the dependent variable when the independent variables are fixed. Less commonly, the focus is on a quantile, or other location parameter of the conditional distribution of the dependent variable given the independent variables. In all cases, a function of the independent variables called the regression function is to be estimated. In regression analysis, it is also of interest to characterize the variation of the dependent variable around the prediction of the regression function using a probability distribution. A related but distinct approach is necessary condition analysis (NCA), which estimates the maximum (rather than average) value of the dependent variable for a given value of the independent variable (ceiling line rather than central line) in order to identify what value of the independent variable is necessary but not sufficient for a given value of the dependent variable.
0.1.4.6.1.1.3	0.1.4.6.1.1	Econometric model	Associative (causal) forecasts	7	Econometric models are statistical models used in econometrics. An econometric model specifies the statistical relationship that is believed to hold between the various economic quantities pertaining to a particular economic phenomenon under study. An econometric model can be derived from a deterministic economic model by allowing for uncertainty, or from an economic model which itself is stochastic. However, it is also possible to use econometric models that are not tied to any specific economic theory.A simple example of an econometric model is one that assumes that monthly spending by consumers is linearly dependent on consumers' income in the previous month. Then the model will consist of the equation {\displaystyle C_{t}=a+bY_{t-1}+e_{t},} C_{t}=a+bY_{{t-1}}+e_{t},
0.1.5	0.1	Survival analysis	Analysis	3	Survival analysis is a branch of statistics for analyzing the expected duration of time until one or more events happen, such as death in biological organisms and failure in mechanical systems.
0.1.5.0	0.1.5	Survival function	Survival analysis	4	The survival function is a function that gives the probability that a patient, device, or other object of interest will survive beyond any given specified time. The survival function is also known as the survivor function or reliability function.The term reliability function is common in engineering while the term survival function is used in a broader range of applications, including human mortality. Another name for the survival function is the complementary cumulative distribution function.
0.1.5.1	0.1.5	Hazard function	Survival analysis	4	Failure rate is the frequency with which an engineered system or component fails, expressed in failures per unit of time. It is often denoted by the Greek letter λ (lambda) and is highly used in reliability engineering. The failure rate of a system usually depends on time, with the rate varying over the life cycle of the system. For example, an automobile's failure rate in its fifth year of service may be many times greater than its failure rate during its first year of service. One does not expect to replace an exhaust pipe, overhaul the brakes, or have major transmission problems in a new vehicle.
0.1.5.2	0.1.5	Log-rank test	Survival analysis	4	In statistics, the log-rank test is a hypothesis test to compare the survival distributions of two samples. It is a nonparametric test and appropriate to use when the data are right skewed and censored (technically, the censoring must be non-informative). It is widely used in clinical trials to establish the efficacy of a new treatment in comparison with a control treatment when the measurement is the time to event (such as the time from initial treatment to a heart attack). The test is sometimes called the Mantel–Cox test, named after Nathan Mantel and David Cox. The log-rank test can also be viewed as a time-stratified Cochran–Mantel–Haenszel test.
0.1.6	0.1	Spatial data	Analysis	3	Spatial analysis or spatial statistics includes any of the formal techniques which study entities using their topological, geometric, or geographic properties. Spatial analysis includes a variety of techniques, many still in their early development, using different analytic approaches and applied in fields as diverse as astronomy, with its studies of the placement of galaxies in the cosmos, to chip fabrication engineering, with its use of  place and route  algorithms to build complex wiring structures. In a more restricted sense, spatial analysis is the technique applied to structures at the human scale, most notably in the analysis of geographic data. Complex issues arise in spatial analysis, many of which are neither clearly defined nor completely resolved, but form the basis for current research. The most fundamental of these is the problem of defining the spatial location of the entities being studied.
0.1.7	0.1	Statistical models	Analysis	3	 A statistical model is a mathematical model that embodies a set of statistical assumptions concerning the generation of some sample data and similar data from a larger population. A statistical model represents, often in considerably idealized form, the data-generating process.
0.1.7.0	0.1.7	Deterministic system	Statistical models	4	In mathematics and physics, a deterministic system is a system in which no randomness is involved in the development of future states of the system. A deterministic model will thus always produce the same output from a given starting condition or initial state.
0.1.7.1	0.1.7	Econometric model	Statistical models	4	Econometric models are statistical models used in econometrics. An econometric model specifies the statistical relationship that is believed to hold between the various economic quantities pertaining to a particular economic phenomenon under study. An econometric model can be derived from a deterministic economic model by allowing for uncertainty, or from an economic model which itself is stochastic. However, it is also possible to use econometric models that are not tied to any specific economic theory.
0.1.7.2	0.1.7	Graphical model	Statistical models	4	A graphical model or probabilistic graphical model (PGM) is a probabilistic model for which a graph expresses the conditional dependence structure between random variables. They are commonly used in probability theory, statistics—particularly Bayesian statistics—and machine learning.
0.1.7.3	0.1.7	Identifiability	Statistical models	4	In statistics, identifiability is a property which a model must satisfy in order for precise inference to be possible. A model is identifiable if it is theoretically possible to learn the true values of this model’s underlying parameters after obtaining an infinite number of observations from it. Mathematically, this is equivalent to saying that different values of the parameters must generate different probability distributions of the observable variables. Usually the model is identifiable only under certain technical restrictions, in which case the set of these requirements is called the identification conditions.
0.1.7.4	0.1.7	Regression analysis	Statistical models	4	In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or 'predictors'). More specifically, regression analysis helps one understand how the typical value of the dependent variable (or 'criterion variable') changes when any one of the independent variables is varied, while the other independent variables are held fixed. Most commonly, regression analysis estimates the conditional expectation of the dependent variable given the independent variables – that is, the average value of the dependent variable when the independent variables are fixed. Less commonly, the focus is on a quantile, or other location parameter of the conditional distribution of the dependent variable given the independent variables. In all cases, a function of the independent variables called the regression function is to be estimated. In regression analysis, it is also of interest to characterize the variation of the dependent variable around the prediction of the regression function using a probability distribution. A related but distinct approach is necessary condition analysis (NCA), which estimates the maximum (rather than average) value of the dependent variable for a given value of the independent variable (ceiling line rather than central line) in order to identify what value of the independent variable is necessary but not sufficient for a given value of the dependent variable.
0.1.7.5	0.1.7	Scientific modelling	Statistical models	4	Scientific modelling is a scientific activity, the aim of which is to make a particular part or feature of the world easier to understand, define, quantify, visualize, or simulate by referencing it to existing and usually commonly accepted knowledge. It requires selecting and identifying relevant aspects of a situation in the real world and then using different types of models for different aims, such as conceptual models to better understand, operational models to operationalize, mathematical models to quantify, and graphical models to visualize the subject. Modelling is an essential and inseparable part of many scientific disciplines, each of which have their own ideas about specific types of modelling.There is also an increasing attention to scientific modelling in fields such as science education, philosophy of science, systems theory, and knowledge visualization. There is growing collection of methods, techniques and meta-theory about all kinds of specialized scientific modelling.
0.1.7.6	0.1.7	Statistical inference	Statistical models	4	"Statistical inference is the process of deducing properties of an underlying probability distribution by analysis of data. Inferential statistical analysis infers properties about a population: this includes testing Hypothesis and deriving estimates. The population is assumed to be larger than the observed data set; in other words, the observed data is assumed to be sampled from a larger population. Inferential statistics can be contrasted with descriptive statistics. Descriptive statistics is solely concerned with properties of the observed data, and does not assume that the data came from a larger population."
0.1.7.7	0.1.7	Statistical theory	Statistical models	4	"The theory of statistics provides a basis for the whole range of techniques, in both study design and data analysis, that are used within applications of statistics. The theory covers approaches to statistical-decision problems and to statistical inference, and the actions and deductions that satisfy the basic principles stated for these different approaches. Within a given approach, statistical theory gives ways of comparing statistical procedures; it can find a best possible procedure within a given context for given statistical problems, or can provide guidance on the choice between alternative procedures. Apart from philosophical considerations about how to make statistical inferences and decisions, much of statistical theory consists of mathematical statistics, and is closely linked to probability theory, to utility theory, and to optimization."
0.1.7.8	0.1.7	Stochastic process	Statistical models	4	In probability theory and related fields, a stochastic or random process is a mathematical object usually defined as a collection of random variables. Historically, the random variables were associated with or indexed by a set of numbers, usually viewed as points in time, giving the interpretation of a stochastic process representing numerical values of some system randomly changing over time, such as the growth of a bacterial population, an electrical current fluctuating due to thermal noise, or the movement of a gas molecule. Stochastic processes are widely used as mathematical models of systems and phenomena that appear to vary in a random manner. They have applications in many disciplines including sciences such as biology, chemistry, ecology, neuroscience, and physics as well as technology and engineering fields such as image processing, signal processing, information theory, computer science, cryptography and telecommunications. Furthermore, seemingly random changes in financial markets have motivated the extensive use of stochasic processes in finance.
0.1.7.9	0.1.7	System identification	Statistical models	4	The field of system identificationNote a uses statistical methods to build mathematical models of dynamical systems from measured data. System identification also includes the optimal design of experiments for efficiently generating informative data for fitting such models as well as model reduction.
0.1.8	0.1	Predictive analytics	Analysis	3	Predictive analytics is the practice of extracting information from existing data sets in order to determine patterns and predict future outcomes and trends. Predictive analytics does not tell you what will happen in the future.
0.1.8.0	0.1.8	Machine learning 	Predictive analytics	4	"Machine learning is a field of computer science that uses statistical techniques to give computer systems the ability to ""learn"" (e.g., progressively improve performance on a specific task) with data, without being explicitly programmed."
0.1.8.0.0	0.1.8.0	Supervised Learning	Machine learning 	5	Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.
0.1.8.0.0.0	0.1.8.0.0	Regression	Supervised Learning	6	In a narrower sense, regression may refer specifically to the estimation of continuous response (dependent) variables, as opposed to the discrete response variables used in classification.[5] The case of a continuous dependent variable may be more specifically referred to as metric regression to distinguish it from related problems.
0.1.8.0.0.0.0	0.1.8.0.0.0	Parametric	Regression	7	Regression is the process of fitting models to data. The regression process depends on the model. If a model is parametric, regression estimates the parameters from the data. If a model is linear in the parameters, estimation is based on methods from linear algebra that minimize the norm of a residual vector.
0.1.8.0.0.0.0.0	0.1.8.0.0.0.0	Linear Regression	Parametric	8	In statistics, linear regression is a linear approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X.
0.1.8.0.0.0.0.1	0.1.8.0.0.0.0	Multiple Regression	Parametric	8	Multiple regression is a statistical tool used to derive the value of a criterion from several other independent, or predictor, variables. It is the simultaneous combination of multiple factors to assess how and to what extent they affect a certain outcome.
0.1.8.0.0.0.0.2	0.1.8.0.0.0.0	Logit linear Regression 	Parametric	8	Binary logistic regression is used to predict the odds of being a case based on the values of the independent variables (predictors). ... In addition, linear regression may make nonsensical predictions for a binary dependent variable.
0.1.8.0.0.0.0.3	0.1.8.0.0.0.0	Regularized Logistic Regression	Parametric	8	In mathematics, statistics, and computer science, particularly in the fields of machine learning and inverse problems, regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting.
0.1.8.0.0.0.0.4	0.1.8.0.0.0.0	Multivariate Logit Regression	Parametric	8	In a regression model,  multiple  denotes several predictors/independent variables. On the other hand,  multivariate  is used to mean several (2 or more) responses/ dependent variables. To this end, multivariate logistic regression is a logistic regression with more than one binary outcome
0.1.8.0.0.0.0.5	0.1.8.0.0.0.0	Generalized linear models	Parametric	8	In statistics, the generalized linear model (GLM) is a flexible generalization of ordinary linear regression that allows for response variables that have error distribution models other than a normal distribution.
0.1.8.0.0.0.0.6	0.1.8.0.0.0.0	Stepwise Regression	Parametric	8	In statistics, stepwise regression is a method of fitting regression models in which the choice of predictive variables is carried out by an automatic procedure. In each step, a variable is considered for addition to or subtraction from the set of explanatory variables based on some prespecified criterion.
0.1.8.0.0.0.0.7	0.1.8.0.0.0.0	Lasso Regression	Parametric	8	In statistics and machine learning, lasso (least absolute shrinkage and selection operator) (also Lasso or LASSO) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces.
0.1.8.0.0.0.0.8	0.1.8.0.0.0.0	Ridge Regression	Parametric	8	Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity. When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value.
0.1.8.0.0.0.0.9	0.1.8.0.0.0.0	Elastic net	Parametric	8	In statistics and, in particular, in the fitting of linear or logistic regression models, the elastic net is a regularized regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods
0.1.8.0.0.0.0.10	0.1.8.0.0.0.0	Homotopy-Based Lasso	Parametric	8	A sparse approximation is a sparse vector that approximately solves a system of equations. Techniques for finding sparse approximations have found wide use in applications such as image processing, audio processing, biology, and document analysis
0.1.8.0.0.0.0.11	0.1.8.0.0.0.0	Differential geometry and Regression	Parametric	8	Differential geometry is a mathematical discipline that uses the techniques of differential calculus, integral calculus, linear algebra and multilinear algebra to study problems in geometry.
0.1.8.0.0.0.0.12	0.1.8.0.0.0.0	Bayesian Regression	Parametric	8	In statistics, Bayesian multivariate linear regression is a Bayesian approach to multivariate linear regression, i.e. linear regression where the predicted outcome is a vector of correlated random variables rather than a single scalar random variable.
0.1.8.0.0.0.0.13	0.1.8.0.0.0.0	Locally Estimate sctaterplot Smothing Regression LOESS	Parametric	8	LOESS Curve Fitting (Local Polynomial Regression) Menu location: Analysis_LOESS. This is a method for fitting a smooth curve between two variables, or fitting a smooth surface between an outcome and up to four predictor variables. The procedure originated as LOWESS (LOcally WEighted Scatter-plot Smoother).
0.1.8.0.0.0.0.14	0.1.8.0.0.0.0	Jackknife Regression	Parametric	8	In statistics, the jackknife is a resampling technique especially useful for variance and bias estimation. ... Given a sample of size , the jackknife estimate is found by aggregating the estimates of each -sized sub-sample.
0.1.8.0.0.0.0.15	0.1.8.0.0.0.0	Single Layer perceptron SLP	Parametric	8	A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function. SLP is the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target (1 , 0).
0.1.8.0.0.0.1	0.1.8.0.0.0	Semi-Parametric 	Regression	7	Nonparametric regression is a category of regression analysis in which the predictor does not take a predetermined form but is constructed according to information derived from the data.
0.1.8.0.0.0.1.0	0.1.8.0.0.0.1	 Spline methods 	Semi-Parametric 	8	Spline interpolation. ... In the mathematical field of numerical analysis, Spline interpolation is a form of interpolation where the interpolant is a special type of piecewise polynomial called a spline. In the mathematical field of numerical analysis, Spline interpolation is a form of interpolation where the interpolant is a special type of piecewise polynomial called a spline. Spline interpolation is often preferred over polynomial interpolation because the interpolation error can be made small even when using low degree polynomials for the spline[citation needed]. Spline interpolation avoids the problem of Runges phenomenon, in which oscillation can occur between points when interpolating using high degree polynomials.
0.1.8.0.0.0.1.1	0.1.8.0.0.0.1	Multivariate addictive Regressionsplines MARS 	Semi-Parametric 	8	In statistics, multivariate adaptive regression splines (MARS) is a form of regression analysis introduced by Jerome H. Friedman in 1991. It is a non-parametric regression technique and can be seen as an extension of linear models that automatically models nonlinearities and interactions between variables.
0.1.8.0.0.0.1.2	0.1.8.0.0.0.1	Generalized additive models  	Semi-Parametric 	8	In statistics, a generalized additive model (GAM) is a generalized linear model in which the linear predictor depends linearly on unknown smooth functions of some predictor variables, and interest focuses on inference about these smooth functions.
0.1.8.0.0.0.1.2.0	0.1.8.0.0.0.1.2	GAM	Generalized additive models  	9	In statistics, a generalized additive model (GAM) is a generalized linear model in which the linear predictor depends linearly on unknown smooth functions of some predictor variables, and interest focuses on inference about these smooth functions.
0.1.8.0.0.0.1.2.1	0.1.8.0.0.0.1.2	Regression	Generalized additive models  	9	Regression
0.1.8.0.0.0.1.2.2	0.1.8.0.0.0.1.2	Classification	Generalized additive models  	9	In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.
0.1.8.0.0.0.1.3	0.1.8.0.0.0.1	Peice-wise Regression	Semi-Parametric 	8	Segmented regression, also known as piecewise regression or broken-stick regression, is a method in regression analysis in which the independent variable is partitioned into intervals and a separate line segment is fit to each interval.
0.1.8.0.0.0.1.4	0.1.8.0.0.0.1	Morse-Smale Regression	Semi-Parametric 	8	Morse-Smale regression offers a way to partition the regression function based on level sets of a defined function and that function s basins of attraction.
0.1.8.0.0.0.1.5	0.1.8.0.0.0.1	Support Vector regression	Semi-Parametric 	8	In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.
0.1.8.0.0.0.1.6	0.1.8.0.0.0.1	Extreme Learning Machines	Semi-Parametric 	8	Extreme learning machine (ELM) is a new class of single-hidden layer feedforward neural network (SLFN), which is simple in theory and fast in implementation. Zong et al. propose a weighted extreme learning machine for learning data with imbalanced class distribution, which maintains the advantages from original ELM
0.1.8.0.0.0.1.7	0.1.8.0.0.0.1	Learning Vector Quantization (LVQ)	Semi-Parametric 	8	In computer science, learning vector quantization (LVQ), is a prototype-based supervised classification algorithm. LVQ is the supervised counterpart of vector quantization systems. Vector quantization (VQ) is a classical quantization technique from signal processing that allows the modeling of probability density functions by the distribution of prototype vectors. It was originally used for data compression. It works by dividing a large set of points (vectors) into groups having approximately the same number of points closest to them. Each group is represented by its centroid point, as in k-means and some other clustering algorithms.
0.1.8.0.0.1	0.1.8.0.0	Artificial Neural Networks	Supervised Learning	6	An artificial neural network is an interconnected group of nodes, akin to the vast network of neurons in a brain. Here, each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another.
0.1.8.0.0.1.0	0.1.8.0.0.1	Multi Layer Perceptron MLP	Artificial Neural Networks	7	A multilayer perceptron (MLP) is a class of feedforward artificial neural network. An MLP consists of at least three layers of nodes. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. ... Its multiple layers and non-linear activation distinguish MLP from a linear perceptron
0.1.8.0.0.1.1	0.1.8.0.0.1	Feedforward Network FNN	Artificial Neural Networks	7	A feedforward neural network is an artificial neural network wherein connections between the units do not form a cycle. As such, it is different from recurrent neural networks. The feedforward neural network was the first and simplest type of artificial neural network devised.
0.1.8.0.0.1.6	0.1.8.0.0.1	Radial Basis Function Network	Artificial Neural Networks	7	In the field of mathematical modeling, a radial basis function network is an artificial neural network that uses radial basis functions as activation functions. The output of the network is a linear combination of radial basis functions of the inputs and neuron parameters.
0.1.8.0.0.1.7	0.1.8.0.0.1	 Spiking neural networks  	Artificial Neural Networks	7	Spiking neural networks (SNNs) fall into the third generation of neural network models, increasing the level of realism in a neural simulation. In addition to neuronal and synaptic state, SNNs also incorporate the concept of time into their operating model.
0.1.8.0.0.1.8	0.1.8.0.0.1	Multilayer Spiking Neural Networks 	Artificial Neural Networks	7	Supervised Learning in Multilayer Spiking Neural Networks. We introduce a supervised learning algorithm for multilayer spiking neural networks. The algorithm overcomes a limitation of existing learning algorithms: it can be applied to neurons firing multiple spikes in artificial neural networks with hidden layers.
0.1.8.0.0.1.9	0.1.8.0.0.1	Auto-Associative Neural Networks	Artificial Neural Networks	7	Auto associative neural networks were feed forward nets trained to produce an approximation of the identity mapping between network inputs and outputs using back propagation or similar learning procedures. The key feature of an auto associative network are a dimensional bottleneck between input and output.
0.1.8.0.0.1.10	0.1.8.0.0.1	Adjustments	Artificial Neural Networks	7	Adjustments
0.1.8.0.0.1.10.0	0.1.8.0.0.1.10	Architecture	Adjustments	8	Artificial neural network (ANN) architecture. ANNs consist of artificial neurons. ... In a commonly used ANN architecture, the multilayer perceptron, the neurons are arranged in layers. An ordered set (a vector) of predictor variables is presented to the input layer.
0.1.8.0.0.1.10.0.0	0.1.8.0.0.1.10.0	Variables type	Architecture	9	Variables type
0.1.8.0.0.1.10.0.1	0.1.8.0.0.1.10.0	Variables scaling	Architecture	9	Normalisation or scaling is not really a functional requirement for the NNs to learn, but it significantly helps as it transposes the input variables into the data range that t. he sigmoid. In real biological neural networks normalization missing.
0.1.8.0.0.1.10.0.2	0.1.8.0.0.1.10.0	Cost function	Architecture	9	"A cost function is a measure of ""how good"" a neural network did with respect to it's given training sample and the expected output. It also may depend on variables such as weights and biases. A cost function is a single value, not a vector, because it rates how good the neural network did as a whole."
0.1.8.0.0.1.10.0.3	0.1.8.0.0.1.10.0	Neural netwok type	Architecture	9	Neural netwoktype
0.1.8.0.0.1.10.0.4	0.1.8.0.0.1.10.0	Number of layers	Architecture	9	Number of layers
0.1.8.0.0.1.10.0.5	0.1.8.0.0.1.10.0	Numbers of hidden layers	Architecture	9	A hidden layer in an artificial neural network is a layer in between input layers and output layers, where artificial neurons take in a set of weighted inputs and produce an output through an activation function.
0.1.8.0.0.1.10.0.6	0.1.8.0.0.1.10.0	Number of nodes	Architecture	9	Number of nodes
0.1.8.0.0.1.10.0.7	0.1.8.0.0.1.10.0	Type of layers	Architecture	9	Type of layers
0.1.8.0.0.1.10.0.8	0.1.8.0.0.1.10.0	Type of weight initialization	Architecture	9	Type of weight initialization
0.1.8.0.0.1.10.0.9	0.1.8.0.0.1.10.0	Type of activation function	Architecture	9	"In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs. A standard computer chip circuit can be seen as a digital network of activation functions that can be ""ON"" (1) or ""OFF"" (0), depending on input."
0.1.8.0.0.1.10.0.10	0.1.8.0.0.1.10.0	Dropout rate(or not)	Architecture	9	Dropout rate(or not)
0.1.8.0.0.1.10.0.11	0.1.8.0.0.1.10.0	Threshold	Architecture	9	A threshold function is one of a series of activation functions — sigmoid and tanh are others — that are used when performing classification in neural networks. Activation in neural networks is explained here.
0.1.8.0.0.1.10.1	0.1.8.0.0.1.10	Hyperparameter tunning	Adjustments	8	Neural Network Hyperparameters. Hyperparameters are often set by hand, selected by some search algorithm, or optimized by some “hyper-learner”. Neural networks can have many hyperparameters, including those which specify the structure of the network itself and those which determine how the network is trained.
0.1.8.0.0.1.10.1.0	0.1.8.0.0.1.10.1	Type of optimizer	Hyperparameter tunning	9	It is the most popular Optimization algorithms used in optimizing a Neural Network. Now gradient descent is majorly used to do Weights updates in a Neural Network Model , i.e update and tune the Model's parameters in a direction so that we can minimize the Loss function.
0.1.8.0.0.1.10.1.1	0.1.8.0.0.1.10.1	Learning rate	Hyperparameter tunning	9	Learning rate is defined in the context of optimization, and minimizing the loss function of a neural network. For this optimization problem, we use gradient descent or other variants of it where the model paramaters (here weights and biases in the network) are updated in a way to decrease the cost function.
0.1.8.0.0.1.10.1.2	0.1.8.0.0.1.10.1	Regularization rate	Hyperparameter tunning	9	In mathematics, statistics, and computer science, particularly in the fields of machine learning and inverse problems, regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting.
0.1.8.0.0.1.10.1.3	0.1.8.0.0.1.10.1	Regularization Type	Hyperparameter tunning	9	In mathematics, statistics, and computer science, particularly in the fields of machine learning and inverse problems, regularization is a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting.
0.1.8.0.0.1.10.1.4	0.1.8.0.0.1.10.1	Type of search for local minima	Hyperparameter tunning	9	Local minima free neural network learning. This technique searches the parameter space, defined by the network weights, to define initial regions of attraction with candidates for local minima, and then exploits each region to locate the minima, and to determine a global minimum.
0.1.8.0.0.1.10.1.5	0.1.8.0.0.1.10.1	Decay rate	Hyperparameter tunning	9	Weight decay is defined as multiplying each weight in the gradient descent at each epoch by a factor λ\lambda smaller than one and greater than zero. This technique is equivalent to introducing an L2L_{2} regularization term to the cost function that one wants to optimize.
0.1.8.0.0.1.10.1.6	0.1.8.0.0.1.10.1	Momentum 	Hyperparameter tunning	9	Neural network momentum is a simple technique that often improves both training speed and accuracy. Training a neural network is the process of finding values for the weights and biases so that for a given set of input values, the computed output values closely match the known, correct, target values.
0.1.8.0.0.1.10.1.7	0.1.8.0.0.1.10.1	Type of fitness measurement	Hyperparameter tunning	9	A fitness function is a particular type of objective function that is used to summarise, as a single figure of merit, how close a given design solution is to achieving the set aims.
0.1.8.0.0.1.10.1.8	0.1.8.0.0.1.10.1	Epochs	Hyperparameter tunning	9	"An epoch is a single step in training a neural network; in other words when a neural network is trained on every training samples only in one pass we say that one epoch is finished. So training process may consist more than one epochs."
0.1.8.0.0.1.10.1.9	0.1.8.0.0.1.10.1	Stop criteria	Hyperparameter tunning	9	Do I keep training a neural network until the minimum mse is obtained and stop, the point you find it becomes constant and do not decrease means you do not.
0.1.8.0.0.2	0.1.8.0.0	Bayesian (Probabilistic Classifiers)	Supervised Learning	6	In machine learning, a probabilistic classifier is a classifier that is able to predict, given an observation of an input, a probability distribution over a set of classes, rather than only outputting the most likely class that the observation should belong to.
0.1.8.0.0.2.0	0.1.8.0.0.2	Bayesian Belief Network	Bayesian (Probabilistic Classifiers)	7	"Bayesian network, Bayes network, belief network, Bayes(ian) model or probabilistic directed acyclic graphical model is a probabilistic graphical model (a type of statistical model) that represents a set of random variables and their conditional dependencies via a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases.Formally, Bayesian networks are DAGs whose nodes represent random variables in the Bayesian sense: they may be observable quantities, latent variables, unknown parameters or Hypothesis. Edges represent conditional dependencies; nodes that are not connected (there is no path from one of the variables to the other in the Bayesian network) represent variables that are conditionally independent of each other. Each node is associated with a probability function that takes, as input, a particular set of values for the node's parent variables, and gives (as output) the probability (or probability distribution, if applicable) of the variable represented by the node. For example, if m   {\displaystyle m}  m parent nodes represent m   {\displaystyle m}  m Boolean variables then the probability function could be represented by a table of 2 m     {\displaystyle 2^{m}}  2^{m} entries, one entry for each of the 2 m     {\displaystyle 2^{m}}  2^{m} possible combinations of its parents being true or false. Similar ideas may be applied to undirected, and possibly cyclic, graphs; such as Markov networks."
0.1.8.0.0.2.1	0.1.8.0.0.2	Naive Bayes (NB)	Bayesian (Probabilistic Classifiers)	7	In machine learning, naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features.Naive Bayes has been studied extensively since the 1950s. It was introduced under a different name into the text retrieval community in the early 1960s, :488 and remains a popular (baseline) method for text categorization, the problem of judging documents as belonging to one category or the other (such as spam or legitimate, sports or politics, etc.) with word frequencies as the features. With appropriate pre-processing, it is competitive in this domain with more advanced methods including support vector machines.  It also finds application in automatic medical diagnosis.Naive Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem. Maximum-likelihood training can be done by evaluating a closed-form expression, :718 which takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers.In the statistics and computer science literature, Naive Bayes models are known under a variety of names, including simple Bayes and independence Bayes.[4] All these names reference the use of Bayes' theorem in the classifier's decision rule, but naive Bayes is not (necessarily) a Bayesian method.
0.1.8.0.0.2.2	0.1.8.0.0.2	Bayesian Networks	Bayesian (Probabilistic Classifiers)	7	A Bayesian network, Bayes network, belief network, Bayes(ian) model or probabilistic directed acyclic graphical model is a probabilistic graphical model (a type of statistical model) that represents a set of random variables and their conditional dependencies via a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases.
0.1.8.0.0.3	0.1.8.0.0	Decision trees 	Supervised Learning	6	Decision tree learning uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining and machine learning.
0.1.8.0.0.3.0	0.1.8.0.0.3	Single decision tree model	Decision trees 	7	"Decision tree learning is a method commonly used in data mining. The goal is to create a model that predicts the value of a target variable based on several input variables. ... Each interior node corresponds to one of the input variables; there are edges to children for each of the possible values of that input variable."
0.1.8.0.0.3.1	0.1.8.0.0.3	Iterative dichotomizer 3 (ID3)	Decision trees 	7	In decision tree learning, ID3 (Iterative Dichotomiser 3) is an algorithm invented by Ross Quinlan used to generate a decision tree from a dataset. ID3 is the precursor to the C4.5 algorithm, and is typically used in the machine learning and natural language processing domains.
0.1.8.0.0.3.2	0.1.8.0.0.3	C4.5/5.0	Decision trees 	7	C4.5 is an algorithm used to generate a decision tree developed by Ross Quinlan. ... The decision trees generated by C4.5 can be used for classification, and for this reason, C4.5 is often referred to as a statistical classifier.
0.1.8.0.0.3.3	0.1.8.0.0.3	Classification and Regression Tree (CART)	Decision trees 	7	Classification and Regression Trees or CART for short is a term introduced by Leo Breiman to refer to Decision Tree algorithms that can be used for classification or regression predictive modeling problems.Apr 7, 2016
0.1.8.0.0.3.4	0.1.8.0.0.3	M5	Decision trees 	7	"M5 model tree is a decision tree learner for regression task, meaning that it is used to predict values of numerical response variable Y. While M5 tree employs the same approach with CART tree in choosing mean squared error as impurity function, it does not assign a constant to the leaf node but instead it fit a multivariate linear regression model; the model tree is thus analogous to piecewise linear functions. According to, M5 model tree can learn efficiently and can handle tasks with very high dimensionality - up to hundreds of attributes. This ability sets M5 apart from regression tree learners at the time (like MARS), whose computational cost grows very quickly when the number of features increases. Also, the advantage of M5 over CART is that model trees are generally much smaller than regression trees and have proven more accurate in the tasks investigated."
0.1.8.0.0.3.5	0.1.8.0.0.3	Multivariate Adaptive Regression Splines (MARS)	Decision trees 	7	In statistics, multivariate adaptive regression splines (MARS) is a form of regression analysis introduced by Jerome H. Friedman in 1991. It is a non-parametric regression technique and can be seen as an extension of linear models that automatically models nonlinearities and interactions between variables.
0.1.8.0.0.3.6	0.1.8.0.0.3	Decision Stump	Decision trees 	7	A decision stump is a machine learning model consisting of a one-level decision tree. That is, it is a decision tree with one internal node (the root) which is immediately connected to the terminal nodes (its leaves). A decision stump makes a prediction based on the value of just a single input feature.
0.1.8.0.0.3.7	0.1.8.0.0.3	Chi-squared Automatic Interaction Detection(CHAID )	Decision trees 	7	Chi-square automatic interaction detection (CHAID) is a decision tree technique, based on adjusted significance testing (Bonferroni testing).
0.1.8.0.0.3.8	0.1.8.0.0.3	Gradient Boosting Machines (GBM)	Decision trees 	7	Friedman introduced his regression technique as a Gradient Boosting Machine (GBM). ... described the generalized abstract class of algorithms as functional gradient boosting. A popular open-source implementation for R calls it Generalized Boosting Model.
0.1.8.0.0.3.9	0.1.8.0.0.3	Random Forests	Decision trees 	7	Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the ...
0.1.8.0.0.3.10	0.1.8.0.0.3	Conditional decision trees	Decision trees 	7	A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.
0.1.8.0.0.3.11	0.1.8.0.0.3	General	Decision trees 	7	General
0.1.8.0.0.3.11.0	0.1.8.0.0.3.11	Measure used to select input variable	General	8	Measure used to select input variable
0.1.8.0.0.3.11.0.0	0.1.8.0.0.3.11.0	Gini impurity	Measure used to select input variable	9	"Node impurity represents how well the trees split the data. There are several impurity measures; one option is the Gini index. When determining the importance in the variable, you can use the mean decrease in accuracy (i.e. misclassification) or mean decrease in node impurity (i.e. Gini index)."
0.1.8.0.0.3.11.0.1	0.1.8.0.0.3.11.0	Entropy	Measure used to select input variable	9	Entropy, as it relates to machine learning, is a measure of the randomness in the information being processed. The higher the entropy, the harder it is to draw any conclusions from that information. Flipping a coin is an example of an action that provides information that is random.
0.1.8.0.0.3.11.0.2	0.1.8.0.0.3.11.0	Information gain	Measure used to select input variable	9	A notable problem occurs when information gain is applied to attributes that can take on a large number of distinct values. For example, suppose that one is building a decision tree for some data describing the customers of a business.
0.1.8.0.0.3.11.0.3	0.1.8.0.0.3.11.0	Chi-square	Measure used to select input variable	9	The Chi-square statistic is a non-parametric (distribution free) tool. This means that a different test must be used if the two groups are related.
0.1.8.0.0.3.11.0.4	0.1.8.0.0.3.11.0	 J-way ANOVA for continuous/ordinal variables	Measure used to select input variable	9	In statistics, one-way analysis of variance (abbreviated one-way ANOVA) is a technique that can be used to compare means of two or more samples (using the F distribution). The ANOVA tests the null hypothesis that samples in all groups are drawn from populations with the same mean values.
0.1.8.0.0.3.11.1	0.1.8.0.0.3.11	Pruning	General	8	Pruning is a technique in machine learning that reduces the size of decision trees by removing sections of the tree that provide little power to classify instances. Pruning reduces the complexity of the final classifier, and hence improves predictive accuracy by the reduction of overfitting.
0.1.8.0.0.3.11.2	0.1.8.0.0.3.11	Dependent variable	General	8	"Response , usually denoted by Y , is the variable being predicted in supervised learning; also called. dependent variable, output variable, target variable or outcome variable. Score refers to a predicted value or class. "" Scoring new data"" means to use a model developed with."
0.1.8.0.0.3.11.3	0.1.8.0.0.3.11	Input variables	General	8	The more rows you have, the more examples from the problem domain. Those columns that are the inputs are referred to as input variables.
0.1.8.0.0.3.11.4	0.1.8.0.0.3.11	Split	General	8	"A tree can be ""learned"" by splitting the source set into subsets based on an attribute value test. ... This process of top-down induction of decision trees (TDIDT) is an example of a greedy algorithm, and it is by far the most common strategy for learning decision trees from data."
0.1.8.0.0.3.11.5	0.1.8.0.0.3.11	Nodes	General	8	Decision Tree - Classification. Leaf node (e.g., Play) represents a classification or decision. The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data.
0.1.8.0.0.3.11.5.0	0.1.8.0.0.3.11.5	Root nodes	nodes	9	To create a tree, we need to have a root node first and we know that nodes are. In order to define information gain precisely, we will code this algorithm from scratch (without using any ML libraries).
0.1.8.0.0.3.11.5.1	0.1.8.0.0.3.11.5	Internal nodes	nodes	9	Internal node. (definition) Definition: A node of a tree that has one or more child nodes, equivalently, one that is not a leaf. Also known as nonterminal node. See also parent, root.
0.1.8.0.0.3.11.5.2	0.1.8.0.0.3.11.5	Leaf	nodes	9	The end of the branch that doesn't split anymore is the decision/leaf
0.1.8.0.1	0.1.8.0	Ensemble learning	Machine learning 	5	An ensemble is itself a supervised learning algorithm, because it can be trained and then used to make predictions. The trained ensemble, therefore, represents a single hypothesis.
0.1.8.0.1.0	0.1.8.0.1	Gradient descent Methods 	Ensemble learning	6	Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or of the approximate gradient) of the function at the current point.
0.1.8.0.1.1	0.1.8.0.1	Genetic algorithms	Ensemble learning	6	A genetic algorithm is a heuristic search method used in artificial intelligence and computing. It is used for finding optimized solutions to search problems based on the theory of natural selection and evolutionary biology. Genetic algorithms are excellent for searching through large and complex data sets.
0.1.8.0.1.2	0.1.8.0.1	Quantum evolutionary methods	Ensemble learning	6	These Quantum Inspired Evolutionary Algorithms (QIEA) were binary encoded evolutionary optimisation techniques, used to solve binary encoded problems [1, 2]. Their signature feature follows superposition of multiple states on a quantum bit (Qbit).
0.1.8.0.1.3	0.1.8.0.1	Boosted Regression methods	Ensemble learning	6	Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.
0.1.8.0.1.4	0.1.8.0.1	XGboost	Ensemble learning	6	XGBoost is an algorithm that has recently been dominating applied machine learning and Kaggle competitions for structured or tabular data. XGBoost is an implementation of gradient boosted decision trees designed for speed and performance
0.1.8.0.1.5	0.1.8.0.1	Random Forests	Ensemble learning	6	Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) 
0.1.8.0.1.6	0.1.8.0.1	Unsupervised with supervised models	Ensemble learning	6	Unsupervised with supervised models
0.1.8.0.1.6.0	0.1.8.0.1.6	Superlearners	Unsupervised with supervised models	7	Simulations and data analysis suggest this new proposed super learner superior to competing methods. This approach for construction of a super learner generalizes to any parameter which can be defined as a minimizer of a loss function.
0.1.8.0.1.6.1	0.1.8.0.1.6	Subensembles	Unsupervised with supervised models	7	Stacking Multiple Machine Learning Models. Stacking, also known as stacked generalization, is an ensemble method where the models are combined using another machine learning algorithm. ... Then this new dataset is used as input for the combiner machine learning algorithm.
0.1.8.0.1.6.2	0.1.8.0.1.6	SuperEnsembles	Unsupervised with supervised models	7	Stacking Multiple Machine Learning Models. Stacking, also known as stacked generalization, is an ensemble method where the models are combined using another machine learning algorithm. ... Then this new dataset is used as input for the combiner machine learning algorithm.
0.1.8.0.1.6.3	0.1.8.0.1.6	Ensemblers	Unsupervised with supervised models	7	Ensemble methods are meta-algorithms that combine several machine learning techniques into one predictive model in order to decrease variance (bagging), bias (boosting), or improve predictions (stacking). ... sequential ensemble methods where the base learners are generated sequentially (e.g. AdaBoost).
0.1.8.0.1.6.3.0	0.1.8.0.1.6.3	Logit boosting (booster)	Ensemblers	8	In machine learning and computational learning theory, LogitBoost is a boosting algorithm formulated by Jerome Friedman, Trevor Hastie, and Robert Tibshirani. The original paper casts the AdaBoost algorithm into a statistical framework. Specifically, if one considers AdaBoost as a generalized additive model and then applies the cost functional of logistic regression, one can derive the LogitBoost algorithm..
0.1.8.0.1.6.3.1	0.1.8.0.1.6.3	Booststrapped Agreggation (Bagging)	Ensemblers	8	Bootstrap aggregating, also called bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting.
0.1.8.0.1.6.3.2	0.1.8.0.1.6.3	Ada Boost	Ensemblers	8	AdaBoost, short for Adaptive Boosting, is a machine learning meta-algorithm formulated by Yoav Freund and Robert Schapire who won the Gödel Prize in 2003 for their work. It can be used in conjunction with many other types of learning algorithms to improve their performance.
0.1.8.0.1.6.3.3	0.1.8.0.1.6.3	Stacked generalization (Blending)	Ensemblers	8	Stacked generalization (or stacking) (Wolpert, 1992) is a different way of combining multiple models, that introduces the concept of a meta learner. ... Using the predictions from 3) as the inputs, and the correct responses as the outputs, train a higher level learner.
0.1.8.0.1.6.3.4	0.1.8.0.1.6.3	Gradient Boosting Machines	Ensemblers	8	Gradient boosting machines are a family of powerful machine-learning techniques that have shown considerable success in a wide range of practical applications. They are highly customizable to the particular needs of the application, like being learned with respect to different loss functions.Dec 4, 2013
0.1.8.0.1.6.3.5	0.1.8.0.1.6.3	Gradient Boosting Regression trees	Ensemblers	8	Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.
0.1.8.0.1.6.3.6	0.1.8.0.1.6.3	Random forests as extensions	Ensemblers	8	Random forests or random decision forests are an ensemble learning method for classification, ... The extension combines Breimans bagging idea and random selection of features
0.1.8.0.2	0.1.8.0	Unsupervised Learning	Machine learning 	5	Unsupervised learning is a type of machine learning algorithm used to draw inferences from datasets consisting of input data without labeled responses. The most common unsupervised learning method is cluster analysis, which is used for exploratory data analysis to find hidden patterns or grouping in data.
0.1.8.0.2.0	0.1.8.0.2	Clustering	Unsupervised Learning	6	Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).
0.1.8.0.2.0.0	0.1.8.0.2.0	K-means Clustering	Clustering	7	The K-means algorithm involves randomly selecting K initial centroids where K is a user defined number of desired clusters. Each point is then assigned to a closest centroid and the collection of points close to a centroid form a cluster.
0.1.8.0.2.0.1	0.1.8.0.2.0	Graph Based techniques	Clustering	7	Graph algorithms solve problems related to graph theory
0.1.8.0.2.0.2	0.1.8.0.2.0	Spectral Clustering	Clustering	7	In multivariate statistics and the clustering of data, spectral clustering techniques make use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions.
0.1.8.0.2.0.3	0.1.8.0.2.0	Morse-smale Clustering 	Clustering	7	"The Morse-Smale complex has several useful applications in statistics. Density mode clustering (also known as mean shift clustering (Fukunaga and Hostetler, 1975)) implicitly uses the Morse- Smale complex; the clusters are the basins of attraction of the modes which correspond to certain crystals.Jul 1, 2015"
0.1.8.0.2.0.4	0.1.8.0.2.0	Mapper Clustering	Clustering	7	Mapper is an algorithm for describing high-dimensional datasets in terms of simple geometric objects. We give a new definition of Mapper, with which we are able to prove that Mapper is a functor and that Mapper is a homotopy equivalence for certain “nice” input data.
0.1.8.0.2.0.4.0	0.1.8.0.2.0.4	Clustering	Mapper Clustering	8	Our method, called Mapper, is based on the idea of partial clustering of the data guided by a set of functions defined on the data. The proposed method is not dependent on any particular clustering algorithm, i.e. any clustering algorithm may be used with Mapper.
0.1.8.0.2.0.4.1	0.1.8.0.2.0.4	Self organizing Map (Kohonen SOM)	Mapper Clustering	8	A self-organizing map (SOM) or self-organizing feature map (SOFM) is a type of artificial neural network (ANN) that is trained using unsupervised learning to produce a low-dimensional (typically two-dimensional), discretized representation of the input space of the training samples, called a map. Is a computational method for the visualization and analysis of high-dimensional data, especially experimentally acquired information.
0.1.8.0.2.0.4.2	0.1.8.0.2.0.4	Clustering	Mapper Clustering	8	Clustering
0.1.8.0.2.0.4.2.0	0.1.8.0.2.0.4.2	Connectivity Models	Clustering	9	"Connectivity-based clustering, also known as hierarchical clustering, is based on the core idea of objects being more related to nearby objects than to objects farther away. These algorithms connect ""objects"" to form ""clusters"" based on their distance. A cluster can be described largely by the maximum distance needed to connect parts of the cluster. At different distances, different clusters will form, which can be represented using a dendrogram, which explains where the common name ""hierarchical clustering"" comes from: these algorithms do not provide a single partitioning of the data set, but instead provide an extensive hierarchy of clusters that merge with each other at certain distances. In a dendrogram, the y-axis marks the distance at which the clusters merge, while the objects are placed along the x-axis such that the clusters don't mix. Connectivity-based clustering is a whole family of methods that differ by the way distances are computed. Apart from the usual choice of distance functions, the user also needs to decide on the linkage criterion (since a cluster consists of multiple objects, there are multiple candidates to compute the distance) to use. Popular choices are known as single-linkage clustering (the minimum of object distances), complete linkage clustering (the maximum of object distances) or UPGMA (""Unweighted Pair Group Method with Arithmetic Mean"", also known as average linkage clustering). Furthermore, hierarchical clustering can be agglomerative (starting with single elements and aggregating them into clusters) or divisive (starting with the complete data set and dividing it into partitions). These methods will not produce a unique partitioning of the data set, but a hierarchy from which the user still needs to choose appropriate clusters. They are not very robust towards outliers, which will either show up as additional clusters or even cause other clusters to merge (known as ""chaining phenomenon"", in particular with single-linkage clustering). In the general case, the complexity is {\displaystyle {\mathcal {O}}(n^{3})} {\mathcal {O}}(n^{3}) for agglomerative clustering and {\displaystyle {\mathcal {O}}(2^{n-1})} {\mathcal {O}}(2^{n-1}) for divisive clustering,[5] which makes them too slow for large data sets. For some special cases, optimal efficient methods (of complexity {\displaystyle {\mathcal {O}}(n^{2})} {\mathcal {O}}(n^{2})) are known: SLINK[6] for single-linkage and CLINK[7] for complete-linkage clustering. In the data mining community these methods are recognized as a theoretical foundation of cluster analysis, but often considered obsolete[citation needed]. They did however provide inspiration for many later methods such as density based clustering."
0.1.8.0.2.0.4.2.0.0	0.1.8.0.2.0.4.2.0	Hierarchical	Connectivity Models	10	"Connectivity-based clustering, also known as hierarchical clustering, is based on the core idea of objects being more related to nearby objects than to objects farther away. These algorithms connect ""objects"" to form ""clusters"" based on their distance. A cluster can be described largely by the maximum distance needed to connect parts of the cluster. At different distances, different clusters will form, which can be represented using a dendrogram, which explains where the common name ""hierarchical clustering"" comes from: these algorithms do not provide a single partitioning of the data set, but instead provide an extensive hierarchy of clusters that merge with each other at certain distances. In a dendrogram, the y-axis marks the distance at which the clusters merge, while the objects are placed along the x-axis such that the clusters don't mix. Connectivity-based clustering is a whole family of methods that differ by the way distances are computed. Apart from the usual choice of distance functions, the user also needs to decide on the linkage criterion (since a cluster consists of multiple objects, there are multiple candidates to compute the distance) to use. Popular choices are known as single-linkage clustering (the minimum of object distances), complete linkage clustering (the maximum of object distances) or UPGMA (""Unweighted Pair Group Method with Arithmetic Mean"", also known as average linkage clustering). Furthermore, hierarchical clustering can be agglomerative (starting with single elements and aggregating them into clusters) or divisive (starting with the complete data set and dividing it into partitions). These methods will not produce a unique partitioning of the data set, but a hierarchy from which the user still needs to choose appropriate clusters. They are not very robust towards outliers, which will either show up as additional clusters or even cause other clusters to merge (known as ""chaining phenomenon"", in particular with single-linkage clustering). In the general case, the complexity is {\displaystyle {\mathcal {O}}(n^{3})} {\mathcal {O}}(n^{3}) for agglomerative clustering and {\displaystyle {\mathcal {O}}(2^{n-1})} {\mathcal {O}}(2^{n-1}) for divisive clustering,[5] which makes them too slow for large data sets. For some special cases, optimal efficient methods (of complexity {\displaystyle {\mathcal {O}}(n^{2})} {\mathcal {O}}(n^{2})) are known: SLINK[6] for single-linkage and CLINK[7] for complete-linkage clustering. In the data mining community these methods are recognized as a theoretical foundation of cluster analysis, but often considered obsolete[citation needed]. They did however provide inspiration for many later methods such as density based clustering."
0.1.8.0.2.0.4.2.0.0.0	0.1.8.0.2.0.4.2.0.0	Average Linkage	Hierarchical	11	UPGMA (Unweighted Pair Group Method with Arithmetic Mean) is a simple agglomerative (bottom-up) hierarchical clustering method. The method is generally attributed to Sokal and Michener.
0.1.8.0.2.0.4.2.0.0.1	0.1.8.0.2.0.4.2.0.0	Complete Linkage	Hierarchical	11	Complete-linkage clustering is one of several methods of agglomerative hierarchical clustering. At the beginning of the process, each element is in a cluster of its own. The clusters are then sequentially combined into larger clusters until all elements end up being in the same cluster. At each step, the two clusters separated by the shortest distance are combined. The definition of 'shortest distance' is what differentiates between the different agglomerative clustering methods. In complete-linkage clustering, the link between two clusters contains all element pairs, and the distance between clusters equals the distance between those two elements (one in each cluster) that are farthest away from each other. The shortest of these links that remains at any step causes the fusion of the two clusters whose elements are involved. The method is also known as farthest neighbour clustering. The result of the clustering can be visualized as a dendrogram, which shows the sequence of cluster fusion and the distance at which each fusion took place.
0.1.8.0.2.0.4.2.0.0.2	0.1.8.0.2.0.4.2.0.0	Single Linkage	Hierarchical	11	In statistics, single-linkage clustering is one of several methods of hierarchical clustering. It is based on grouping clusters in bottom-up fashion (agglomerative clustering), at each step combining two clusters that contain the closest pair of elements not yet belonging to the same cluster as each other. A drawback of this method is that it tends to produce long thin clusters in which nearby elements of the same cluster have small distances, but elements at opposite ends of a cluster may be much farther from each other than to elements of other clusters. This may lead to difficulties in defining classes that could usefully subdivide the data.
0.1.8.0.2.0.4.2.0.0.3	0.1.8.0.2.0.4.2.0.0	Centroid Method	Hierarchical	11	In centroid method, the distance between two clusters is the distance between the two mean vectors of the clusters. At each stage of the process we combine the two clusters that have the smallest centroid distance.
0.1.8.0.2.0.4.2.0.0.4	0.1.8.0.2.0.4.2.0.0	Ward’s Method	Hierarchical	11	This method does not directly define a measure of distance between two points or clusters. It is an ANOVA based approach. At each stage, those two clusters marge, which provides the smallest increase in the combined error sum of squares from one-way univariate ANOVAs that can be done for each variable with groups defined by the clusters at that stage of the process
0.1.8.0.2.0.4.2.1	0.1.8.0.2.0.4.2	Performant	Clustering	9	Performant
0.1.8.0.2.0.4.2.1.0	0.1.8.0.2.0.4.2.1	Basic sequential algorithmic scheme BSAS	Performant	10	The basic sequential algorithmic scheme (BSAS) is a basic clustering algorithm. In the basic form vectors are presented only once and the number of clusters is not known a priori.
0.1.8.0.2.0.4.2.1.1	0.1.8.0.2.0.4.2.1	BIRCH	Performant	10	The Birch algorithm builds a dendrogram called clustering feature tree (CF tree) while scanning the data set. Each entry in the CF tree represents a cluster of objects and is characterized by a 3-tuple: (N, LS, SS), where N is the number of objects in the cluster and LS, SS are defined in the following.
0.1.8.0.2.0.4.2.2	0.1.8.0.2.0.4.2	Subspace Models	Clustering	9	The problem of subspace clustering is given by the fact that there are {\displaystyle 2^{d}} 2^{d} different subspaces of a space with {\displaystyle d} d dimensions. If the subspaces are not axis-parallel, an infinite number of subspaces is possible. Hence, subspace clustering algorithms utilize some kind of heuristic to remain computationally feasible, at the risk of producing inferior results. For example, the downward-closure property (cf. association rules) can be used to build higher-dimensional subspaces only by combining lower-dimensional ones, as any subspace T containing a cluster, will result in a full space S also to contain that cluster (i.e. S ⊆ T), an approach taken by most of the traditional algorithms such as CLIQUE,[3] SUBCLU.[4] It is also possible to define a subspace using different degrees of relevance for each dimension, an approach taken by iMWK-Means
0.1.8.0.2.0.4.2.2.0	0.1.8.0.2.0.4.2.2	CLIQUE	Subspace Models	10	Clustering high-dimensional data is the cluster analysis of data with anywhere from a few dozen to many thousands of dimensions. Such high-dimensional spaces of data are often encountered in areas such as medicine, where DNA microarray technology can produce a large number of measurements at once, and the clustering of text documents, where, if a word-frequency vector is used, the number of dimensions equals the size of the vocabulary.
0.1.8.0.2.0.4.2.3	0.1.8.0.2.0.4.2	Density Models	Clustering	9	In density-based clustering,[9] clusters are defined as areas of higher density than the remainder of the data set. Objects in these sparse areas - that are required to separate clusters - are usually considered to be noise and border points.
0.1.8.0.2.0.4.2.3.0	0.1.8.0.2.0.4.2.3	Mean-shift	Density Models	10	Mean shift is a non-parametric feature-space analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm. Application domains include cluster analysis in computer vision and image processing.
0.1.8.0.2.0.4.2.3.1	0.1.8.0.2.0.4.2.3	OPTICS	Density Models	10	Ordering points to identify the clustering structure (OPTICS) is an algorithm for finding density-based clusters in spatial data. ... Its basic idea is similar to DBSCAN, but it addresses one of DBSCAN's major weaknesses: the problem of detecting meaningful clusters in data of varying density.
0.1.8.0.2.0.4.2.3.2	0.1.8.0.2.0.4.2.3	DBSCAN	Density Models	10	Density-based spatial clustering of applications with noise (DBSCAN) is a data clustering algorithm proposed by Martin Ester, Hans-Peter Kriegel, Jörg Sander and Xiaowei Xu in 1996. It is a density-based clustering algorithm: given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions (whose nearest neighbors are too far away). DBSCAN is one of the most common clustering algorithms and also most cited in scientific literature.
0.1.8.0.2.0.4.2.4	0.1.8.0.2.0.4.2	Distribution Models	Clustering	9	The clustering model most closely related to statistics is based on distribution models. Clusters can then easily be defined as objects belonging most likely to the same distribution. A convenient property of this approach is that this closely resembles the way artificial data sets are generated: by sampling random objects from a distribution. While the theoretical foundation of these methods is excellent, they suffer from one key problem known as overfitting, unless constraints are put on the model complexity. A more complex model will usually be able to explain the data better, which makes choosing the appropriate model complexity inherently difficult.
0.1.8.0.2.0.4.2.4.0	0.1.8.0.2.0.4.2.4	Expectation-Maximization (EM) Algorithm	Distribution Models	10	The EM (expectation maximization) technique is similar to the K-Means technique. ... Instead of assigning examples to clusters to maximize the differences in means for continuous variables, the EM clustering algorithm computes probabilities of cluster memberships based on one or more probability distributions.
0.1.8.0.2.0.4.2.5	0.1.8.0.2.0.4.2	Centroid Models	Clustering	9	In centroid-based clustering, clusters are represented by a central vector, which may not necessarily be a member of the data set. When the number of clusters is fixed to k, k-means clustering gives a formal definition as an optimization problem: find the k cluster centers and assign the objects to the nearest cluster center, such that the squared distances from the cluster are minimized.
0.1.8.0.2.0.4.2.5.0	0.1.8.0.2.0.4.2.5	Fuzzy C-Means	Centroid Models	10	Fuzzy clustering (also referred to as soft clustering) is a form of clustering in which each data point can belong to more than one cluster. Clustering or cluster analysis involves assigning data points to clusters such that items in the same cluster are as similar as possible, while items belonging to different clusters are as dissimilar as possible. Clusters are identified via similarity measures. These similarity measures include distance, connectivity, and intensity. Different similarity measures may be chosen based on the data or the application
0.1.8.0.2.0.4.2.5.1	0.1.8.0.2.0.4.2.5	K-Means++	Centroid Models	10	k-means++ is an algorithm for choosing the initial values or seeds for the k-means clustering algorithm. It was proposed in 2007 by David Arthur and Sergei Vassilvitskii, as an approximation algorithm for the NP-hard k-means problem—a way of avoiding the sometimes poor clusterings found by the standard k-means algorithm. It is similar to the first of three seeding methods proposed, in independent work, in 2006[3] by Rafail Ostrovsky, Yuval Rabani, Leonard Schulman and Chaitanya Swamy. (The distribution of the first seed is different.).
0.1.8.0.2.0.4.2.5.2	0.1.8.0.2.0.4.2.5	k-Medians	Centroid Models	10	In statistics and data mining, k-medians clustering is a cluster analysis algorithm. ... Formally, given a set of data points x, the k centers ci are to be chosen so as to minimize the sum of the distances from each x to the nearest ci.
0.1.8.0.2.0.4.2.5.3	0.1.8.0.2.0.4.2.5	k-Medoids	Centroid Models	10	The k-medoids algorithm is a clustering algorithm related to the k-means algorithm and the medoidshift algorithm. Both the k-means and k-medoids algorithms are partitional (breaking the dataset up into groups) and both attempt to minimize the distance between points labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the k-means algorithm, k-medoids chooses datapoints as centers (medoids or exemplars) and works with a generalization of the Manhattan Norm to define distance between datapoints instead of {\displaystyle l_{2}} l_{2}. This method was proposed in 1987 for the work with {\displaystyle l_{1}} l_{1} norm and other distances. k-medoid is a classical partitioning technique of clustering that clusters the data set of n objects into k clusters known a priori. A useful tool for determining k is the silhouette.
0.1.8.0.2.0.4.2.5.4	0.1.8.0.2.0.4.2.5	k-Means	Centroid Models	10	k-means clustering, or Lloyd's algorithm  , is an iterative, data-partitioning algorithm that assigns n observations to exactly one of k clusters defined by centroids, where k is chosen before the algorithm starts. The algorithm proceeds as follows: Choose k initial cluster centers (centroid).
0.1.8.0.2.0.5	0.1.8.0.2.0	Instance based 	Clustering	7	For every test data point, search database of training data for ‘similar’ points and predict according to those points.
0.1.8.0.2.0.5.0	0.1.8.0.2.0.5	k-Nearest Neighbor (kNN)	Instance based 	8	k-nearest neighbors algorithm. In pattern recognition, the k-nearest neighbors algorithm (k-NN) is a non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space. ... In k-NN classification, the output is a class membership.
0.1.8.0.3	0.1.8.0	Dimensionality reduction	Machine learning 	5	In statistics, machine learning, and information theory, dimensionality reduction or dimension reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. It can be divided into feature selection and feature extraction.
0.1.8.0.3.0	0.1.8.0.3	Dimension reduction	Dimensionality reduction	6	In machine learning and statistics, dimensionality reduction or dimension reduction is the process of reducing the number of random variables under consideration, via obtaining a set of principal variables. It can be divided into feature selection and feature extraction.
0.1.8.0.3.1	0.1.8.0.3	Pipelining	Dimensionality reduction	6	The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a ‘__’, as in the example below. A step’s estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting to None.
0.1.8.0.3.2	0.1.8.0.3	Principal component analysis PCA	Dimensionality reduction	6	Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components (or sometimes, principal modes of variation).
0.1.8.0.3.3	0.1.8.0.3	Independent component analysis ICA	Dimensionality reduction	6	Independent component analysis (ICA) is a statistical and computational technique for revealing hidden factors that underlie sets of random variables, measurements, or signals. The latent variables are assumed nongaussian and mutually independent, and they are called the independent components of the observed data.
0.1.8.0.3.4	0.1.8.0.3	Principal Component Regression PCR	Dimensionality reduction	6	In statistics, principal component regression (PCR) is a regression analysis technique that is based on principal component analysis (PCA). ... In PCR, instead of regressing the dependent variable on the explanatory variables directly, the principal components of the explanatory variables are used as regressors.
0.1.8.0.3.5	0.1.8.0.3	Kernel PCA	Dimensionality reduction	6	In the field of multivariate statistics, kernel principal component analysis (kernel PCA) [1] is an extension of principal component analysis (PCA) using techniques of kernel methods. Using a kernel, the originally linear operations of PCA are performed in a reproducing kernel Hilbert space.
0.1.8.0.3.6	0.1.8.0.3	 Incremental PCA	Dimensionality reduction	6	Incremental principal component analysis (IPCA) is typically used as a replacement for principal component analysis (PCA) when the dataset to be decomposed is too large to fit in memory. IPCA builds a low-rank approximation for the input data using an amount of memory which is independent of the number of input data samples. It is still dependent on the input data features, but changing the batch size allows for control of memory usage.
0.1.8.0.3.7	0.1.8.0.3	 Randomized PCA	Dimensionality reduction	6	Principal component analysis (PCA) requires the computation of a low-rank approximation to a matrix containing the data being analyzed. In many applications of PCA, the best possible accuracy of any rank-deficient approximation is at most a few digits (measured in the spectral norm, relative to the spectral norm of the matrix being approximated). In such circumstances, efficient algorithms have not come with guarantees of good accuracy, unless one or both dimensions of the matrix being approximated are small. We describe an efficient algorithm for the low-rank approximation of matrices that produces accuracy very close to the best possible, for matrices of arbitrary sizes. We illustrate our theoretical results via several numerical examples.
0.1.8.0.3.8	0.1.8.0.3	Principal Least Squares Regression	Dimensionality reduction	6	"Partial least squares regression (PLS regression) is a statistical method that bears some relation to principal components regression; instead of finding hyperplanes of maximum variance between the response and independent variables, it finds a linear regression model by projecting the predicted variables and the ..."
0.1.8.0.3.9	0.1.8.0.3	Sammon Mapping	Dimensionality reduction	6	Sammon mapping or Sammon projection is an algorithm that maps a high-dimensional space to a space of lower dimensionality (see multidimensional scaling) by trying to preserve the structure of inter-point distances in high-dimensional space in the lower-dimension projection.
0.1.8.0.3.10	0.1.8.0.3	Random projections	Dimensionality reduction	6	The dimensions and distribution of random projections matrices are controlled so as to preserve the pairwise distances between any two samples of the dataset. Thus random projection is a suitable approximation technique for distance based method.
0.1.8.0.3.11	0.1.8.0.3	Multidimensional Scaling	Dimensionality reduction	6	Multidimensional scaling (MDS) is a means of visualizing the level of similarity of individual cases of a dataset. It refers to a set of related ordination techniques used in information visualization, in particular to display the information contained in a distance matrix.
0.1.8.0.3.12	0.1.8.0.3	Discriminant Analysis	Dimensionality reduction	6	Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fisher's linear discriminant, a method used in statistics, pattern recognition and machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier, or, more commonly, for dimensionality reduction before later classification.
0.1.8.0.3.12.0	0.1.8.0.3.12	Linear discriminant analysis LDA	Discriminant Analysis	7	Linear discriminant analysis (LDA) is a generalization of Fisher s linear discriminant, a method used in statistics, pattern recognition and machine learning to find a linear combination of features that characterizes or separates two or more classes of objects or events.
0.1.8.0.3.12.1	0.1.8.0.3.12	Quadratic discriminant analysis QDA	Discriminant Analysis	7	Quadratic discriminant analysis. Quadratic discriminant analysis (QDA) is closely related to linear discriminant analysis (LDA), where it is assumed that the measurements from each class are normally distributed.
0.1.8.0.3.12.2	0.1.8.0.3.12	kernel Fisher discriminant analysis  KFDA	Discriminant Analysis	7	In statistics, kernel Fisher discriminant analysis (KFD), also known as generalized discriminant analysis and kernel discriminant analysis, is a kernelized version of linear discriminant analysis (LDA). It is named after Ronald Fisher. Using the kernel trick, LDA is implicitly performed in a new feature space, which allows non-linear mappings to be learned.
0.1.8.0.3.12.3	0.1.8.0.3.12	MDA	Discriminant Analysis	7	Multiple Discriminant Analysis (MDA) is a method for compressing a multivariate signal to yield a lower-dimensional signal amenable to classification. MDA is not directly used to perform classification. It merely supports classification by yielding a compressed signal amenable to classification.
0.1.8.0.4	0.1.8.0	Time Series Forecasting	Machine learning 	5	Time series forecasting is the use of a model to predict future values based on previously observed values.
0.1.8.0.4.0	0.1.8.0.4	Arima Models 	Time Series Forecasting	6	In statistics and econometrics, and in particular in time series analysis, an autoregressive integrated moving average (ARIMA) model is a generalization of an autoregressive moving average (ARMA) model. Both of these models are fitted to time series data either to better understand the data or to predict future points in the series (forecasting). ARIMA models are applied in some cases where data show evidence of non-stationarity, where an initial differencing step (corresponding to the  integrated  part of the model) can be applied one or more times to eliminate the non-stationarity.
0.1.8.0.4.1	0.1.8.0.4	SEM-Structural Equation models 	Time Series Forecasting	6	Structural equation modeling (SEM) includes a diverse set of mathematical models, computer algorithms, and statistical methods that fit networks of constructs to data. SEM includes confirmatory factor analysis, path analysis, partial least squares path modeling, and latent growth modeling. The concept should not be confused with the related concept of structural models in econometrics, nor with structural models in economics. Structural equation models are often used to assess unobservable 'latent' constructs. They often invoke a measurement model that defines latent variables using one or more observed variables, and a structural model that imputes relationships between latent variables. The links between constructs of a structural equation model may be estimated with independent regression equations or through more involved approaches such as those employed in LISREL.
0.1.8.0.4.2	0.1.8.0.4	Bayesian Networks	Time Series Forecasting	6	A Bayesian network, Bayes network, belief network, Bayes(ian) model or probabilistic directed acyclic graphical model is a probabilistic graphical model (a type of statistical model) that represents a set of random variables and their conditional dependencies via a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases.
0.1.8.0.4.3	0.1.8.0.4	Singular spectrum Analysis	Time Series Forecasting	6	In time series analysis, singular spectrum analysis (SSA) is a nonparametric spectral estimation method. It combines elements of classical time series analysis, multivariate statistics, multivariate geometry, dynamical systems and signal processing. Its roots lie in the classical Karhunen (1946)–Loève (1945, 1978) spectral decomposition of time series and random fields and in the Mañé (1981)–Takens (1981) embedding theorem. SSA can be an aid in the decomposition of time series into a sum of components, each having a meaningful interpretation. The name  singular spectrum analysis  relates to the spectrum of eigenvalues in a singular value decomposition of a covariance matrix, and not directly to a frequency domain decomposition.
0.1.8.0.4.4	0.1.8.0.4	Extensible markov models 	Time Series Forecasting	6	In probability theory, a Markov model is a stochastic model used to model randomly changing systems. It is assumed that future states depend only on the current state, not on the events that occurred before it (that is, it assumes the Markov property). Generally, this assumption enables reasoning and computation with the model that would otherwise be intractable. For this reason, in the fields of predictive modelling and probabilistic forecasting, it is desirable for a given model to exhibit the Markov property.
0.1.8.0.5	0.1.8.0	Reinforcement learning 	Machine learning 	5	Reinforcement learning (RL) is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. The problem, due to its generality, is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In the operations research and control literature, reinforcement learning is called approximate dynamic programming, or neuro-dynamic programming. The problems of interest in reinforcement learning have also been studied in the theory of optimal control, which is concerned mostly with the existence and characterization of optimal solutions, and algorithms for their exact computation, and less with learning or approximation, particularly in the absence of a mathematical model of the environment. In economics and game theory, reinforcement learning may be used to explain how equilibrium may arise under bounded rationality.
0.1.8.0.5.0	0.1.8.0.5	Q-learning 	Reinforcement learning 	6	Q-learning is a model-free reinforcement learning technique. Specifically, Q-learning can be used to find an optimal action-selection policy for any given (finite) Markov decision process (MDP). It works by learning an action-value function that ultimately gives the expected utility of taking a given action in a given state and following the optimal policy thereafter. A policy is a rule that the agent follows in selecting actions, given the state it is in. When such an action-value function is learned, the optimal policy can be constructed by simply selecting the action with the highest value in each state. One of the strengths of Q-learning is that it is able to compare the expected utility of the available actions without requiring a model of the environment. Additionally, Q-learning can handle problems with stochastic transitions and rewards, without requiring any adaptations. It has been proven that for any finite MDP, Q-learning eventually finds an optimal policy, in the sense that the expected value of the total reward return over all successive steps, starting from the current state, is the maximum achievable.
0.1.8.0.5.1	0.1.8.0.5	Temporal Difference	Reinforcement learning 	6	Temporal difference (TD) learning is a prediction-based machine learning method. It has primarily been used for the reinforcement learning problem, and is said to be  a combination of Monte Carlo ideas and dynamic programming (DP) ideas.   TD resembles a Monte Carlo method because it learns by sampling the environment according to some policy, and is related to dynamic programming techniques as it approximates its current estimate based on previously learned estimates (a process known as bootstrapping). The TD learning algorithm is related to the temporal difference model of animal learning.
0.1.8.0.5.2	0.1.8.0.5	State-Action-Reward-State-Action SARSA	Reinforcement learning 	6	Is an algorithm for learning a Markov decision process policy, used in the reinforcement learning area of machine learning. It was introduced in a technical note  where the alternative name SARSA was only mentioned as a footnote.This name simply reflects the fact that the main function for updating the Q-value depends on the current state of the agent  S1 , the action the agent chooses  A1 , the reward  R  the agent gets for choosing this action, the state  S2  that the agent will now be in after taking that action, and finally the next action  A2  the agent will choose in its new state. Taking every letter in the quintuple (st, at, rt, st+1, at+1) yields the word SARSA
0.1.8.0.5.3	0.1.8.0.5	Deep reinforcement learning  DRL	Reinforcement learning 	6	Reinforcement learning (RL) is an area of machine learning inspired by behaviourist psychology, concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward.
0.1.8.0.6	0.1.8.0	Association Rules 	Machine learning 	5	 Association rule learning is a rule-based machine learning method for discovering interesting relations between variables in large databases. It is intended to identify strong rules discovered in databases using some measures of interestingness.
0.1.8.0.6.0	0.1.8.0.6	FP-Growth	Association Rules 	6	In Data Mining the task of finding frequent pattern in large databases is very important and has been studied in large scale in the past few years. Unfortunately, this task is computationally expensive, especially when a large number of patterns exist. The FP-Growth Algorithm, proposed by Han in], is an efficient and scalable method for mining the complete set of frequent patterns by pattern fragment growth, using an extended prefix-tree structure for storing compressed and crucial information about frequent patterns named frequent-pattern tree (FP-tree). In his study, Han proved that his method outperforms other popular methods for mining frequent patterns, e.g. the Apriori Algorithm and the TreeProjection. In some later works it was proved that FP-Growth has better performance than other methods, including Eclat and Relim. The popularity and efficiency of FP-Growth Algorithm contributes with many studies that propose variations to improve his performance.
0.1.8.0.6.1	0.1.8.0.6	Eclat Algorithm	Association Rules 	6	This is an algorithm for Frequent Pattern Mining based on Depth-First Search traversal of the itemset Lattice but it's rather a DFS traversal of the prefix tree than lattice and the Branch and Bound method is used for stopping.
0.1.8.0.6.2	0.1.8.0.6	Apriori Algorithm	Association Rules 	6	Apriori is an algorithm for frequent item set mining and association rule learning over transactional databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent item sets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.
0.1.8.0.7	0.1.8.0	Deep Learning 	Machine learning 	5	Deep learning (also known as deep structured learning or hierarchical learning) is part of a broader family of machine learning methods based on learning data representations, as opposed to task-specific algorithms. Learning can be supervised, semi-supervised or unsupervised. Deep learning architectures such as deep neural networks, deep belief networks and recurrent neural networks have been applied to fields including computer vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, bioinformatics, drug design and board game programs, where they have produced results comparable to and in some cases superior to human experts
0.1.8.0.7.0	0.1.8.0.7	Deep Feedforward Network DFNN	Deep Learning 	6	A feedforward neural network is an artificial neural network wherein connections between the units do not form a cycle. As such, it is different from recurrent neural networks. The feedforward neural network was the first and simplest type of artificial neural network devised.
0.1.8.0.7.1	0.1.8.0.7	Time Delay Neural Network / Shared Weights Neural Networks TDNN 	Deep Learning 	6	Time delay neural network (TDNN) is an artificial neural network architecture whose primary purpose is to work on sequential data. ... The original paper presented a perceptron network whose connection weights were trained with the back-propagation algorithm, this may be done in batch or online.
0.1.8.0.7.2	0.1.8.0.7	Hoppfield Network	Deep Learning 	6	A Hopfield net is a recurrent neural network having synaptic connection pattern such that there is an underlying Lyapunov function for the activity dynamics. Started in any initial state, the state of the system evolves to a final state that is a (local) minimum of the Lyapunov function.
0.1.8.0.7.3	0.1.8.0.7	Wavelet Neural Network	Deep Learning 	6	Wavelet neural networks(WNN) are a class of neural networks consisting of wavelets. A novel learning method based on immune genetic algorithm(IGA) for continuous wavelet neural networks is presented in this paper.
0.1.8.0.7.4	0.1.8.0.7	Unsupervised Pretrained Networks (UPNs)	Deep Learning 	6	Unsupervised pre-training initializes a discriminative neural net from one which was trained using an unsupervised criterion, such as a deep belief network or a deep autoencoder. This method can sometimes help with both the optimization and the overfitting issues.
0.1.8.0.7.5	0.1.8.0.7	Word  Embedding Layer	Deep Learning 	6	Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers.
0.1.8.0.7.6	0.1.8.0.7	Deep Kernel Machines	Deep Learning 	6	In this new contribution, a deep multiple kernel is recursively defined as a multi-layered combination of nonlinear activation functions, each one involves a combination of several elementary or intermediate kernels, and results into a positive semi-definite deep kernel.
0.1.8.0.7.7	0.1.8.0.7	Deep Coding Network/ sparse Coding	Deep Learning 	6	Sparse coding is a class of unsupervised methods for learning sets of over-complete bases to represent data efficiently. ... The advantage of having an over-complete basis is that our basis vectors are better able to capture structures and patterns inherent in the input data.
0.1.8.0.7.8	0.1.8.0.7	Generative Adversarial Neural Network	Deep Learning 	6	Generative adversarial networks (GANs) are a class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks contesting with each other in a zero-sum game framework.
0.1.8.0.7.9	0.1.8.0.7	Compound Hierarchical-Deep Models	Deep Learning 	6	We call our architectures compound HD models, where “HD” stands for “Hierarchical-Deep,” because they are derived by composing hierarchical nonparametric Bayesian models with deep networks, two influential approaches from the recent unsupervised learning literature with complementary strengths.
0.1.8.0.7.10	0.1.8.0.7	Spike-and-Slab RBMs (ssRBMs) 	Deep Learning 	6	The spike-and-slab Restricted Boltzmann Machine (RBM) is defined by having both a real valued slab  variable and a binary spike  variable associated with each unit in the hidden layer. In this paper we generalize and extend the spikeandslab RBM to include non-zero means of the conditional distribution over the observed variables given the binary spike variables. We also introduce a term, quadratic in the observed data that we exploit to guarantee that all conditionals associated with the model are well defined  a guarantee that was absent in the original spikeandslab RBM. The inclusion of these generalizations improves the performance of the spike-and-slab RBM as a feature learner and achieves competitive performance on the CIFAR10 image classification task. The spikeandslab model, when trained in a convolutional configuration, can generate sensible samples that demonstrate that the model has captured the broad statistical structure of natural images
0.1.8.0.7.11	0.1.8.0.7	Tensor Deep Stacking Network (T-DSN)	Deep Learning 	6	"The T-DSN consists of multiple, stacked blocks, where each block contains a bilinear mapping from two hidden layers to the output layer, using a weight tensor to incorporate higher order statistics of the hidden binary (½0; 1 ) features"
0.1.8.0.7.12	0.1.8.0.7	Denoising Autoencoders	Deep Learning 	6	These notes describe the sparse autoencoder learning algorithm, which is one approach to automatically learn features from unlabeled data. In some domains, such as computer vision, this approach is not by itself competitive with the best hand-engineered features, but the features it can learn do turn out to be useful for a range of problems (including ones in audio, text, etc). Further, there’re more sophisticated versions of the sparse autoencoder (not described in these notes, but that you’ll hear more about later in the class) that do surprisingly well, and in many cases are competitive with or superior to even the best hand-engineered representations.
0.1.8.0.7.13	0.1.8.0.7	Denoising Autoencoders	Deep Learning 	6	These notes describe the sparse autoencoder learning algorithm, which is one approach to automatically learn features from unlabeled data. In some domains, such as computer vision, this approach is not by itself competitive with the best hand-engineered features, but the features it can learn do turn out to be useful for a range of problems (including ones in audio, text, etc). Further, there’re more sophisticated versions of the sparse autoencoder (not described in these notes, but that you’ll hear more about later in the class) that do surprisingly well, and in many cases are competitive with or superior to even the best hand-engineered representations.
0.1.8.0.7.14	0.1.8.0.7	Variational Autoencoders	Deep Learning 	6	Variational autoencoders are cool. They let us design complex generative models of data, and fit them to large datasets. They can generate images of fictional celebrity faces and high-resolution digital artwork.
0.1.8.0.7.15	0.1.8.0.7	Stacked (Denoising) Auto-Encoders	Deep Learning 	6	The Stacked Denoising Autoencoder (SdA) is an extension of the stacked autoencoder
0.1.8.0.7.16	0.1.8.0.7	Deep Boltzmann Machines	Deep Learning 	6	A deep Boltzmann machine (DBM) is a type of binary pairwise Markov random field (undirected probabilistic graphical model) with multiple layers of hidden random variables. It is a network of symmetrically coupled stochastic binary units. It comprises a set of visible units and layers of hidden units.
0.1.8.0.7.17	0.1.8.0.7	Restricted Boltzmann Machine	Deep Learning 	6	Although learning is impractical in general Boltzmann machines, it can be made quite efficient in an architecture called the restricted Boltzmann machine or RBM which does not allow intralayer connections between hidden units. After training one RBM, the activities of its hidden units can be treated as data for training a higher-level RBM. This method of stacking RBMs makes it possible to train many layers of hidden units efficiently and is one of the most common deep learning strategies. As each new layer is added the overall generative model gets better.
0.1.8.0.7.18	0.1.8.0.7	Restricted Boltzmann Machine w/ continuous-valued inputs CRBM:	Deep Learning 	6	A Boltzmann machine is a type of stochastic recurrent neural network (and Markov Random Field). Boltzmann machines can be seen as the stochastic, generative counterpart of Hopfield nets. They were one of the first neural networks capable of learning internal representations, and are able to represent and (given sufficient time) solve difficult combinatoric problems. They are theoretically intriguing because of the locality and Hebbian nature of their training algorithm, and because of their parallelism and the resemblance of their dynamics to simple physical processes. Boltzmann machines with unconstrained connectivity have not proven useful for practical problems in machine learning or inference, but if the connectivity is properly constrained, the learning can be made efficient enough to be useful for practical problems.
0.1.8.0.7.19	0.1.8.0.7	Convolutional Deep Belief Network	Deep Learning 	6	In computer science, Convolutional Deep Belief Network (CDBN) is a type of deep artificial neural network that is composed of multiple layers of convolutional restricted Boltzmann machines stacked together.
0.1.8.0.7.20	0.1.8.0.7	Information fuzzy networks	Deep Learning 	6	Information fuzzy networks (IFN) is a greedy machine learning algorithm for supervised learning. The data structure produced by the learning algorithm is also called Info Fuzzy Network.
0.1.8.0.7.21	0.1.8.0.7	Deep Belief Network	Deep Learning 	6	In machine learning, a deep belief network (DBN) is a generative graphical model, or alternatively a class of deep neural network, composed of multiple layers of latent variables (hidden units), with connections between the layers but not between units within each layer.
0.1.8.0.7.22	0.1.8.0.7	Deep Neural Network	Deep Learning 	6	On the same page, here you have the definition A deep neural network (DNN) is an artificial neural network (ANN) with multiple hidden layers of units between the input and output layers
0.1.8.0.7.23	0.1.8.0.7	Deep residual Neural Network	Deep Learning 	6	Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.
0.1.8.0.7.24	0.1.8.0.7	Neural Turing Machine	Deep Learning 	6	The NTM can be seen as a differentiable version of the Turing Machine. Similarly to a Turing Machine, it has two main components: a (bounded) memory tape, and a controller that is responsible for making the interface between the external world (ie. the input sequence and the output representation) and the memory through read and write heads. This architecture is said to be differentiable, in the sense that both the controller and the addressing mechanisms (the heads) are differentiable. The parameters of the model can then be learned using Stochastic Gradient Descent (SGD). Let’s describe these components in more details.
0.1.8.0.7.25	0.1.8.0.7	Recurrent networks	Deep Learning 	7	A recurrent neural network (RNN) is a class of artificial neural network where connections between nodes form a directed graph along a sequence. This allows it to exhibit temporal dynamic behavior for a time sequence.
0.1.8.0.7.25.0	0.1.8.0.7.25	Recurrent Neural Network RNN 	Recurrent networks	8	A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This allows it to exhibit dynamic temporal behavior. A recurrent neural network basically unfolds over time. It is used for sequential inputs where the time factor is the main differentiating factor between the elements of the sequence. For example, here is a recurrent neural network used for language modelling that has been unfolded over time. At each time step, in addition to the user input at that time step, it also accepts the output of the hidden layer that was computed at the previous time step.
0.1.8.0.7.25.1	0.1.8.0.7.25	Stochastic Neural Network	Recurrent networks	8	Stochastic neural networks are a type of artificial neural networks built by introducing random variations into the network, either by giving the network's neurons stochastic transfer functions, or by giving them stochastic weights.
0.1.8.0.7.25.2	0.1.8.0.7.25	Multiple Time Scales Recurrent Neural Network	Recurrent networks	8	A multiple timescales recurrent neural network (MTRNN) is a neural-based computational model that can simulate the functional hierarchy of the brain through self-organization that depends on spatial connection between neurons and on distinct types of neuron activities, each with distinct time properties.
0.1.8.0.7.25.3	0.1.8.0.7.25	Second Order Recurrent Neural Network	Recurrent networks	8	Higher Order Recurrent Neural Networks. A recurrent neural network (RNN) is a type of neural net- work suitable for modeling a sequence of arbitrary length. At each time step t, an RNN receives an input xt, the state.Apr 30, 2016
0.1.8.0.7.25.4	0.1.8.0.7.25	Recurrent Multilayer Perceptron	Recurrent networks	8	A multilayer perceptron (MLP) is a class of feedforward artificial neural network. An MLP consists of at least three layers of nodes. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training.
0.1.8.0.7.25.5	0.1.8.0.7.25	Hierarchical Recurrent Neural Network	Recurrent networks	8	earning both hierarchical and temporal representation has been among the long-standing challenges of recurrent neural networks. Multiscale recurrent neural networks have been considered as a promising approach to resolve this issue, yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence. In this paper, we propose a novel multiscale approach, called the hierarchical multiscale recurrent neural networks, which can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism. We show some evidence that our proposed multiscale architecture can discover underlying hierarchical structure in the sequences without using explicit boundary information. We evaluate our proposed model on character-level language modelling and handwriting sequence modelling.
0.1.8.0.7.25.6	0.1.8.0.7.25	Continuous Time Recurrent Neural Network	Recurrent networks	8	A continuous-time recurrent neural network described by differential equations for realtime support vector regression (SVR). The SVR is first formulated as a convex quadratic programming problem, and then a continuous-time recurrent neural network with one-layer structure is designed for training the support vector machine. Furthermore, simulation results on an illustrative example are given to demonstrate the effectiveness and performance of the proposed neural network.
0.1.8.0.7.25.7	0.1.8.0.7.25	Bi-Directional Recurrent Neural Network	Recurrent networks	8	The principle of BRNN is to split the neurons of a regular RNN into two directions, one for positive time direction(forward states), and another for negative time direction(backward states). Those two states' output are not connected to inputs of the opposite direction states.
0.1.8.0.7.25.8	0.1.8.0.7.25	Long Short Term Memory Network	Recurrent networks	8	Long short-term memory (LSTM) block or network is a simple recurrent neural network which can be used as a building component or block (of hidden layers) for an eventually bigger recurrent neural network. There are different types of LSTMs, which differ among them in the components or connections that they have.
0.1.8.0.7.25.9	0.1.8.0.7.25	Echo State Network	Recurrent networks	8	The echo state network (ESN), is a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity). The connectivity and weights of hidden neurons are fixed and randomly assigned.
0.1.8.0.7.25.10	0.1.8.0.7.25	Elman/Jordan Networks	Recurrent networks	8	Jordan networks are similar to Elman networks. ... The context units in a Jordan network are also referred to as the state layer. They have a recurrent connection to themselves. Elman and Jordan networks are also known as  simple recurrent networks  (SRN).
0.1.8.0.7.25.11	0.1.8.0.7.25	Hopfield Network	Recurrent networks	8	Hopfield nets serve as content-addressable memory systems with binary threshold nodes. They are guaranteed to converge to a local minimum, but will sometimes converge to a false pattern (wrong local minimum) rather than the stored pattern (expected local minimum). Hopfield networks also provide a model for understanding human memory.
0.1.8.0.7.25.12	0.1.8.0.7.25	Gated Recurrent Neural Network	Recurrent networks	8	Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, introduced in 2014. Their performance on polyphonic music modeling and speech signal modeling was found to be similar to that of long short-term memory. They have fewer parameters than LSTM, as they lack an output gate.
0.1.8.0.7.26	0.1.8.0.7	Convolutional Neural Networks (CNNs)	Deep Learning 	7	In machine learning, a convolutional neural network (CNN, or ConvNet) is a class of deep, feed-forward artificial neural networks that has successfully been applied to analyzing visual imagery. ... They have applications in image and video recognition, recommender systems and natural language processing.
0.1.8.0.7.27	0.1.8.0.7	Deconvolutional Neural Network	Deep Learning 	7	"""This uses the same filters are the corresponding conv layer; the only difference is that they are flipped horizontally and vertically."""
0.1.8.0.7.28	0.1.8.0.7	Recursive Neural Networks.	Deep Learning 	7	A recursive neural network (RvNN) is a kind of deep neural network created by applying the same set of weights recursively over a structure, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order.
0.1.8.0.7.29	0.1.8.0.7	Conditional GAN (image2image)	Deep Learning 	7	We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.
0.1.8.0.7.30	0.1.8.0.7	Networks and some properties	Deep Learning	6	Networks and some properties
0.1.8.0.7.30.0	0.1.8.0.7.30	Activation function	Networks and some properties	7	Activation function
0.1.8.0.7.30.0.0	0.1.8.0.7.30.0	Some desirable properties	Activation function	8	Some desirable properties
0.1.8.0.7.30.0.0.0	0.1.8.0.7.30.0.0	Nonlinear	Some desirable properties	9	Non-linearity is needed in activation functions because its aim in a neural network is to produce a nonlinear decision boundary via non-linear combinations of the weight and inputs. ... A squashing function is for example a nonlinear activation function that maps to [0,1] like the sigmoid activation function.
0.1.8.0.7.30.0.0.1	0.1.8.0.7.30.0.0	Continuously differentiable	Some desirable properties	9	This property is necessary for enabling gradient-based optimization methods. The binary step activation function is not differentiable at 0, and it differentiates to 0 for all other values, so gradient-based methods can make no progress with it
0.1.8.0.7.30.0.0.2	0.1.8.0.7.30.0.0	Range	Some desirable properties	9	When the range of the activation function is finite, gradient-based training methods tend to be more stable, because pattern presentations significantly affect only limited weights. When the range is infinite, training is generally more efficient because pattern presentations significantly affect most of the weights. In the latter case, smaller learning rates are typically necessary.
0.1.8.0.7.30.0.0.3	0.1.8.0.7.30.0.0	Monotonic	Some desirable properties	9	When the activation function is monotonic, the error surface associated with a single-layer model is guaranteed to be convex
0.1.8.0.7.30.0.0.4	0.1.8.0.7.30.0.0	Smooth Functions with a Monotonic derivative	Some desirable properties	9	These have been shown to generalize better in some cases. The argument for these properties suggests that such activation functions are more consistent with Occam's razor
0.1.8.0.7.30.0.0.5	0.1.8.0.7.30.0.0	Approximates identity near the origin	Some desirable properties	9	When activation functions have this property, the neural network will learn efficiently when its weights are initialized with small random values. When the activation function does not approximate identity near the origin, special care must be used when initializing the weights.
0.1.8.0.7.30.0.1	0.1.8.0.7.30.0	Activation function AF	Activation function	8	https://en.wikipedia.org/wiki/Activation_function
0.1.8.0.7.30.1	0.1.8.0.7.30	Backpropagation	Networks and some properties	7	Backpropagation, short for  backward propagation of errors,  is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights.
0.1.8.0.8	0.1.8.0	Kernels 	Machine learning 	5	Kernels 
0.1.8.0.8.0	0.1.8.0.8	Kernels	Kernels 	6	"Kernel methods owe their name to the use of kernel functions, which enable them to operate in a high-dimensional, implicit feature space without ever computing the coordinates of the data in that space, but rather by simply computing the inner products between the images of all pairs of data in the feature space. This operation is often computationally cheaper than the explicit computation of the coordinates. This approach is called the ""kernel trick"". Kernel functions have been introduced for sequence data, graphs, text, images, as well as vectors."
0.1.8.0.8.0.0	0.1.8.0.8.0	Laplace Radial Basis	Kernels	7	"A radial basis function (RBF) is a real-valued function whose value depends only on the distance from the origin, so that {\displaystyle \phi (\mathbf {x} )=\phi (\|\mathbf {x} \|)} \phi (\mathbf {x} )=\phi (\|\mathbf {x} \|); or alternatively on the distance from some other point c, called a center, so that {\displaystyle \phi (\mathbf {x} ,\mathbf {c} )=\phi (\|\mathbf {x} -\mathbf {c} \|)} \phi (\mathbf {x} ,\mathbf {c} )=\phi (\|\mathbf {x} -\mathbf {c} \|). Any function {\displaystyle \phi } \phi  that satisfies the property {\displaystyle \phi (\mathbf {x} )=\phi (\|\mathbf {x} \|)} \phi (\mathbf {x} )=\phi (\|\mathbf {x} \|) is a radial function. The norm is usually Euclidean distance, although other distance functions are also possible."
0.1.8.0.8.0.1	0.1.8.0.8.0	Bessel	Kernels	7	The level spacing distributions which arise when one rescales the Laguerre or Jacobi ensembles of hermitian matrices is studied. These distributions are expressible in terms of a Fredholm determinant of an integral operator whose kernel is expressible in terms of Bessel functions of order 
0.1.8.0.8.0.2	0.1.8.0.8.0	Hyperbolic Tangent	Kernels	7	A HyperbolicTangentKernel provides a kernel based on the hyperbolic tangent of a dot product with fixed linear scaling. Hyperbolic tangent kernels are popular as neural network activation functions.
0.1.8.0.8.0.3	0.1.8.0.8.0	Polynomial	Kernels	7	In machine learning, the polynomial kernel is a kernel function commonly used with support vector machines (SVMs) and other kernelized models, that represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables, allowing learning of non-linear models. Intuitively, the polynomial kernel looks not only at the given features of input samples to determine their similarity, but also combinations of these. In the context of regression analysis, such combinations are known as interaction features. The (implicit) feature space of a polynomial kernel is equivalent to that of polynomial regression, but without the combinatorial blowup in the number of parameters to be learned. When the input features are binary-valued (booleans), then the features correspond to logical conjunctions of input features.
0.1.8.0.8.0.4	0.1.8.0.8.0	Guassian Radial Basis	Kernels	7	In machine learning, the radial basis function kernel, or RBF kernel, is a popular kernel function used in various kernelized learning algorithms. In particular, it is commonly used in support vector machine classification.
0.1.8.0.8.0.5	0.1.8.0.8.0	Linear	Kernels	7	In machine learning, the polynomial kernel is a kernel function commonly used with support vector machines (SVMs) and other kernelized models, that represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables, allowing learning of non-linear models.
0.1.8.0.8.1	0.1.8.0.8	Kernel Methods	Kernels 	6	Kernel Methods
0.1.8.0.8.1.0	0.1.8.0.8.1	Incomplete Cholesky Decomposition 	Kernel Methods	7	Low-rank kernel approximation methods (Incomplete Cholesky Decomposition, Cholesky with Side-information
0.1.8.0.8.1.1	0.1.8.0.8.1	Interior Point Code Quadratic Optimizer	Kernel Methods	7	Interior point methods (also referred to as barrier methods) are a certain class of algorithms that solve linear and nonlinear convex optimization problems.John von Neumann suggested an interior point method of linear programming which was neither a polynomial time method nor an efficient method in practice. In fact, it turned out to be slower in practice compared to the commonly used simplex method. In 1984, Narendra Karmarkar developed a method for linear programming called Karmarkar's algorithmwhich runs in provably polynomial time and is also very efficient in practice. It enabled solutions of linear programming problems which were beyond the capabilities of the simplex method. Contrary to the simplex method, it reaches a best solution by traversing the interior of the feasible region. The method can be generalized to convex programming based on a self-concordant barrier function used to encode the convex set.
0.1.8.0.8.1.2	0.1.8.0.8.1	Kernel Canonical Correlation Analysis (KCCA)	Kernel Methods	7	Kernel Canonical Correlation Analysis (KCCA) is a non-linear extension of CCA. Given two random variables, KCCA aims at extracting the information which is shared by the two random variables.
0.1.8.0.8.1.3	0.1.8.0.8.1	Kernel Feature Analysis	Kernel Methods	7	The common property of the feature extractors Ii : X -+ lR in this section is to yield meaningful features on the data (e.g., large variance, kurtosis, bimodality) while maintaining a certain degree of simplicity in Ii itself. The latter may be given by a small RKHS norm or a small £1 norm of the expansion coefficients.  //  Accelerated Kernel Feature Analysis (AKFA), that discovers salient features evidenced in a sample of n unclassified patterns, is presented. Like earlier kernel-based feature selection algorithms, AKFA implicitly embeds each pattern into a Hilbert space, H, induced by a Mercer kernel. An \ell-dimensional linear subspace of H is iteratively constructed by maximizing a variance condition for the nonlinearly transformed sample. This linear subspace can then be used to define more efficient data representations and pattern classifiers. AKFA requires O(\elln2) operations, as compared to 0(n^3) for Sch¨olkof, Smola, and Müller's Kernel Principal Component Analysis (KPCA), and O(\ell^2 n^2) for Smola, Mangasarian, and Sch¨olkopf's Sparse Kernel Feature Analysis (SKFA). Numerical experiments show that AKFA can generate more concise feature representations than both KPCA and SKFA, and demonstrate that AKFA obtains similar classification performance as KPCA for a face recognition problem.
0.1.8.0.8.1.4	0.1.8.0.8.1	Kernel Principle Components Analysis (KPCA)	Kernel Methods	7	Dimension reduction could be improved by implementing sparse kernel feature analysis, a technique closely related to kernel PCA but with considerably less run-time complexity. While a projection onto a component with kernel PCA requires computing n kernel values, for sparse kernel feature analysis only one kernel value is calculated.
0.1.8.0.8.1.5	0.1.8.0.8.1	Spectral Clustering	Kernel Methods	7	In multivariate statistics and the clustering of data, spectral clustering techniques make use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions. The similarity matrix is provided as an input and consists of a quantitative assessment of the relative similarity of each pair of points in the dataset. In application to image segmentation, spectral clustering is known as segmentation-based object categorization.
0.1.8.0.8.1.6	0.1.8.0.8.1	Online Learning with Kernels	Kernel Methods	7	In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update our best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once. Online learning is a common technique used in areas of machine learning where it is computationally infeasible to train over the entire dataset, requiring the need of out-of-core algorithms. It is also used in situations where it is necessary for the algorithm to dynamically adapt to new patterns in the data, or when the data itself is generated as a function of time, e.g. stock price prediction. Online learning algorithms may be prone to catastrophic interference. This problem is tackled by incremental learning approaches.
0.1.8.0.8.1.7	0.1.8.0.8.1	Ranking	Kernel Methods	7	Ranking with kernel-based methods
0.1.8.0.8.1.8	0.1.8.0.8.1	Gaussian Processes Flow 	Kernel Methods	7	In probability theory and statistics, a Gaussian process is a particular kind of statistical model where observations occur in a continuous domain, e.g. time or space. In a Gaussian process, every point in some continuous input space is associated with a normally distributed random variable. Moreover, every finite collection of those random variables has a multivariate normal distribution, i.e. every finite linear combination of them is normally distributed. The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.
0.1.8.0.8.1.9	0.1.8.0.8.1	Relevance Vector Machine	Kernel Methods	7	In mathematics, a Relevance Vector Machine (RVM) is a machine learning technique that uses Bayesian inference to obtain parsimonious solutions for regression and probabilistic classification.  The RVM has an identical functional form to the support vector machine, but provides probabilistic classification.
0.1.8.0.8.1.10	0.1.8.0.8.1	Support Vector Machine	Kernel Methods	7	In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.
0.1.8.0.9	0.1.8.0	Model Validation	Machine learning 	5	Model Validation
0.1.8.0.9.0	0.1.8.0.9	Cluster Validity	Model Validation	6	Cluster Validity
0.1.8.0.9.0.0	0.1.8.0.9.0	External Evaluation	Cluster Validity	7	External Evaluation
0.1.8.0.9.0.0.0	0.1.8.0.9.0.0	Silhouette coefficient	External Evaluation	8	Assume the data have been clustered via any technique, such as k-means, into {\displaystyle k} k clusters. For each datum {\displaystyle i} i, let {\displaystyle a(i)} a(i) be the average dissimilarity of {\displaystyle i} i with all other data within the same cluster. We can interpret {\displaystyle a(i)} a(i) as how well {\displaystyle i} i is assigned to its cluster (the smaller the value, the better the assignment). We then define the average dissimilarity of point {\displaystyle i} i to a cluster {\displaystyle c} c as the average of the distance from {\displaystyle i} i to all points in {\displaystyle c} c.Let {\displaystyle b(i)} b(i) be the lowest average dissimilarity of {\displaystyle i} i to any other cluster, of which {\displaystyle i} i is not a member. The cluster with this lowest average dissimilarity is said to be the  neighbouring cluster  of {\displaystyle i} i because it is the next best fit cluster for point {\displaystyle i} i.
0.1.8.0.9.0.0.1	0.1.8.0.9.0.0	Dunn index	External Evaluation	8	The Dunn index (DI) (introduced by J. C. Dunn in 1974) is a metric for evaluating clustering algorithms. This is part of a group of validity indices including the Davies–Bouldin index or Silhouette index, in that it is an internal evaluation scheme, where the result is based on the clustered data itself. As do all other such indices, the aim is to identify sets of clusters that are compact, with a small variance between members of the cluster, and well separated, where the means of different clusters are sufficiently far apart, as compared to the within cluster variance. For a given assignment of clusters, a higher Dunn index indicates better clustering. One of the drawbacks of using this is the computational cost as the number of clusters and dimensionality of the data increase.
0.1.8.0.9.0.0.2	0.1.8.0.9.0.0	Davies–Bouldin index	External Evaluation	8	The Davies–Bouldin index (DBI) (introduced by David L. Davies and Donald W. Bouldin in 1979) is a metric for evaluating clustering algorithms. This is an internal evaluation scheme, where the validation of how well the clustering has been done is made using quantities and features inherent to the dataset. This has a drawback that a good value reported by this method does not imply the best information retrieval.
0.1.8.0.9.0.1	0.1.8.0.9.0	Internal Evaluation	Cluster Validity	7	Internal Evaluation
0.1.8.0.9.0.1.0	0.1.8.0.9.0.1	Mutual Information	Internal Evaluation	8	In probability theory and information theory, adjusted mutual information, a variation of mutual information may be used for comparing clusterings. It corrects the effect of agreement solely due to chance between clusterings, similar to the way the adjusted rand index corrects the Rand index. It is closely related to variation of information: when a similar adjustment is made to the VI index, it becomes equivalent to the AMI. The adjusted measure however is no longer metrical.
0.1.8.0.9.0.1.1	0.1.8.0.9.0.1	Fowlkes–Mallows index	Internal Evaluation	8	Fowlkes–Mallows index is an external evaluation method that is used to determine the similarity between two clusterings (clusters obtained after a clustering algorithm). This measure of similarity could be either between two hierarchical clusterings or a clustering and a benchmark classification. A higher value for the Fowlkes–Mallows index indicates a greater similarity between the clusters and the benchmark classifications.
0.1.8.0.9.0.1.2	0.1.8.0.9.0.1	Jaccard index	Internal Evaluation	8	The Jaccard index, also known as the Jaccard similarity coefficient (originally coined coefficient de communauté by Paul Jaccard), is a statistic used for comparing the similarity and diversity of sample sets. The Jaccard coefficient measures similarity between finite sample sets, and is defined as the size of the intersection divided by the size of the union of the sample sets: J(A,B) = |A n B|/|A uB|.
0.1.8.0.9.0.1.3	0.1.8.0.9.0.1	F-measure F1	Internal Evaluation	8	In statistical analysis of binary classification, the F1 score (also F-score or F-measure) is a measure of a test's accuracy. It considers both the precision p and the recall r of the test to compute the score: p is the number of correct positive results divided by the number of all positive results, and r is the number of correct positive results divided by the number of positive results that should have been returned. The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.
0.1.8.0.9.0.1.4	0.1.8.0.9.0.1	Rand Measure	Internal Evaluation	8	The Rand index or Rand measure (named after William M. Rand) in statistics, and in particular in data clustering, is a measure of the similarity between two data clusterings. A form of the Rand index may be defined that is adjusted for the chance grouping of elements, this is the adjusted Rand index. From a mathematical standpoint, Rand index is related to the accuracy, but is applicable even when class labels are not used.
0.1.8.0.9.1	0.1.8.0.9	Bootstrap Sampling	Model Validation	6	In statistics, bootstrapping is any test or metric that relies on random sampling with replacement. Bootstrapping allows assigning measures of accuracy (defined in terms of bias, variance, confidence intervals, prediction error or some other such measure) to sample estimates. This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods. Generally, it falls in the broader class of resampling methods. Bootstrapping is the practice of estimating properties of an estimator (such as its variance) by measuring those properties when sampling from an approximating distribution. One standard choice for an approximating distribution is the empirical distribution function of the observed data. In the case where a set of observations can be assumed to be from an independent and identically distributed population, this can be implemented by constructing a number of resamples with replacement, of the observed dataset (and of equal size to the observed dataset).
0.1.8.0.9.2	0.1.8.0.9	Cross Validation	Model Validation	6	Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it. In k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples.
0.1.8.0.9.3	0.1.8.0.9	ROC Curves	Model Validation	6	The ROC curve is a fundamental tool for diagnostic test evaluation. In a ROC curve the true positive rate (Sensitivity) is plotted in function of the false positive rate (100-Specificity) for different cut-off points of a parameter.
0.1.8.0.9.4	0.1.8.0.9	Precision and Recall	Model Validation	6	In statistics, if the null hypothesis is that all items are irrelevant (where the hypothesis is accepted or rejected based on the number selected compared with the sample size), absence of type I and type II errors corresponds respectively to maximum precision (no false positive) and maximum recall (no false negative). The above pattern recognition example contained 8 − 5 = 3 type I errors and 12 − 5 = 7 type II errors. Precision can be seen as a measure of exactness or quality, whereas recall is a measure of completeness or quantity.
0.1.8.0.9.5	0.1.8.0.9	Sensitivity and Specificity	Model Validation	6	In medical diagnosis, test sensitivity is the ability of a test to correctly identify those with the disease (true positive rate), whereas test specificity is the ability of the test to correctly identify those without the disease (true negative rate).
0.1.8.0.9.6	0.1.8.0.9	Kappa Statistic	Model Validation	6	Cohen s kappa coefficient is a statistic which measures inter-rater agreement for qualitative (categorical) items. It is generally thought to be a more robust measure than simple percent agreement calculation, since κ takes into account the possibility of the agreement occurring by chance.
0.1.8.0.9.7	0.1.8.0.9	Confusion Matrix	Model Validation	6	In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix,[4] is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix). Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa).[2] The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabeling one as another).
0.1.8.0.9.7.0	0.1.8.0.9.7	Confusion Matrix	Confusion Matrix	7	A confusion matrix is a table that is often used to describe the performance of a classification model (or classifier) on a set of test data for which the true values are known.Mar 25, 2014
0.1.8.0.9.7.1	0.1.8.0.9.7	True positives (TP)	Confusion Matrix	7	TP denote the number of true positives
0.1.8.0.9.7.2	0.1.8.0.9.7	True negatives (TN)	Confusion Matrix	7	TN denote the number of true negatives, correctly rejected
0.1.8.0.9.7.3	0.1.8.0.9.7	False positives (FP)	Confusion Matrix	7	FP denote the number of false positives, incorrectly identified, type 1 error
0.1.8.0.9.7.4	0.1.8.0.9.7	False negatives (FN)	Confusion Matrix	7	FN denote the number of false negatives, incorrectly rejected, type 2 error
0.1.8.0.9.7.5	0.1.8.0.9.7	Accuracy	Confusion Matrix	7	"More commonly, it is a description of systematic errors, a measure of statistical bias; as these cause a difference between a result and a ""true"" value, ISO calls this trueness."
0.1.8.0.9.7.6	0.1.8.0.9.7	Misclassification Rate	Confusion Matrix	7	"Also known as ""Error Rate"", 1 minus Accuracy"
0.1.8.0.9.7.7	0.1.8.0.9.7	True Positive Rate	Confusion Matrix	7	Sensitivity, recall, hit rate, or true positive rate (TPR).
0.1.8.0.9.7.8	0.1.8.0.9.7	False Positive Rate	Confusion Matrix	7	Fall-out or false positive rate (FPR)
0.1.8.0.9.7.9	0.1.8.0.9.7	Specificity	Confusion Matrix	7	Specificity, selectivity or true negative rate (TNR)
0.1.8.0.9.7.10	0.1.8.0.9.7	Precision	Confusion Matrix	7	"The false discovery rate (FDR) is a method of conceptualizing the rate of type I errors in null hypothesis testing when conducting multiple comparisons. FDR-controlling procedures are designed to control the expected proportion of ""discoveries"" (rejected null hypotheses) that are false (incorrect rejections).[1] FDR-controlling procedures provide less stringent control of Type I errors compared to familywise error rate (FWER) controlling procedures (such as the Bonferroni correction), which control the probability of at least one Type I error. Thus, FDR-controlling procedures have greater power, at the cost of increased numbers of Type I errors."
0.1.8.0.9.7.11	0.1.8.0.9.7	Prevalence	Confusion Matrix	7	The complement of the Negative Predictive Value is the false omission rate (FOR)
0.1.8.0.9.7.12	0.1.8.0.9.7	Positive Predictive Value	Confusion Matrix	7	"AKA Precision, a ""true positive"" is the event that the test makes a positive prediction, and the subject has a positive result under the gold standard, and a ""false positive"" is the event that the test makes a positive prediction, and the subject has a negative result under the gold standard. The ideal value of the PPV, with a perfect test, is 1 (100%), and the worst possible value would be zero."
0.1.8.0.9.7.13	0.1.8.0.9.7	Negative Predictive Value	Confusion Matrix	7	"A ""true negative"" is the event that the test makes a negative prediction, and the subject has a negative result under the gold standard, and a ""false negative"" is the event that the test makes a negative prediction, and the subject has a positive result under the gold standard. The ideal value of the NPV, with a perfect test, is 1 (100%), and the worst possible value would be zero."
0.1.8.0.9.7.14	0.1.8.0.9.7	F Score	Confusion Matrix	7	This is a weighted average of the true positive rate (recall) and precision.
0.1.8.0.10	0.1.8.0	Main Concepts	Machine learning 	5	Main Concepts
0.1.8.0.10.0	0.1.8.0.10	Predictive	Main Concepts	6	Predictive analytics encompasses a variety of statistical techniques from data mining, predictive modelling, and machine learning, that analyze current and historical facts to make predictions about future or otherwise unknown events.
0.1.8.0.10.0.0	0.1.8.0.10.0	Regression	Predictive	7	Regression: a numerical value is observed and Y = R
0.1.8.0.10.0.1	0.1.8.0.10.0	Classification	Predictive	7	Classification: group information is given and Y = {1, . . . , K}
0.1.8.0.10.1	0.1.8.0.10	Descriptive	Main Concepts	6	Descriptive analytics is a preliminary stage of data processing that creates a summary of historical data to yield useful information and possibly prepare the data for further analysis. Descriptive analytics is sometimes said to provide information about happened.
0.1.8.0.10.1.0	0.1.8.0.10.1	Clustering 	Descriptive	7	Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).
0.1.8.0.10.1.1	0.1.8.0.10.1	Visualization	Descriptive	7	Data visualization is a general term that describes any effort to help people understand the significance of data by placing it in a visual context. Patterns, trends and correlations that might go undetected in text-based data can be exposed and recognized easier with data visualization software.
0.1.8.0.10.2	0.1.8.0.10	Missing gap	Main Concepts	6	In statistics, missing data, or missing values, occur when no data value is stored for the variable in an observation. Missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data.
0.1.8.0.10.2.0	0.1.8.0.10.2	Inductive	Missing gap	7	"In logic, we often refer to the two broad methods of reasoning as the deductive and inductive approaches. Deductive reasoning works from the more general to the more specific. Sometimes this is informally called a ""top-down"" approach. We might begin with thinking up a theory about our topic of interest."
0.1.8.0.10.2.1	0.1.8.0.10.2	Deductive	Missing gap	7	"In logic, we often refer to the two broad methods of reasoning as the deductive and inductive approaches. Deductive reasoning works from the more general to the more specific. Sometimes this is informally called a ""top-down"" approach. We might begin with thinking up a theory about our topic of interest."
0.1.8.0.10.3	0.1.8.0.10	Segmentation	Main Concepts	6	Segmentation is the process of dividing potential markets or consumers into specific groups. Market research analysis using segmentation is a basic component of any marketing effort. ... There are four main types of segmentation used in market research analysis: a priori, usage, attitudinal and need.
0.1.8.0.10.3.0	0.1.8.0.10.3	A Priori Grouping	Grouping	7	A priori is defined as relating to knowledge that proceeds from theoretical deduction rather than from observation or experience. For purposes of market research analysis this means making certain assumptions about different groups that are generally accepted as pertaining to that group.  For example, deducing that adults over 50 are not as tech savvy as twenty somethings is a safe assumption based on the reasoning that high tech devices were not as widely available to the older generation than they are to the younger. However, be careful to check your assumptions since they can change over time. In 30 years, that statement may no longer be true.
0.1.8.0.10.3.0.0	0.1.8.0.10.3.0	RFM analysis	A Priori Grouping	8	RFM (recency, frequency, monetary) analysis is a marketing technique used to determine quantitatively which customers are the best ones by examining how recently a customer has purchased (recency), how often they purchase (frequency), and how much the customer spends (monetary).
0.1.8.0.10.3.0.0.0	0.1.8.0.10.3.0.0	Migration matrices	RFM analysis	9	Migration Matrices and Cumulative Default Probabilities. A migration matrix is a squared matrix with initial credit state, or rating, in rows and final credit state in columns.
0.1.8.0.10.3.0.1	0.1.8.0.10.3.0	Cell based Segments	A Priori Grouping	8	Cell based Segments
0.1.8.0.10.3.0.1.0	0.1.8.0.10.3.0.1	Variables  	Cell based Segments	9	Variables  
0.1.8.0.10.3.0.1.1	0.1.8.0.10.3.0.1	Time 	Cell based Segments	9	Time 
0.1.8.0.10.3.1	0.1.8.0.10.3	Clustering 	Grouping	7	Clustering 
0.1.8.0.10.3.1.0	0.1.8.0.10.3.1	Hierarchical methods	Clustering 	8	In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is amethod of cluster analysis which seeks to build ahierarchy of clusters.
0.1.8.0.10.3.1.1	0.1.8.0.10.3.1	Partition methods	Clustering 	8	The data table is first divided using the rangepartitioning method whose results are again subdivided into subdivisions using the hashpartitioning scheme. It combines the benefits of the two methods, i.e. the controlling power of range and the placing of information and striping by the hash.
0.1.8.0.10.3.1.2	0.1.8.0.10.3.1	Self organizing maps	Clustering 	8	A self-organizing map or self-organizing feature map is a type of artificial neural network that is trained using unsupervised learning to produce a low-dimensional, discretized representation of the input space of the training samples, called a map, and is therefore a method to do dimensionality reduction.
0.1.8.0.10.4	0.1.8.0.10	Supervised learning	Main Concepts	6	Supervised learning is the machine learning task oflearning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.
0.1.8.0.10.4.0	0.1.8.0.10.4	Classification learning 	Supervised learning	7	In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.
0.1.8.0.10.4.1	0.1.8.0.10.4	Preference learning 	Supervised learning	7	Preference learning is a subfield in machine learning in which the goal is to learn a predictive preference model from observed preference information.
0.1.8.0.10.4.1.0	0.1.8.0.10.4.1	Rank	Preference learning 	8	"Learning to rank[1] or machine-learned ranking (MLR) is the application of machine learning, typically supervised, semi-supervised or reinforcement learning, in the construction of ranking models for information retrieval systems. Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. ""relevant"" or ""not relevant"") for each item. The ranking model's purpose is to rank, i.e. produce a permutation of items in new, unseen lists in a way which is ""similar"" to rankings in the training data in some sense."
0.1.8.0.10.4.2	0.1.8.0.10.4	Function learning 	Supervised learning	7	Function learning 
0.1.8.0.10.4.2.0	0.1.8.0.10.4.2	Logistic regression	Function learning 	8	In statistics, the logistic model (or logit model) is a statistical model that is usually taken to apply to a binary dependent variable. In regression analysis,logistic regression or logit regression is estimating the parameters of a logistic model.
0.1.8.0.10.5	0.1.8.0.10	Unsupervised learning	Main Concepts	6	Unsupervised learning is a group of Machine Learning algorithms and approaches that work with this kind of “no-ground-truth” data
0.1.8.0.10.6	0.1.8.0.10	Reinforcement learning	Main Concepts	6	Reinforcement learning (RL) is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. The problem, due to its generality, is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In the operations research and control literature, reinforcement learning is called approximate dynamic programming, or neuro-dynamic programming. The problems of interest in reinforcement learning have also been studied in the theory of optimal control, which is concerned mostly with the existence and characterization of optimal solutions, and algorithms for their exact computation, and less with learning or approximation, particularly in the absence of a mathematical model of the environment. In economics and game theory, reinforcement learning may be used to explain how equilibrium may arise under bounded rationality.
0.1.8.0.10.7	0.1.8.0.10	Parametric	Main Concepts	6	Parametric statistics is a branch of statistics which assumes that sample data comes from a population that follows a probability distribution based on a fixed set of parameters. Most well-known elementary statistical methods are parametric.
0.1.8.0.10.8	0.1.8.0.10	Semi-parametric	Main Concepts	6	Generally used to fit a parametric model in which the. functional form of a subset of the explanatory variables is not. known and/or in which the distribution of the error term. cannot be assumed to be of a specific type beforehand. Most popular semiparametric regression models are the.
0.1.8.0.10.9	0.1.8.0.10	Non-parametric	Main Concepts	6	Nonparametric statistics refer to a statistical method in which the data is not required to fit a normal distribution.Nonparametric statistics uses data that is often ordinal, meaning it does not rely on numbers, but rather a ranking or order of sorts.
0.1.8.0.10.10	0.1.8.0.10	Instance based	Main Concepts	6	In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compares new problem instances with instances seen in training, which have been stored in memory.
0.1.8.0.10.11	0.1.8.0.10	Bayesian	Main Concepts	6	Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics.
0.1.8.0.10.12	0.1.8.0.10	Hyperplanes	Main Concepts	6	In geometry, a hyperplane is a subspace whose dimension is one less than that of its ambient space. If a space is 3-dimensional then its hyperplanes are the 2-dimensional planes, while if the space is 2-dimensional, its hyperplanesare the 1-dimensional lines.
0.1.8.0.10.13	0.1.8.0.10	Decision trees	Main Concepts	6	A decision tree is a decision support tool that uses atree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility.
0.1.8.0.10.14	0.1.8.0.10	Probabilistic Classifiers	Main Concepts	6	Probabilistic Classifiers. A Bayes classifier is a probabilistic model that is used for supervised learning. A Bayes classifier is based on the idea that the role of a class is to predict the values of features for members of that class.
0.2	0	Data treatment	Statistics	2	"Statistical treatment of data is essential in order to make use of the data in the right form. Raw data collection is only one aspect of any experiment; the organization ofdata is equally important so that appropriate conclusions can be drawn. This is what statistical treatment of data is all about."
0.2.0	0.2	Missing data	Data treatment	3	"Missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data. Missing data can occur because of nonresponse: no information is provided for one or more items or for a whole unit (""subject"")."
0.2.0.0	0.2.0	The concept of missing data	Missing data	4	Missing data mean that we are missing some type of information about the phenomena in which we are interested. When observations are missing for any reason, our ability to understand the nature of the phenomena is reduced and the extent to which is not often known. Then missing data are, in general, a threat to validity of scientific inquiry.
0.2.0.1	0.2.0	The prevalence of missing data	Missing data	4	Review of journal articles suggest that missing data are common and often not given adequate attention by social scientists – the problem is either ignored or finessed and such situation cover different areas of scientific activity and the potential impact of missing data on research is worrisome! or finessed and such situation cover different areas of scientific activity and the potential impact of missing data on research is worrisome!
0.2.0.2	0.2.0	Why data might be missing	Missing data	4	We can consider three broad categories: 1- the study participants, 2- the study design, 3- the interaction of the participants and the study design.The stage of the study in which missing data occurs is also informative.Data can be lost at the study recruitment stage, the implementation stage, or the follow-up stage. Data missing from the recruitment stage could be due to exclusionary criteria for the study, dropout prior to assignment to experimental conditions (e.g., treatment groups), or participants losing interest in the study prior to signing a consent form. Data missing during the implementation stage might be due to skipped items on questionnaires, to absence during a data collection period, or to refusal to participate after being recruited. Data missing at follow-up is a familiar situation for longitudinal researchers: data could be missing due to participants dropping out of the study or to the inability to contact participants for follow-up data.
0.2.0.3	0.2.0	Data might be missing	Missing data	4	Reasons that data might be missing
0.2.0.3.0	0.2.0.3	Different units of analysis	Data might be missing	5	Unit missing data, referring to data for an entire unit of analysis that is missing (some participant) and Missing values, referring to scores on a particular variable (questionnaire item) that are missing.
0.2.0.3.1	0.2.0.3	Multilevel studies	Data might be missing	5	missing data” can occur at the individual or participants level, at the group level (example, by gender) and /or at the organization or community level (hospitals, schools, banks)
0.2.0.3.2	0.2.0.3	Single items within a measure	Data might be missing	5	Similary, “missing values” can occur for single items within a measure, for subscales and for entire test scores.
0.2.0.3.3	0.2.0.3	Cross-sectionally	Data might be missing	5	Data can be missing cross-sectionally (for persons or variables observed at a single occasion) or across time in longitudinal studies.
0.2.0.4	0.2.0	The impact of missing data 	Missing data	4	The amount of missing data the actual process that causes missing data can affect the validity of inferences made from the analysis
0.2.0.5	0.2.0	Components of the scientific process for missing data	Missing data	4	Measurement, Understanding relationship between variables, Drawing scientific conclusions
0.2.0.6	0.2.0	Missing data problems arise from 	Missing data	4	Missing data problems arise from 
0.2.0.6.0	0.2.0.6	Missing cases 	Missing data problems arise from 	5	Occur when study participants fail to provide data per study
0.2.0.6.1	0.2.0.6	Missing variables occur	Missing data problems arise from 	5	When participants fail to provide data for some but not all variables
0.2.0.6.2	0.2.0.6	Missing occasion	Missing data problems arise from 	5	Occur when participants are available for some but not all of the data collection periods in a longitudinal study.
0.2.0.7	0.2.0	Stages	Missing data	4	Participant recruitment\\ Assignment to conditions (experimental studies)\\ Data collection and maintenance\\ Data entry\\ Data analysis\\ Report results\\
0.2.0.8	0.2.0	Consequences of missing data	Missing data	4	Consequences of missing data
0.2.0.8.0	0.2.0.8	On construct validity	Consequences of missing data	5	Reflects how well our measures capture the constructs we wish to observe and how well the scores on our measures predict other relevant variables. Reliability is defined as the degree of true – score variation relative to observed – score variation. We see that as the error variance increase, reliability decrease. Then with missing data, we lost information, which can rise to larger amounts of error variance. Measurement bias is another potential problem with missing data. For single measures composed of multiple items or indicators the information obtained may reflect only a portion of the construct of interest.
0.2.0.8.1	0.2.0.8	On internal validity	Consequences of missing data	5	Missing data can affect both the reliability (stability, consistency, or reproducibility) and validity (accuracy, verisimilitude, or generalizability) of research findings. Missing data can influence the interpretation of findings in a study, the synthesis or results across studies and the process of building a sound knowledge concerning the field and the study.
0.2.0.9	0.2.0	Selection for data analytical procedures	Missing data	4	Selection for data analytical procedures
0.2.0.9.0	0.2.0.9	Steps to select a method for handling missing data.	Selection for data analytical procedures	5	Steps to select a method for handling missing data.
0.2.0.9.0.0	0.2.0.9.0	Identifying relevant study variables	Steps to select a method for handling missing data.	6	We recommend that analyst first identify the specific variables for analysis before considering what may be missing. By this way we are simplifying both diagnostic and treating missing data.
0.2.0.9.0.1	0.2.0.9.0	Specifying the level of analysis	Steps to select a method for handling missing data.	6	Identification of the level of analysis in an important preliminary step in the missing data decision-making process: •when micro level data are aggregated and the aggregate is the focus of analysis, missing data at the micro level may not be great problem. •But, in the other cases, missing micro level data can create strong biais in macro level analysis (for example in longitudinal studies when estimating change parameters). •Also biased results may occur when the micro level is the unit of analysis and when macro level data are missing.
0.2.0.9.0.2	0.2.0.9.0	Conducting missing data diagnostics	Steps to select a method for handling missing data.	6	If the missing data mechanism is known Amount of missing data
0.2.0.9.0.3	0.2.0.9.0	Selecting relevant statistical models and tests.	Steps to select a method for handling missing data.	6	Some guidelines, About Parameter estimation, Identify Statistical software default procedures
0.2.0.9.1	0.2.0.9	Decision making	Selection for data analytical procedures	5	To describe a sample or phenomena, To assess relations between variables or items, To assess change over time in the same variable or variables, To compare groups, To assess change over time and compare groups
0.2.0.10	0.2.0	Procedures	Missing data	4	General procedures handling missing data
0.2.0.10.0	0.2.0.10	Diagnostic of missing data	Procedures	5	Diagnosing the type and extent of missing data (using the most popular statistical software procedures). Proper diagnostic inform the researcher about the inferential limitation from the observed data and about caution when interpreting results
0.2.0.10.1	0.2.0.10	Diagnosting the missing data mechanism	Procedures	5	As was already introduced, we consider three missing data mechanisms – missing completely at random (MCAR), missing at random (MAR) and missing not at random (MNAR). Little MCAR test (1988) avoid this problem associated with multiple significance tests. The MCAR test compares the observed variable means for each pattern of missing values with the expected population means (maximum likelihood estimates) and compute an overall, weighted squared deviation (almost like a sum of squares weighted by the covariance between variables).
0.2.0.10.2	0.2.0.10	Diagnosing the amount of missing data	Procedures	5	Most often, amount refers to the number of incomplete cases. In our data there are 6 participants (1, 4, 6, 8, 9 and 10) with missing data for at least one variable (60% of the participants).Amount of missing data can also refer to the total number of missing observations for a particular variable or set of variables. For instance for the DV there are two cases (20%) that are missing data. Amount of missing data can also refer to the total number of missing observations out of an entire data set. In our data there are 6 cells missing data out of a total of 50 cells (or 12% of cases missing data). 
0.2.0.10.3	0.2.0.10	Methods for assessing the extent to which data are missing	Procedures	5	Methods for assessing the extent to which data are missing
0.2.0.10.3.0	0.2.0.10.3	Listwise or complete case method	Methods for assessing the extent to which data are missing	6	When the amount of missing data is viewed as the number of cases with missing data for at least one variable, we use the Listwise or complete case method. Then complete case method can be often a problematic solution to missing data problems.
0.2.0.10.3.1	0.2.0.10.3	The complete variable method	Methods for assessing the extent to which data are missing	6	This method provide an estimate of the proportion of variables than contain missing values. Our considerations about the complete case analysis can be repeated for this method, which means that this method can also represent a problematic solution to missing data problems.
0.2.0.10.3.2	0.2.0.10.3	The available case method	Methods for assessing the extent to which data are missing	6	When amount of missing data is defined as the number of missing values for each variable (this method is sometimes referred to as pairwise delection). The information provided is pertinent to understanding patterns of missing data. In our data, each variable has only one missing data, except the DV, which has two. And the pattern in the way data are missing is not uniform: for each variable, a different participant is missing a value.
0.2.0.10.3.3	0.2.0.10.3	Sparse matrix method and its related ratio method	Methods for assessing the extent to which data are missing	6	In such method we compute the amount of missing values in the total matrix data. In our data a maximum of 50 observations is possible (10 participants x 5 variables) only six cells are missing (12%)
0.2.0.10.3.4	0.2.0.10.3	The ratio method	Methods for assessing the extent to which data are missing	6	An index defined by the ratio of sparse matrix amount missing to complete case amount missing – such ratio offers an average amount of missing variables per incomplete case. Taking values between 0 and 1, the higher the ratio, the more missing data are present for each case.
0.2.0.10.4	0.2.0.10	Diagnosing levels and pattern of missing data	Procedures	5	Diagnosing levels and pattern of missing data
0.2.0.10.4.0	0.2.0.10.4	 Levels or unit of analysis	Diagnosing levels and pattern of missing data	6	Example – in education, we might wish to focus on students rather than on schools – thus we analyze the data using student – level information. If we want to focus on schools we would use school –level information. (
0.2.0.10.4.1	0.2.0.10.4	Pattern of missing data	Diagnosing levels and pattern of missing data	6	The pattern of missing data can be calculated by a straightforward procedure: to create a unique code for each pattern: From the dummy code matrix for the missing data, each variable is represented numerically by 2k where k is the number of the column represented by that variable in the data set.
0.2.0.10.4.2	0.2.0.10.4	Diagnostic procedures using graphing	Diagnosing levels and pattern of missing data	6	The data matrix plot: the data matrix, after being dummy coded for missing data, is plotted in two colors (usually black and white) to represent missing an unmissing values. The Dot Chart is a graphical representation of the missing data patterns sorted by a specified grouping variable.
0.2.0.10.4.3	0.2.0.10.4	Dummy coding missing data	Diagnosing levels and pattern of missing data	6	"All diagnostic procedures start with one fundamental step – Dummy coding missing values If a value is missing in the data matrix, a dummy code corresponding to that variable is coded as 1; otherwise is coded as 0:Dummy coding serves as the basis for a numerical diagnostic approach: numerical procedures produce diagnostic information in the form of quantitative indices. We will study quantitative indices that can be used to assess the facets of missing data – mechanism, amount and pattern, dimensions and level of missing data."
0.2.0.11	0.2.0	Single imputation 	Missing data	4	Single imputation methods. Single imputation denotes that the missing value is replaced by a value. In this method the sample size is retrieved. However, the imputed values are assumed to be the real values that would have been observed when the data would have been complete.
0.2.0.11.0	0.2.0.11	A constant	Single imputation 	5	Impute a constant
0.2.0.11.0.0	0.2.0.11.0	Mean Substitution	A constant	6	Mean Substitution
0.2.0.11.0.0.0	0.2.0.11.0.0	Mean	Mean Substitution	7	Mean imputation is the replacement of a missing observation with the mean of the non-missing observations for that variable.Is a popular method in social sciences and easy to implement in most statistical software packages but if mean values are imputed, extreme values are underrepresented and the variable with missing value will decrease in variance – the method generate biased estimates of variances and covariance's and generally must be avoid.
0.2.0.11.0.0.1	0.2.0.11.0.0	K-nearest neighbors (KNN	Mean Substitution	7	ML provides an estimate of the population mean (μ) rather than calculate the sample mean. In various probabilistic context, ML estimate is sample mean. Otherwise, substantial deviation from the assumed distribution tend to render poor estimates of the mean and offer few or no advantages over the arithmetic mean.
0.2.0.11.0.1	0.2.0.11.0	Median imputation	A constant	6	When underlying distribution are skewed as well as those that are flat or peaked (Platykurtic, leptokurtic), there is a risk for being poorly represented by mean then, an alternative measure of the central tendency provides a better summary of the underlying distribution in particular, the median frequently performs well as a measure of central tendency when distribution deviate from the standard normal distribution (or from other symmetric distribution)
0.2.0.11.0.2	0.2.0.11.0	Zero imputation	A constant	6	Zero imputation is the most common procedure in binary response measures.
0.2.0.11.1	0.2.0.11	A random selected value	Single imputation 	5	A random selected value
0.2.0.11.1.0	0.2.0.11.1	Empirical procedures	A random selected value	6	Empirical procedures
0.2.0.11.1.0.0	0.2.0.11.1.0	Hot Deck imputation	Empirical procedures	7	a) One involves randomly selecting a value from the observed data to replace a missing value. b) A related method is hot deck within adjustment cells which involves doing the same but after blocking on relevant covariates. c) a third hot deck method is to use the nearest neighbor's value to replace the missing data.
0.2.0.11.1.0.1	0.2.0.11.1.0	Cold Deck imputation	Empirical procedures	7	In this method we use values from another data set to replace missing values from the current data set. Survey research is the most likely situation where cold deck imputation can be possible. However, there are other situations where it can be possible to consider a Cold Deck approach.
0.2.0.11.1.1	0.2.0.11.1	Model based procedures	A random selected value	6	Model based procedures
0.2.0.11.1.1.0	0.2.0.11.1.1	The Bernoulli or binomial distribution 	Model based procedures	7	For dichotomous outcomes
0.2.0.11.1.1.1	0.2.0.11.1.1	The Poisson distribution for counted variables	Model based procedures	7	For rare outcomes such juvenile criminality
0.2.0.11.1.1.2	0.2.0.11.1.1	The multinomial distribution 	Model based procedures	7	For unordered categorical values
0.2.0.11.2	0.2.0.11	A nonrandom derived value	Single imputation 	5	A nonrandom derived value
0.2.0.11.2.0	0.2.0.11.2	Regression imputation	A nonrandom derived value	6	Regression imputation predicts the missing value by using a regression of the item of interest on variables observed for all cases.
0.2.0.11.2.1	0.2.0.11.2	Deductive imputation	A nonrandom derived value	6	Values may be imputed in the data editing, using logical relations among the variables
0.2.0.11.2.2	0.2.0.11.2	Cells means imputations	A nonrandom derived value	6	Then, persons2 and 6, missing the value for years of education, would be assigned the mean value for the four women age 35 or older who respond to the question: 12.25
0.2.0.11.2.3	0.2.0.11.2	Stochastic cell mean imputation	A nonrandom derived value	6	If the response variable were approximately normally distributed, the missing values could be imputed with a randomly generated value from a normal distribution with mean = average of the values for the respond units in cell X and variance equal to corresponding empirical variance
0.2.0.12	0.2.0	Multiple imputation	Missing data	4	Multiple imputation is a statistical technique for analyzing incomplete data sets, that is, data sets for which some entries are missing. Application of the technique requires three steps: imputation, analysis and pooling. The figure illustrates these steps.
0.2.1	0.2	Outliers	Data treatment	3	"In statistics, an outlier is an observation point that is distant from other observations. An outlier may be due to variability in the measurement or it may indicate experimental error; the latter are sometimes excluded from the data set."
0.2.1.0	0.2.1	Graphical procedures	Outliers	4	Graphical procedures
0.2.1.0.0	0.2.1.0	Histogram	Graphical procedures	5	A diagram consisting of rectangles whose area is proportional to the frequency of a variable and whose width is equal to the class interval.
0.2.1.0.1	0.2.1.0	Box-plot	Graphical procedures	5	A simple way of representing statistical data on a plot in which a rectangle is drawn to represent the second and third quartiles, usually with a vertical line inside to indicate the median value. The lower and upper quartiles are shown as horizontal lines either side of the rectangle.
0.2.1.0.2	0.2.1.0	Andrews Plots	Graphical procedures	5	In data visualization, an Andrews plot or Andrews curve is a way to visualize structure in high-dimensional data. To visualize them, the Andrews plot defines a finite Fourier series: This function is then plotted for .
0.2.1.0.3	0.2.1.0	Q-Q plot	Graphical procedures	5	A q-q plot is a plot of the quantiles of the first data set against the quantiles of the second data set. By a quantile, we mean the fraction (or percent) of points below the given value. If the two sets come from a population with the same distribution, the points should fall approximately along this reference line.
0.2.1.0.4	0.2.1.0	Outliers in simple linear regression	Graphical procedures	5	A data point is influential if it unduly influences any part of a regression analysis, such as the predicted responses, the estimated slope coefficients, or the. One advantage of the case in which we have only one predictor is that we can look at simple scatter plots in order to identify any outliers and influential data points.
0.2.1.1	0.2.1	Outliers may arise	Outliers	4	Outliers may arise
0.2.1.1.0	0.2.1.1	Inherent variability	Outliers may arise	5	Reflects the distributional properties of a correct basic model describing the generation of the data
0.2.1.1.1	0.2.1.1	Measurement error	Outliers may arise	5	Errors in the measurement instrument or mistakes in recording the measurement.
0.2.1.1.2	0.2.1.1	Execution error	Outliers may arise	5	Arises in the imperfect collection of our data, if we choose a biased sample or we include individuals not truly representative of the population.
0.2.1.2	0.2.1	Model-based	Outliers	4	Model-based
0.2.1.2.0	0.2.1.2	Statistical Tests	Model-based	5	A statistical test provides a mechanism for making quantitative decisions about a process or processes. ... For more discussion about the meaning of a statistical hypothesis test.
0.2.1.2.0.0	0.2.1.2.0	Procedures for univariate samples	Statistical Tests	6	Procedures for univariate samples
0.2.1.2.0.0.0	0.2.1.2.0.0	Robust estimation of dispersion	Procedures for univariate samples	7	Robust statistics are statistics with good performance for data drawn from a wide range of probability distributions, especially for distributions that are not normal. Robust statistical methods have been developed for many common problems, such as estimating location, scale, and regression parameters.
0.2.1.2.0.0.0.0	0.2.1.2.0.0.0	Winsorized variance	Robust estimation of dispersion	8	Compute the Winsorized variance of a variable. Description: The standard variance estimate can be heavily influenced by extreme values. The Winsorized variance compensates for this by setting the tail values equal to a certain percentile value.
0.2.1.2.0.0.1	0.2.1.2.0.0	Winsorizing	Procedures for univariate samples	7	Winsorizing or winsorization is the transformation of statistics by limiting extreme values in the statistical data to reduce the effect of possibly spurious outliers. It is named after the engineer-turned-biostatistician Charles P. Winsor (1895–1951). The effect is the same as clipping in signal processing.
0.2.1.2.0.0.2	0.2.1.2.0.0	Trimming	Procedures for univariate samples	7	A truncated mean or trimmed mean is a statistical measure of central tendency, much like the mean and median. For example, given a set of 8 points, trimming by 12.5% would discard the minimum and maximum value in the sample: the smallest and largest values, and would compute the mean of the remaining 6 points.
0.2.1.2.0.0.3	0.2.1.2.0.0	Gastwirth estimator	Procedures for univariate samples	7	Gastwirth's location estimator, an alternative to the mean that is the subject of this post.
0.2.1.2.0.0.4	0.2.1.2.0.0	Trimean	Procedures for univariate samples	7	Trimean is a measure of central tendency, like mean, median and mode. Its meaning is sometimes confusing because it is defined in a manner different from these traditional measures of central tendencies.
0.2.1.2.0.0.5	0.2.1.2.0.0	Median	Procedures for univariate samples	7	The median is a simple measure of central tendency. To find the median, we arrange the observations in order from smallest to largest value. If there is an odd number of observations, the median is the middle value. If there is an even number of observations, the median is the average of the two middle values.
0.2.1.2.0.1	0.2.1.2.0	Testing for discordancy:	Statistical Tests	6	These methods are works with a formula necessary to identify the outliers in the data set. There are two kinds of outlier detection methods: formal test and informal test. It is usually called as tests of discordancy and labeling methods, respectively.
0.2.1.2.0.1.0	0.2.1.2.0.1	Tests 	Testing for discordancy:	7	Tests 
0.2.1.2.0.1.0.0	0.2.1.2.0.1.0	Grubbs tests for one or two outliers in data sample	Tests 	8	Grubbs' test (named after Frank E. Grubbs, who published the test in 1950), also known as the maximum normalized residual test or extreme studentized deviate test, is a statistical test used to detect outliers in a univariate data set assumed to come from a normally distributed population.
0.2.1.2.0.1.0.1	0.2.1.2.0.1.0	Dixon tests for outlier	Tests 	8	In statistics, Dixon's Q test, or simply the Q test, is used for identification and rejection of outliers. This assumes normal distribution and per Robert Dean and Wilfrid Dixon, and others, this test should be used sparingly and never more than once in a data set.
0.2.1.2.0.1.0.2	0.2.1.2.0.1.0	Cochran test for outlying or inlying variance	Tests 	8	Cochran test may refer to two different statistical tests: Cochran's Q test, a non-parametric test that is applied to the analysis of two-way randomized block designs with a binary response variable. Cochran's C test, a variance outlier test.
0.2.1.2.0.1.0.3	0.2.1.2.0.1.0	Chi-squared test for outlier	Tests 	8	Chi-square Test. Chi-square test is one of the important nonparametric tests that is used to compare more than two variables for a randomly selected data. The expected frequencies are calculated based on the conditions of null hypothesis. ... The Chi-square test statistic is, with k-1 degrees of freedom.
0.2.1.2.0.1.0.4	0.2.1.2.0.1.0	Rubbs tests for one or two outliers in data sample	Tests 	8	Grubbs' test (named after Frank E. Grubbs, who published the test in 1950), also known as the maximum normalized residual test or extreme studentized deviate test, is a statistical test used to detect outliers in a univariate data set assumed to come from a normally distributed population.
0.2.1.2.0.2	0.2.1.2.0	Dealing with Discordancy	Statistical Tests	6	Dealing with Discordancy
0.2.1.2.0.2.0	0.2.1.2.0.2	Rejection	Dealing with Discordancy	7	We may indeed decide to reject (or replace) the discordant outliers and proceed to analyse the residual (modified) data on the original model.
0.2.1.2.0.2.1	0.2.1.2.0.2	Modification	Dealing with Discordancy	7	We may indeed decide to reject (or replace) the discordant outliers and proceed to analyse the residual (modified) data on the original model.
0.2.1.2.0.2.2	0.2.1.2.0.2	Incorporation	Dealing with Discordancy	7	We may choose to modify the model for incorporation of the outliers in a non-discordant fashion.
0.2.1.2.0.2.3	0.2.1.2.0.2	Identification	Dealing with Discordancy	7	We may concentrate attention on the discordant outliers as a welcome identification of unsuspected factors of practical importance.
0.2.1.2.1	0.2.1.2	Depth-based Approaches 	Model-based	5	Depth-based Approaches 
0.2.1.2.1.0	0.2.1.2.1	ISOdepth	Depth-based Approaches 	6	Depth functions are statistical tools, used to attribute a sensible ordering to observations in a sample from the center outwards. Recently several depth functions have been proposed for functional data. These depth functions can for example be used for robust classification and for the detection of outlying curves. A new depth function is presented, which can be applied to multivariate curves and which takes the local changes in the amount of variability in amplitude into account
0.2.1.2.1.1	0.2.1.2.1	FDC	Depth-based Approaches 	6	Depth functions are statistical tools, used to attribute a sensible ordering to observations in a sample from the center outwards. Recently several depth functions have been proposed for functional data. These depth functions can for example be used for robust classification and for the detection of outlying curves. A new depth function is presented, which can be applied to multivariate curves and which takes the local changes in the amount of variability in amplitude into account
0.2.1.2.2	0.2.1.2	Deviation-based Approaches	Model-based	5	Deviation-based Approaches
0.2.1.2.2.0	0.2.1.2.2	ODseq	Deviation-based Approaches	6	Outlier (also called deviation or exception) detection is an important function in data mining. In identifying outliers, the deviation-based approach has many advantages and draws much attention. Although a linear algorithm for sequential deviation detection is proposed, it is not stable and always loses many deviation points. In this paper, we present three algorithms on detecting deviations. The first algorithm is time proportional to the square of the dataset length, and the second is time proportional to the square of the number of distinct data values. These two algorithms lead to same result, while the latter is much more efficient than the former. In the third algorithm, a deviation factor is defined to help finding deviation points. Although leading to approximation results, it is the most efficient of the three, especially to large datasets with lots of distinct values.
0.2.1.3	0.2.1	Proximity-based	Outliers	4	Proximity-based
0.2.1.3.0	0.2.1.3	Distance-based Approaches	Proximity-based	5	Distance-based Approaches
0.2.1.3.0.0	0.2.1.3.0	Index-based	Distance-based Approaches	6	Distance based methods use the same parametric model for the substitutions and deduce from these rates evolutionary distances between units. The distance matrix is then analyzed by hierarchical clustering type methods such as neighbor-joining (single linkage clustering) or unweighted pair-group with arithmetic mean (average clustering). Distance-based methods can be seen as intermediary containing both parametric and non parametric components. Compute distance rangj g eoin using spatial index structure – Exclude point from further consideration if its ε-neighborhood contains more than Card(DB) . π points
0.2.1.3.0.1	0.2.1.3.0	Nested-loop based	Distance-based Approaches	6	Divide buffer in two parts. Use second part to scan/compare all points with the points from the first part
0.2.1.3.0.2	0.2.1.3.0	Grid-based	Distance-based Approaches	6	Build grid such that any two points from the same grid cell have a distance of Build grid such that any two points from the same grid cell have a distance of at most ε to each other – Points need only compared with points from neighboring cells
0.2.1.3.0.3	0.2.1.3.0	Linearization	Distance-based Approaches	6	Linearization of a multi-dimensional data set using space-fill curves – 1D representation is partitioned into micro clusters – Algorithm for the average Algorithm for the average kNN-distance model distance model
0.2.1.3.0.4	0.2.1.3.0	ORCA	Distance-based Approaches	6	NL algorithm with randomization and simple pruning – Pruning p : if a point has a score greater than the top-n outlier so far (cut-off), remove this point from further consideration => non-outliers are pruned => works good on randomized data (can be done in linear time) > t ï NL l ith 36 => worst-case: naïve NL algorithm – Algorithm for both kNN-distance models and the DB(ε,π)-outlier model
0.2.1.3.0.5	0.2.1.3.0	Partition-based detection	Distance-based Approaches	6	Use BIRCH clustering to identify clusters/partitions of non-outliers -Prune partitions that do not contain outliers -Use Index/Nested Loop algorithms on the remaining data points -Since many data point are removed during pruning, the efficiency is increased significantly.
0.2.1.3.0.6	0.2.1.3.0	Cell-Based	Distance-based Approaches	6	Divide the dataset into cells with length -K is the dimensionality, D is the distance-Define Layer-1 neighbors – all the intermediate neighbor cells. The maximum distance between a cell and its neighbor cells is D-Define Layer-2 neighbors – the cells within 3 cell of a certain cell. The minimum distance between a cell and the cells outside of Layer-2 neighbors is D 
0.2.1.3.1	0.2.1.3	Density-based Approaches	Proximity-based	5	Density-Based Clustering refers to   unsupervised learning methods that identify distinctive groups/clusters in the data, based on the idea that a cluster in a data space is a contiguous region of high point density, separated from other such clusters by contiguous regions of low point density. The data points in the separating regions of low point density are typically considered noise/outliers.
0.2.1.4	0.2.1	Adaptation of different models to a special problem	Outliers	4	Adaptation of different models to a special problem
0.2.1.4.0	0.2.1.4	High dimensional Approaches	Adaptation of different models to a special problem	5	High dimensional Approaches
0.2.1.4.0.0	0.2.1.4.0	Angle-based approaches 	High dimensional Approaches	6	Angles are more stable than distances in high dimensional spaces (cf Angles are more stable than distances in high dimensional spaces (cf. e.g. the popularity of cosine-based similarity measures for text data)  - Object o is an outlier if most other objects are located in similar directions - Object o is no outlier if many other objects are located in varying Object o is no outlier if many other objects are located in varying directions
0.2.1.4.0.1	0.2.1.4.0	Grid-based subspace outlier detection	High dimensional Approaches	6	Partition data space by an equi Partition data space by an equi-depth grid ( depth grid (Φ = number of cells in each = number of cells in each dimension) - Sparsity coefficient S(C) for a k-dimensional grid cell C  where count(C) is the number of data objects in C -  S(C) <0 => count(C) is lower than expected -  Outliers are those objects that are located in lower-dimensional cells with negative sparsity coefficient
0.2.1.4.0.2	0.2.1.4.0	SOD – subspace outlier degree	High dimensional Approaches	6	Compute the subspace in which the kNNs of a point p minimize the variance. Compute the hyperplane that is orthogonal to that subspace - Take the distance of p to the hyperplane as measure for its “outlierness”
0.2.2	0.2	Feature Scaling	Data treatment	3	Feature scaling is a method used to standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step.
0.2.2.0	0.2.2	n1 - standardization ((x-mean)/sd)	Feature Scaling	4	n1 - standardization ((x-mean)/sd)
0.2.2.1	0.2.2	Standardization	Feature Scaling	4	Standardization
0.2.2.2	0.2.2	Positional standardization 	Feature Scaling	4	Positional standardization 
0.2.2.3	0.2.2	Unitization 	Feature Scaling	4	Unitization 
0.2.2.4	0.2.2	Positional unitization  	Feature Scaling	4	Positional unitization  
0.2.2.5	0.2.2	Unitization with zero minimum 	Feature Scaling	4	Unitization with zero minimum 
0.2.2.6	0.2.2	Normalization in range <-1,1> 	Feature Scaling	4	Normalization in range <-1,1> 
0.2.2.7	0.2.2	Positional normalization in range <-1,1> 	Feature Scaling	4	Positional normalization in range <-1,1> 
0.2.2.8	0.2.2	Quotient transformation (x/sd)	Feature Scaling	4	Quotient transformation (x/sd)
0.2.2.9	0.2.2	Positional quotient transformation  	Feature Scaling	4	Positional quotient transformation  
0.2.2.10	0.2.2	Quotient transformation with range	Feature Scaling	4	Quotient transformation with range
0.2.2.11	0.2.2	Quotient transformation with max	Feature Scaling	4	Quotient transformation with max
0.2.2.12	0.2.2	Quotient transformation with mean	Feature Scaling	4	Quotient transformation with mean
0.2.2.13	0.2.2	Positional quotient transformation 	Feature Scaling	4	Positional quotient transformation 
0.2.2.14	0.2.2	Quotient transformation with sum	Feature Scaling	4	Quotient transformation with sum
0.2.2.15	0.2.2	Quotient transformation 	Feature Scaling	4	Quotient transformation 
0.2.2.16	0.2.2	Normalization 	Feature Scaling	4	Normalization 
0.2.2.17	0.2.2	Positional normalization 	Feature Scaling	4	Positional normalization 
0.2.2.18	0.2.2	Normalization with zero being the central point 	Feature Scaling	4	Normalization with zero being the central point`

// Get JSON data
data = d3.dsv('\t').parse(lala);
		
  // *********** Convert flat data into a nice tree ***************
  // create a name: node map
//letters = d3.csv.parse(bardata, function(d) {
//    return {
//        letter:d.letter, 
//        frequency:+d.frequency
//    };
//});  	
  
  
  
  var dataMap = data.reduce(function(map, node) {
    map[node.name] = node;
    return map;
  }, {});

  // create the tree array
  var treeData = [];
  data.forEach(function(node) {
    // add to parent
    var parent = dataMap[node.parent];
    if (parent) {
      // create child array if it doesn't exist
      (parent.children || (parent.children = []))
        // add node to child array
        .push(node);
    } else {
      // parent is null or missing
      treeData.push(node);
    }
  });
    // Calculate total nodes, max label length
    var totalNodes = 0;
    var maxLabelLength = 0;
    // variables for drag/drop
    var selectedNode = null;
    var draggingNode = null;
    // panning variables
    var panSpeed = 200;
    var panBoundary = 20; // Within 20px from edges will pan when dragging.
    // Misc. variables
    var i = 0;
    var duration = 750;
    var root;

    // size of the diagram
    var viewerWidth = $(document).width();
    var viewerHeight = $(document).height();

    var tree = d3.layout.tree()
        .size([viewerHeight, viewerWidth]);

    // define a d3 diagonal projection for use by the node paths later on.
    var diagonal = d3.svg.diagonal()
        .projection(function(d) {
            return [d.y, d.x];
        });

    // A recursive helper function for performing some setup by walking through all nodes

    function visit(parent, visitFn, childrenFn) {
        if (!parent) return;

        visitFn(parent);

        var children = childrenFn(parent);
        if (children) {
            var count = children.length;
            for (var i = 0; i < count; i++) {
                visit(children[i], visitFn, childrenFn);
            }
        }
    }

    // Call visit function to establish maxLabelLength
    visit(treeData[0], function(d) {
        totalNodes++;
        maxLabelLength = Math.max(d.name.length, maxLabelLength);

    }, function(d) {
        return d.children && d.children.length > 0 ? d.children : null;
    });


    // sort the tree according to the node names

    function sortTree() {
        tree.sort(function(a, b) {
            return b.name.toLowerCase() < a.name.toLowerCase() ? 1 : -1;
        });
    }
    // Sort the tree initially incase the JSON isn't in a sorted order.
    sortTree();

    // TODO: Pan function, can be better implemented.

    function pan(domNode, direction) {
        var speed = panSpeed;
        if (panTimer) {
            clearTimeout(panTimer);
            translateCoords = d3.transform(svgGroup.attr("transform"));
            if (direction == 'left' || direction == 'right') {
                translateX = direction == 'left' ? translateCoords.translate[0] + speed : translateCoords.translate[0] - speed;
                translateY = translateCoords.translate[1];
            } else if (direction == 'up' || direction == 'down') {
                translateX = translateCoords.translate[0];
                translateY = direction == 'up' ? translateCoords.translate[1] + speed : translateCoords.translate[1] - speed;
            }
            scaleX = translateCoords.scale[0];
            scaleY = translateCoords.scale[1];
            scale = zoomListener.scale();
            svgGroup.transition().attr("transform", "translate(" + translateX + "," + translateY + ")scale(" + scale + ")");
            d3.select(domNode).select('g.node').attr("transform", "translate(" + translateX + "," + translateY + ")");
            zoomListener.scale(zoomListener.scale());
            zoomListener.translate([translateX, translateY]);
            panTimer = setTimeout(function() {
                pan(domNode, speed, direction);
            }, 50);
        }
    }

    // Define the zoom function for the zoomable tree

    function zoom() {
        svgGroup.attr("transform", "translate(" + d3.event.translate + ")scale(" + d3.event.scale + ")");
    }


    // define the zoomListener which calls the zoom function on the "zoom" event constrained within the scaleExtents
    var zoomListener = d3.behavior.zoom().scaleExtent([0.1, 3]).on("zoom", zoom);

    function initiateDrag(d, domNode) {
        draggingNode = d;
        d3.select(domNode).select('.ghostCircle').attr('pointer-events', 'none');
        d3.selectAll('.ghostCircle').attr('class', 'ghostCircle show');
        d3.select(domNode).attr('class', 'node activeDrag');

        svgGroup.selectAll("g.node").sort(function(a, b) { // select the parent and sort the path's
            if (a.id != draggingNode.id) return 1; // a is not the hovered element, send "a" to the back
            else return -1; // a is the hovered element, bring "a" to the front
        });
        // if nodes has children, remove the links and nodes
        if (nodes.length > 1) {
            // remove link paths
            links = tree.links(nodes);
            nodePaths = svgGroup.selectAll("path.link")
                .data(links, function(d) {
                    return d.target.id;
                }).remove();
            // remove child nodes
            nodesExit = svgGroup.selectAll("g.node")
                .data(nodes, function(d) {
                    return d.id;
                }).filter(function(d, i) {
                    if (d.id == draggingNode.id) {
                        return false;
                    }
                    return true;
                }).remove();
        }

        // remove parent link
        parentLink = tree.links(tree.nodes(draggingNode.parent));
        svgGroup.selectAll('path.link').filter(function(d, i) {
            if (d.target.id == draggingNode.id) {
                return true;
            }
            return false;
        }).remove();

        dragStarted = null;
    }

    // define the baseSvg, attaching a class for styling and the zoomListener
    var baseSvg = d3.select("#tree-container").append("svg")
        .attr("width", viewerWidth)
        .attr("height", viewerHeight)
        .attr("class", "overlay")
        .call(zoomListener);


    // Define the drag listeners for drag/drop behaviour of nodes.
    dragListener = d3.behavior.drag()
        .on("dragstart", function(d) {
            if (d == root) {
                return;
            }
            dragStarted = true;
            nodes = tree.nodes(d);
            d3.event.sourceEvent.stopPropagation();
            // it's important that we suppress the mouseover event on the node being dragged. Otherwise it will absorb the mouseover event and the underlying node will not detect it d3.select(this).attr('pointer-events', 'none');
        })
        .on("drag", function(d) {
            if (d == root) {
                return;
            }
            if (dragStarted) {
                domNode = this;
                initiateDrag(d, domNode);
            }

            // get coords of mouseEvent relative to svg container to allow for panning
            relCoords = d3.mouse($('svg').get(0));
            if (relCoords[0] < panBoundary) {
                panTimer = true;
                pan(this, 'left');
            } else if (relCoords[0] > ($('svg').width() - panBoundary)) {

                panTimer = true;
                pan(this, 'right');
            } else if (relCoords[1] < panBoundary) {
                panTimer = true;
                pan(this, 'up');
            } else if (relCoords[1] > ($('svg').height() - panBoundary)) {
                panTimer = true;
                pan(this, 'down');
            } else {
                try {
                    clearTimeout(panTimer);
                } catch (e) {

                }
            }

            d.x0 += d3.event.dy;
            d.y0 += d3.event.dx;
            var node = d3.select(this);
            node.attr("transform", "translate(" + d.y0 + "," + d.x0 + ")");
            updateTempConnector();
        }).on("dragend", function(d) {
            if (d == root) {
                return;
            }
            domNode = this;
            if (selectedNode) {
                // now remove the element from the parent, and insert it into the new elements children
                var index = draggingNode.parent.children.indexOf(draggingNode);
                if (index > -1) {
                    draggingNode.parent.children.splice(index, 1);
                }
                if (typeof selectedNode.children !== 'undefined' || typeof selectedNode._children !== 'undefined') {
                    if (typeof selectedNode.children !== 'undefined') {
                        selectedNode.children.push(draggingNode);
                    } else {
                        selectedNode._children.push(draggingNode);
                    }
                } else {
                    selectedNode.children = [];
                    selectedNode.children.push(draggingNode);
                }
                // Make sure that the node being added to is expanded so user can see added node is correctly moved
                expand(selectedNode);
                sortTree();
                endDrag();
            } else {
                endDrag();
            }
        });

    function endDrag() {
        selectedNode = null;
        d3.selectAll('.ghostCircle').attr('class', 'ghostCircle');
        d3.select(domNode).attr('class', 'node');
        // now restore the mouseover event or we won't be able to drag a 2nd time
        d3.select(domNode).select('.ghostCircle').attr('pointer-events', '');
        updateTempConnector();
        if (draggingNode !== null) {
            update(root);
            centerNode(draggingNode);
            draggingNode = null;
        }
    }

    // Helper functions for collapsing and expanding nodes.

    function collapse(d) {
        if (d.children) {
            d._children = d.children;
            d._children.forEach(collapse);
            d.children = null;
        }
    }

    function expand(d) {
        if (d._children) {
            d.children = d._children;
            d.children.forEach(expand);
            d._children = null;
        }
    }

    var overCircle = function(d) {
        selectedNode = d;
        updateTempConnector();
    };
    var outCircle = function(d) {
        selectedNode = null;
        updateTempConnector();
    };

    // Function to update the temporary connector indicating dragging affiliation
    var updateTempConnector = function() {
        var data = [];
        if (draggingNode !== null && selectedNode !== null) {
            // have to flip the source coordinates since we did this for the existing connectors on the original tree
            data = [{
                source: {
                    x: selectedNode.y0,
                    y: selectedNode.x0
                },
                target: {
                    x: draggingNode.y0,
                    y: draggingNode.x0
                }
            }];
        }
        var link = svgGroup.selectAll(".templink").data(data);

        link.enter().append("path")
            .attr("class", "templink")
            .attr("d", d3.svg.diagonal())
            .attr('pointer-events', 'none');

        link.attr("d", d3.svg.diagonal());

        link.exit().remove();
    };

    // Function to center node when clicked/dropped so node doesn't get lost when collapsing/moving with large amount of children.

    function centerNode(source) {
        scale = zoomListener.scale();
        x = -source.y0;
        y = -source.x0;
        x = x * scale + viewerWidth / 2;
        y = y * scale + viewerHeight / 2;
        d3.select('g').transition()
            .duration(duration)
            .attr("transform", "translate(" + x + "," + y + ")scale(" + scale + ")");
        zoomListener.scale(scale);
        zoomListener.translate([x, y]);
    }

    // Toggle children function

    function toggleChildren(d) {
        if (d.children) {
            d._children = d.children;
            d.children = null;
        } else if (d._children) {
            d.children = d._children;
            d._children = null;
        }
        return d;
    }

    // Toggle children on click.

    function click(d) {
        if (d3.event.defaultPrevented) return; // click suppressed
        d = toggleChildren(d);
        update(d);
        centerNode(d);
    }

    function update(source) {
        // Compute the new height, function counts total children of root node and sets tree height accordingly.
        // This prevents the layout looking squashed when new nodes are made visible or looking sparse when nodes are removed
        // This makes the layout more consistent.
        var levelWidth = [1];
        var childCount = function(level, n) {

            if (n.children && n.children.length > 0) {
                if (levelWidth.length <= level + 1) levelWidth.push(0);

                levelWidth[level + 1] += n.children.length;
                n.children.forEach(function(d) {
                    childCount(level + 1, d);
                });
            }
        };
        childCount(0, root);
        var newHeight = d3.max(levelWidth) * 25; // 25 pixels per line  
        tree = tree.size([newHeight, viewerWidth]);

        // Compute the new tree layout.
        var nodes = tree.nodes(root).reverse(),
            links = tree.links(nodes);

        // Set widths between levels based on maxLabelLength.
        nodes.forEach(function(d) {
            d.y = (d.depth * (maxLabelLength * 10)); //maxLabelLength * 10px
            // alternatively to keep a fixed scale one can set a fixed depth per level
            // Normalize for fixed-depth by commenting out below line
            // d.y = (d.depth * 500); //500px per level.
        });

        // Update the nodes…
        node = svgGroup.selectAll("g.node")
            .data(nodes, function(d) {
                return d.id || (d.id = ++i);
            });

        // Enter any new nodes at the parent's previous position.
        var nodeEnter = node.enter().append("g")
            .call(dragListener)
            .attr("class", "node")
            .attr("transform", function(d) {
                return "translate(" + source.y0 + "," + source.x0 + ")";
            })
            ;			

        nodeEnter.append("circle")
            .attr('class', 'nodeCircle')
            .attr("r", 0)
            .style("fill", function(d) {
                return d._children ? "lightsteelblue" : "#fff";
            })
			.on('click', click);

        nodeEnter.append("text")
            .attr("x", function(d) {
                return d.children || d._children ? -10 : 10;
            })
            .attr("dy", ".35em")
            .attr('class', 'nodeText')
            .attr("text-anchor", function(d) {
                return d.children || d._children ? "end" : "start";
            })
            .text(function(d) {
                return d.Label;
            })
            .style("fill-opacity", 0)
			.on("mouseover", function(d) {
				div.transition()
				  .duration(200)
				  .style("opacity", .9);
				div .html(
					"PID: " + d.name + "<br/>" + 
					"Label: " + d.Label + "<br/>" +
					"Description: " + d.Definition + "<br/>" 

					)
				  .style("left", (d3.event.pageX) + "px")
				  .style("top", (d3.event.pageY - 28) + "px");
				})
			  .on("mouseout", function(d) {
				div.transition()
				  .duration(500)
				  .style("opacity", 0);
				});

        // phantom node to give us mouseover in a radius around it
        nodeEnter.append("circle")
            .attr('class', 'ghostCircle')
            .attr("r", 30)
            .attr("opacity", 0.2) // change this to zero to hide the target area
        .style("fill", "red")
            .attr('pointer-events', 'mouseover')
            .on("mouseover", function(node) {
                overCircle(node);
            })
            .on("mouseout", function(node) {
                outCircle(node);
            });

        // Update the text to reflect whether node has children or not.
        node.select('text')
            .attr("x", function(d) {
                return d.children || d._children ? -10 : 10;
            })
            .attr("text-anchor", function(d) {
                return d.children || d._children ? "end" : "start";
            })
            .text(function(d) {
                return d.Label;
            });

        // Change the circle fill depending on whether it has children and is collapsed
        node.select("circle.nodeCircle")
            .attr("r", 4.5)
            .style("fill", function(d) {
                return d._children ? "lightsteelblue" : "#fff";
            });
		// add the tool tip
		var div = d3.select("body").append("div")
			.attr("class", "tooltip")
			.style("opacity", 0);
        // Transition nodes to their new position.
        var nodeUpdate = node.transition()
            .duration(duration)
            .attr("transform", function(d) {
                return "translate(" + d.y + "," + d.x + ")";
            });

        // Fade the text in
        nodeUpdate.select("text")
            .style("fill-opacity", 1);

        // Transition exiting nodes to the parent's new position.
        var nodeExit = node.exit().transition()
            .duration(duration)
            .attr("transform", function(d) {
                return "translate(" + source.y + "," + source.x + ")";
            })
            .remove();

        nodeExit.select("circle")
            .attr("r", 0);

        nodeExit.select("text")
            .style("fill-opacity", 0);

        // Update the links…
        var link = svgGroup.selectAll("path.link")
            .data(links, function(d) {
                return d.target.id;
            });

        // Enter any new links at the parent's previous position.
        link.enter().insert("path", "g")
            .attr("class", "link")
            .attr("d", function(d) {
                var o = {
                    x: source.x0,
                    y: source.y0
                };
                return diagonal({
                    source: o,
                    target: o
                });
            });

        // Transition links to their new position.
        link.transition()
            .duration(duration)
            .attr("d", diagonal);

        // Transition exiting nodes to the parent's new position.
        link.exit().transition()
            .duration(duration)
            .attr("d", function(d) {
                var o = {
                    x: source.x,
                    y: source.y
                };
                return diagonal({
                    source: o,
                    target: o
                });
            })
            .remove();

        // Stash the old positions for transition.
        nodes.forEach(function(d) {
            d.x0 = d.x;
            d.y0 = d.y;
        });
    }

    // Append a group which holds all nodes and which the zoom Listener can act upon.
    var svgGroup = baseSvg.append("g");

    // Define the root
    root = treeData[0];
    root.x0 = viewerHeight / 2;
    root.y0 = 0;

    // Layout the tree initially and center on the root node.
    update(root);
    centerNode(root);

</script>
</body>
